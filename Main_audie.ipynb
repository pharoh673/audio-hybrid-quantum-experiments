{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 928025,
          "sourceType": "datasetVersion",
          "datasetId": 500970
        },
        {
          "sourceId": 282531084,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "997c8c2dee5642c7a2d37bfc9ab4d1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0bcb14b08314411bdca24b91cd727f0",
              "IPY_MODEL_b9bb13e0a74140498e6b0541fad3b6fb",
              "IPY_MODEL_b1d14bab06cd42b1a8c0c9a43ec16452"
            ],
            "layout": "IPY_MODEL_67952384a9e14971bc0f30edc257ee29"
          }
        },
        "d0bcb14b08314411bdca24b91cd727f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd348dc5a0d241dfbc36023fa7ea4466",
            "placeholder": "​",
            "style": "IPY_MODEL_33a50d6989d447d1a80060150e047d72",
            "value": "Train: 100%"
          }
        },
        "b9bb13e0a74140498e6b0541fad3b6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ad0fe19ffd441c291dbeb89f3d6b55a",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa6ed41e10f8457b832a7049a141da98",
            "value": 111
          }
        },
        "b1d14bab06cd42b1a8c0c9a43ec16452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_801455c43ef0445d9d6d489baa39e169",
            "placeholder": "​",
            "style": "IPY_MODEL_5882b760b0d3433c9bc5f064b63d82a1",
            "value": " 111/111 [21:11&lt;00:00, 10.53s/it, loss=0.6235, acc=97.99%]"
          }
        },
        "67952384a9e14971bc0f30edc257ee29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bd348dc5a0d241dfbc36023fa7ea4466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a50d6989d447d1a80060150e047d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ad0fe19ffd441c291dbeb89f3d6b55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6ed41e10f8457b832a7049a141da98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "801455c43ef0445d9d6d489baa39e169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5882b760b0d3433c9bc5f064b63d82a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec26e924ac8c4a67b2e23f4f9d58d615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7632cf560422424589d69566748b932e",
              "IPY_MODEL_9918a6e4da7c4c4a83b20b42388c9922",
              "IPY_MODEL_4cbd57c2c5c84a9b97375d0b41553600"
            ],
            "layout": "IPY_MODEL_2cdf271d89004794924ec5a8a873bc5b"
          }
        },
        "7632cf560422424589d69566748b932e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70295aede5f4bf19bb9f9f8459b96fc",
            "placeholder": "​",
            "style": "IPY_MODEL_b175f62429384c12924457a03f3f12a8",
            "value": "Train: 100%"
          }
        },
        "9918a6e4da7c4c4a83b20b42388c9922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0755a00f484ffcbcd32313211f24fa",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_786dd17ecfcf4c7c9518468775c62975",
            "value": 111
          }
        },
        "4cbd57c2c5c84a9b97375d0b41553600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1a0bab80fe41008b7f24b1ed191f74",
            "placeholder": "​",
            "style": "IPY_MODEL_d4fd0f4e56ed4f16a70fab9dc139188d",
            "value": " 111/111 [17:25&lt;00:00,  8.09s/it, loss=0.6151, acc=98.18%]"
          }
        },
        "2cdf271d89004794924ec5a8a873bc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b70295aede5f4bf19bb9f9f8459b96fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b175f62429384c12924457a03f3f12a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a0755a00f484ffcbcd32313211f24fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786dd17ecfcf4c7c9518468775c62975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d1a0bab80fe41008b7f24b1ed191f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fd0f4e56ed4f16a70fab9dc139188d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c9f694f9ef48a29e2a0b7f7413db05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_073f7f47cca34c8194a133ce0cb004ed",
              "IPY_MODEL_ad7b1871c5734b118d735d46a7a4d645",
              "IPY_MODEL_21f5ff2663544121ba9643a7531b48be"
            ],
            "layout": "IPY_MODEL_be18476941e34a1483361f6b33bc27c7"
          }
        },
        "073f7f47cca34c8194a133ce0cb004ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497b6c3d8c50471c8bb1749e803a68b8",
            "placeholder": "​",
            "style": "IPY_MODEL_6cb5aef1b57f4199964a7219da82b48d",
            "value": "Train: 100%"
          }
        },
        "ad7b1871c5734b118d735d46a7a4d645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd6ef7b6fd247c0b4bb8a439da9ad0e",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f0378297888477380ee6edaebcc390a",
            "value": 111
          }
        },
        "21f5ff2663544121ba9643a7531b48be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a88591e147b48e0becd9135ac0cccf0",
            "placeholder": "​",
            "style": "IPY_MODEL_2c62569ab74040f2be41eaa58951a89c",
            "value": " 111/111 [17:57&lt;00:00,  8.29s/it, loss=0.5933, acc=98.94%]"
          }
        },
        "be18476941e34a1483361f6b33bc27c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "497b6c3d8c50471c8bb1749e803a68b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb5aef1b57f4199964a7219da82b48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd6ef7b6fd247c0b4bb8a439da9ad0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0378297888477380ee6edaebcc390a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a88591e147b48e0becd9135ac0cccf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c62569ab74040f2be41eaa58951a89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c62f23ebbbb2459d8983f4ef4f20ba53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1dff32f20c54949912402d98534f4c2",
              "IPY_MODEL_04ad33548e0f40e488b5d58e1177f606",
              "IPY_MODEL_7143b75d73c646a289a9744ff49c650f"
            ],
            "layout": "IPY_MODEL_b6f8f40d6e0e421db0b347e7e15f75aa"
          }
        },
        "b1dff32f20c54949912402d98534f4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30424a97a29549fb9bcf1ce63469b7ef",
            "placeholder": "​",
            "style": "IPY_MODEL_8ed644d26150469aa2da4fd547cc9cdd",
            "value": "Train: 100%"
          }
        },
        "04ad33548e0f40e488b5d58e1177f606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b612d03e0214706a405782bd9e6e890",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52f595f5ff1f4ac485cd056f1e967658",
            "value": 111
          }
        },
        "7143b75d73c646a289a9744ff49c650f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610a58d58e0247a79d4f7e046f712f60",
            "placeholder": "​",
            "style": "IPY_MODEL_1b61822ddbe84cdebfeba3acf5405db2",
            "value": " 111/111 [17:51&lt;00:00,  8.43s/it, loss=0.5849, acc=99.21%]"
          }
        },
        "b6f8f40d6e0e421db0b347e7e15f75aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "30424a97a29549fb9bcf1ce63469b7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed644d26150469aa2da4fd547cc9cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b612d03e0214706a405782bd9e6e890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f595f5ff1f4ac485cd056f1e967658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "610a58d58e0247a79d4f7e046f712f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b61822ddbe84cdebfeba3acf5405db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "280fb856de264e0e9c9e3088925021eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55e04b05c2eb451daca4a3ab8b5d1da9",
              "IPY_MODEL_6187837960a34c8b9a4c82d3e1dd0d8a",
              "IPY_MODEL_d2aedd3af4e34c9b87b01ae7cedf0c3f"
            ],
            "layout": "IPY_MODEL_79def67722924daabc1f264b3044ab93"
          }
        },
        "55e04b05c2eb451daca4a3ab8b5d1da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae85463a8fe64e489cacf61bfc44017d",
            "placeholder": "​",
            "style": "IPY_MODEL_eedb0155abed4ead89d133a0e7d364d1",
            "value": "Train: 100%"
          }
        },
        "6187837960a34c8b9a4c82d3e1dd0d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ec4f4ec55e040cd8e99c1b70aeeebb5",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2589799e39c44ab1babf8a28499b64b9",
            "value": 111
          }
        },
        "d2aedd3af4e34c9b87b01ae7cedf0c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb35b7c190aa485bb916c807b556eed9",
            "placeholder": "​",
            "style": "IPY_MODEL_8c7c72f7e0474f39a9aa82be0b5b1cc4",
            "value": " 111/111 [17:43&lt;00:00,  8.44s/it, loss=0.5705, acc=99.52%]"
          }
        },
        "79def67722924daabc1f264b3044ab93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ae85463a8fe64e489cacf61bfc44017d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedb0155abed4ead89d133a0e7d364d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ec4f4ec55e040cd8e99c1b70aeeebb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2589799e39c44ab1babf8a28499b64b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb35b7c190aa485bb916c807b556eed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7c72f7e0474f39a9aa82be0b5b1cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9176f1ae339c48ffa504468e93802f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ade70d62e0204efbac87cbfeda080615",
              "IPY_MODEL_a10d58d3e3cb4529ba17e1cd476f13d0",
              "IPY_MODEL_752a18615e864ef68667a07f903a1955"
            ],
            "layout": "IPY_MODEL_8a8226d7605142a781a6cff1a8920004"
          }
        },
        "ade70d62e0204efbac87cbfeda080615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf524b91712a46bc8b7a30b3b779f40f",
            "placeholder": "​",
            "style": "IPY_MODEL_f115d47d13884590921550e8aa03deb1",
            "value": "Train: 100%"
          }
        },
        "a10d58d3e3cb4529ba17e1cd476f13d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb49aa6e3ef46ad9b2561141274a09d",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71e31d44f0c7479fbe7fa08cb453aa89",
            "value": 111
          }
        },
        "752a18615e864ef68667a07f903a1955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ddeedfe69744a84a8897833e34f82fd",
            "placeholder": "​",
            "style": "IPY_MODEL_e35af60662b04a6f8f18496bf50513e1",
            "value": " 111/111 [17:48&lt;00:00,  8.30s/it, loss=0.5644, acc=99.68%]"
          }
        },
        "8a8226d7605142a781a6cff1a8920004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "cf524b91712a46bc8b7a30b3b779f40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f115d47d13884590921550e8aa03deb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb49aa6e3ef46ad9b2561141274a09d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e31d44f0c7479fbe7fa08cb453aa89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ddeedfe69744a84a8897833e34f82fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e35af60662b04a6f8f18496bf50513e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faea1f34809f4c78a9a1b2250bf5573a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d75d8ccf43f4d39ab7b09f135fb0fd8",
              "IPY_MODEL_cabe6b473f394f46a53e313620c0cc42",
              "IPY_MODEL_618a0a78fa9a4de68d1aeb895596fc80"
            ],
            "layout": "IPY_MODEL_0877ff1c32824410b51cb496166c4e90"
          }
        },
        "4d75d8ccf43f4d39ab7b09f135fb0fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570fec5b81a045928a5779fb5bbf1dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_9546d1ca8b2348f684088b82ff1d74d6",
            "value": "Train: 100%"
          }
        },
        "cabe6b473f394f46a53e313620c0cc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32acce55a3fd4dae81b1997b2aaf4212",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6cc0c7488b1485d98e297b91f5ae7da",
            "value": 111
          }
        },
        "618a0a78fa9a4de68d1aeb895596fc80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48d1995a3d644349ee2b7f8772b8608",
            "placeholder": "​",
            "style": "IPY_MODEL_892662eb6006466a87ea9a3cb3544809",
            "value": " 111/111 [17:52&lt;00:00,  8.21s/it, loss=0.5577, acc=99.80%]"
          }
        },
        "0877ff1c32824410b51cb496166c4e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "570fec5b81a045928a5779fb5bbf1dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9546d1ca8b2348f684088b82ff1d74d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32acce55a3fd4dae81b1997b2aaf4212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6cc0c7488b1485d98e297b91f5ae7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b48d1995a3d644349ee2b7f8772b8608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892662eb6006466a87ea9a3cb3544809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c96776290724b90a27ad34cb497f03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d5cd2af2e147cca0f7e1120d4dc87f",
              "IPY_MODEL_9540021ae13c4d669edeee28836c3dc9",
              "IPY_MODEL_44616b9fb25a40ebb31f9c187b4e46f2"
            ],
            "layout": "IPY_MODEL_12038b3b16bd4efaa5848fb3fe53a0e1"
          }
        },
        "d4d5cd2af2e147cca0f7e1120d4dc87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc58817165b4583bc6986445f134e93",
            "placeholder": "​",
            "style": "IPY_MODEL_a62be1ad8fb543d2931f4c0237bd1801",
            "value": "Train: 100%"
          }
        },
        "9540021ae13c4d669edeee28836c3dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e747ecf50644d51b72396a997cadfe9",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5efa0aee28d431483f59e63fabf6ba9",
            "value": 9
          }
        },
        "44616b9fb25a40ebb31f9c187b4e46f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0461951189164733b083e9aae761b303",
            "placeholder": "​",
            "style": "IPY_MODEL_0f98dc7c8f334d3bb788bdab4a43730c",
            "value": " 9/9 [06:44&lt;00:00, 36.95s/it, acc=14.58%, loss=2.2844]"
          }
        },
        "12038b3b16bd4efaa5848fb3fe53a0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0dc58817165b4583bc6986445f134e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62be1ad8fb543d2931f4c0237bd1801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e747ecf50644d51b72396a997cadfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5efa0aee28d431483f59e63fabf6ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0461951189164733b083e9aae761b303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f98dc7c8f334d3bb788bdab4a43730c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe35e20873bb4b4bba4d3b0c12fbdde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5df3d09481640ff85a71658391a4224",
              "IPY_MODEL_3be72b2682b34f20ac759b5504f0b501",
              "IPY_MODEL_85981f5dcb9d4c36af7494d875f6e300"
            ],
            "layout": "IPY_MODEL_22bf6bd1e25d46d2a5d4fcc3df5ffc49"
          }
        },
        "e5df3d09481640ff85a71658391a4224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8112341c444d06ae72b5e7497c5310",
            "placeholder": "​",
            "style": "IPY_MODEL_bc12b21db07b45f7837297f074b3b48c",
            "value": "Train: 100%"
          }
        },
        "3be72b2682b34f20ac759b5504f0b501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6792589aa6543d1891edf9b68e6796d",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c1208cec3494efd84f8b023981a2882",
            "value": 9
          }
        },
        "85981f5dcb9d4c36af7494d875f6e300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e179110b4d54c3a84ca162b4fe2a7df",
            "placeholder": "​",
            "style": "IPY_MODEL_86b5db52353c43ea8be2352934c2a3a9",
            "value": " 9/9 [00:25&lt;00:00,  2.28s/it, acc=20.45%, loss=2.2049]"
          }
        },
        "22bf6bd1e25d46d2a5d4fcc3df5ffc49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3c8112341c444d06ae72b5e7497c5310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc12b21db07b45f7837297f074b3b48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6792589aa6543d1891edf9b68e6796d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1208cec3494efd84f8b023981a2882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e179110b4d54c3a84ca162b4fe2a7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b5db52353c43ea8be2352934c2a3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fec1fb65d88041ffae5f9cce4c10311b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8374ccff1854fbcadd4a34c9c187d71",
              "IPY_MODEL_c1e02ce200a14095b89904a0c08181e0",
              "IPY_MODEL_d0a2c8a703cb43d4b45d4ee949b83dde"
            ],
            "layout": "IPY_MODEL_e4c8630f44e34443a652159f2daf4ab0"
          }
        },
        "c8374ccff1854fbcadd4a34c9c187d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091baa76a18c44f4b654ac773f4f3c17",
            "placeholder": "​",
            "style": "IPY_MODEL_2588e151cdcd46baac131cd01827875e",
            "value": "Train: 100%"
          }
        },
        "c1e02ce200a14095b89904a0c08181e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7710d20cb44449bb9964895cbc44f69",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29a9e15107bf4f33b61e122eafc630ad",
            "value": 9
          }
        },
        "d0a2c8a703cb43d4b45d4ee949b83dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a967380430564df4a7102de3e3763691",
            "placeholder": "​",
            "style": "IPY_MODEL_830ddfada0384c6bb4a012d740c21562",
            "value": " 9/9 [00:25&lt;00:00,  2.50s/it, acc=26.33%, loss=2.1216]"
          }
        },
        "e4c8630f44e34443a652159f2daf4ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "091baa76a18c44f4b654ac773f4f3c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2588e151cdcd46baac131cd01827875e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7710d20cb44449bb9964895cbc44f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a9e15107bf4f33b61e122eafc630ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a967380430564df4a7102de3e3763691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "830ddfada0384c6bb4a012d740c21562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59f2f33927e94c3ba5d37f9ab9865893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df091e75fbe24f4497ac78b0c2b0e2c1",
              "IPY_MODEL_83f1fff6e4104898b19319fbb8e61dbd",
              "IPY_MODEL_b73eaa86e2cf4a7b835c99a05bc0246e"
            ],
            "layout": "IPY_MODEL_331e288bce19401dbc57ee6ab1f9fcc5"
          }
        },
        "df091e75fbe24f4497ac78b0c2b0e2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21bc6c8760624b84945693a355fa5d71",
            "placeholder": "​",
            "style": "IPY_MODEL_19d47eee79bf4264b9510db3a269d22e",
            "value": "Train: 100%"
          }
        },
        "83f1fff6e4104898b19319fbb8e61dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e49daf36a7f4ae0b3ddf190dd5d473c",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_952b027bd697476c89779c78c24453e9",
            "value": 9
          }
        },
        "b73eaa86e2cf4a7b835c99a05bc0246e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_231003f2ea034a6aa800a810ba927ba6",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d86aaf4be644b085c45cf111102e85",
            "value": " 9/9 [00:27&lt;00:00,  2.55s/it, acc=27.65%, loss=2.0662]"
          }
        },
        "331e288bce19401dbc57ee6ab1f9fcc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "21bc6c8760624b84945693a355fa5d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d47eee79bf4264b9510db3a269d22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e49daf36a7f4ae0b3ddf190dd5d473c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952b027bd697476c89779c78c24453e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "231003f2ea034a6aa800a810ba927ba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d86aaf4be644b085c45cf111102e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df040bfad19446f7a648c7f000cdb1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81ae03d95dfc4c828d7f9705bdb8ff12",
              "IPY_MODEL_b7ebb8a3a1954c54b46599b1da0d3dcc",
              "IPY_MODEL_32f95e3a249c46658f11d81a098b2073"
            ],
            "layout": "IPY_MODEL_781eeb7797c34d5ab08c13f89200093f"
          }
        },
        "81ae03d95dfc4c828d7f9705bdb8ff12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf924747a884285b8c9dee2c88f0922",
            "placeholder": "​",
            "style": "IPY_MODEL_fc97b268be4a452ab800e3f62cf1014c",
            "value": "Train: 100%"
          }
        },
        "b7ebb8a3a1954c54b46599b1da0d3dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d22bf901b874799830e8635b42383f8",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b96d87f7fe524b40acc45b42c2761209",
            "value": 9
          }
        },
        "32f95e3a249c46658f11d81a098b2073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c43afba6e6f4aa288a67c1a3255a76e",
            "placeholder": "​",
            "style": "IPY_MODEL_b42b322317984535a9ecc27e70ce1204",
            "value": " 9/9 [00:26&lt;00:00,  2.45s/it, acc=29.55%, loss=2.0204]"
          }
        },
        "781eeb7797c34d5ab08c13f89200093f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5bf924747a884285b8c9dee2c88f0922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc97b268be4a452ab800e3f62cf1014c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d22bf901b874799830e8635b42383f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b96d87f7fe524b40acc45b42c2761209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c43afba6e6f4aa288a67c1a3255a76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42b322317984535a9ecc27e70ce1204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ef480cff0c438e8baeb7f7b3d7bd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7c3d1e0c939429c87fb92e7ca441ec9",
              "IPY_MODEL_963e938f06a846c89a13f9abecd6a943",
              "IPY_MODEL_f813e7c7ff854039aa021fb834170207"
            ],
            "layout": "IPY_MODEL_adfa4b343d574ef39a93e92924cf874a"
          }
        },
        "f7c3d1e0c939429c87fb92e7ca441ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ce5929c58b04cf5aff93e81b595787f",
            "placeholder": "​",
            "style": "IPY_MODEL_48a4bd9e8f574c7c985ef6c81e917d96",
            "value": "Train: 100%"
          }
        },
        "963e938f06a846c89a13f9abecd6a943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ad34ab6db34ce7bdb029cad3134b5b",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b79721e213444016afb570da0d906030",
            "value": 14
          }
        },
        "f813e7c7ff854039aa021fb834170207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5856b90b83f422b8b0ad33d94fa3d13",
            "placeholder": "​",
            "style": "IPY_MODEL_f3d3830124e6495ba55dd0700ee238d7",
            "value": " 14/14 [52:42&lt;00:00, 213.00s/it, acc=72.16%, loss=1.1778]"
          }
        },
        "adfa4b343d574ef39a93e92924cf874a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7ce5929c58b04cf5aff93e81b595787f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a4bd9e8f574c7c985ef6c81e917d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48ad34ab6db34ce7bdb029cad3134b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79721e213444016afb570da0d906030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5856b90b83f422b8b0ad33d94fa3d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d3830124e6495ba55dd0700ee238d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8526b299b7a045eb8237b9782b752f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b80a4f488a85490db8d34bad2fca334b",
              "IPY_MODEL_06a5e8177c6e48c2af6a9f7d3bf90e9c",
              "IPY_MODEL_c4888cec127445d59d8d5feafe7fd252"
            ],
            "layout": "IPY_MODEL_39510bedb6b7420daaadacd91db0ef8b"
          }
        },
        "b80a4f488a85490db8d34bad2fca334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7138cccb7040ec8dfd9207bb1fbfd9",
            "placeholder": "​",
            "style": "IPY_MODEL_7f2c5f00842f42d4b60abd7c38d3676e",
            "value": "Train: 100%"
          }
        },
        "06a5e8177c6e48c2af6a9f7d3bf90e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d699ca2848b344e38226172b899d0d00",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2810d97edeb049a194516f8c0506435d",
            "value": 14
          }
        },
        "c4888cec127445d59d8d5feafe7fd252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b3bd89b30a44e96ba30871f9ed221e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c7dd37bcca7f4267b3a1f216733e20f7",
            "value": " 14/14 [17:41&lt;00:00, 72.81s/it, acc=73.33%, loss=1.1624]"
          }
        },
        "39510bedb6b7420daaadacd91db0ef8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ae7138cccb7040ec8dfd9207bb1fbfd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2c5f00842f42d4b60abd7c38d3676e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d699ca2848b344e38226172b899d0d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2810d97edeb049a194516f8c0506435d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b3bd89b30a44e96ba30871f9ed221e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dd37bcca7f4267b3a1f216733e20f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440b7a439c774ecd9a3d3de730f5eecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9303607605034a2b8b936a24c3bbcb4b",
              "IPY_MODEL_049b24ca69034225ac8e9e81b501bf0c",
              "IPY_MODEL_8234d99de75c4dc8865e42cd58b3b091"
            ],
            "layout": "IPY_MODEL_074e89bd78c440d8abe216f2ff5cb929"
          }
        },
        "9303607605034a2b8b936a24c3bbcb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8138247b157047c895f7cb57fcbf2d15",
            "placeholder": "​",
            "style": "IPY_MODEL_401d88c79d374f668625ec60ee40e482",
            "value": "Train: 100%"
          }
        },
        "049b24ca69034225ac8e9e81b501bf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da5083a92fd416bb1e3cd0aeca4279c",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_396bacbfee9845a5a826472be2a2c337",
            "value": 14
          }
        },
        "8234d99de75c4dc8865e42cd58b3b091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a30e699df5d46d28590832195a9bb7c",
            "placeholder": "​",
            "style": "IPY_MODEL_8adcf78c33b643f2b2f4c97ce15fd51d",
            "value": " 14/14 [17:52&lt;00:00, 73.35s/it, acc=74.26%, loss=1.1364]"
          }
        },
        "074e89bd78c440d8abe216f2ff5cb929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8138247b157047c895f7cb57fcbf2d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401d88c79d374f668625ec60ee40e482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da5083a92fd416bb1e3cd0aeca4279c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396bacbfee9845a5a826472be2a2c337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a30e699df5d46d28590832195a9bb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8adcf78c33b643f2b2f4c97ce15fd51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30f2c8117d9d46bcaa4f03edf0a2828a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e74f27c6bf5749d0b77f0a3302b8c78b",
              "IPY_MODEL_d60beb48ba124beeb878d44bb4f01c7c",
              "IPY_MODEL_d83f0e1d893445b9a22a94f023b4bd0a"
            ],
            "layout": "IPY_MODEL_0949eed59a0c447caa9ff2a5d27fb77b"
          }
        },
        "e74f27c6bf5749d0b77f0a3302b8c78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d428dbe2bcaa40468b1cff26d485fa7d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d9c90c7d73f4b8a97eb5f7269594015",
            "value": "Train: 100%"
          }
        },
        "d60beb48ba124beeb878d44bb4f01c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00e3121b5cfa45deb66e86c3e164dbc6",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ccf744ea5454af0876e7b031b26c20b",
            "value": 14
          }
        },
        "d83f0e1d893445b9a22a94f023b4bd0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d6fc68615a4cdf9f4ba4f43b832194",
            "placeholder": "​",
            "style": "IPY_MODEL_5bc83b1412e345b086e8b7326b671cf8",
            "value": " 14/14 [52:22&lt;00:00, 216.10s/it, acc=73.08%, loss=1.0004]"
          }
        },
        "0949eed59a0c447caa9ff2a5d27fb77b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d428dbe2bcaa40468b1cff26d485fa7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9c90c7d73f4b8a97eb5f7269594015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00e3121b5cfa45deb66e86c3e164dbc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccf744ea5454af0876e7b031b26c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11d6fc68615a4cdf9f4ba4f43b832194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bc83b1412e345b086e8b7326b671cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8352a4ccd3ab4cac85ac8dcfec59fcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0d439d6bccb48fa84c3a14a2275c519",
              "IPY_MODEL_671f251630494415af95a1eacc9930ea",
              "IPY_MODEL_6b56987b856244db9d2c10392fccdf5b"
            ],
            "layout": "IPY_MODEL_f205b0a669df4665b0f5639270ca9de0"
          }
        },
        "c0d439d6bccb48fa84c3a14a2275c519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ef6bc4c9c24e958523a3307399d45d",
            "placeholder": "​",
            "style": "IPY_MODEL_bb230e5f27e54dd3a2b3245477301a36",
            "value": "Train: 100%"
          }
        },
        "671f251630494415af95a1eacc9930ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5de78d47a4a4230978f0fc3d3f80752",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b024216ea24468aa19108955bf4d831",
            "value": 14
          }
        },
        "6b56987b856244db9d2c10392fccdf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4253372536ca4ac591154f5fc84f23da",
            "placeholder": "​",
            "style": "IPY_MODEL_fee2462451dc488fb2e2a475c7ec3026",
            "value": " 14/14 [02:01&lt;00:00,  8.31s/it, acc=73.74%, loss=0.9791]"
          }
        },
        "f205b0a669df4665b0f5639270ca9de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "05ef6bc4c9c24e958523a3307399d45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb230e5f27e54dd3a2b3245477301a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5de78d47a4a4230978f0fc3d3f80752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b024216ea24468aa19108955bf4d831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4253372536ca4ac591154f5fc84f23da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee2462451dc488fb2e2a475c7ec3026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb11e18b09a043079a938e01ffbb429e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e006948196342aabbc20899bf65f95b",
              "IPY_MODEL_37552eb10d6e4218a9725fd7bf2d47cc",
              "IPY_MODEL_eba287ecfc63443794eb98ed7ec710af"
            ],
            "layout": "IPY_MODEL_eb284a924f1341e9ae6081de7e413ef5"
          }
        },
        "5e006948196342aabbc20899bf65f95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff9604b2bcbb47d8a5db9c25c4e712df",
            "placeholder": "​",
            "style": "IPY_MODEL_ea709b49d2d34e979057a2d572f08433",
            "value": "Train: 100%"
          }
        },
        "37552eb10d6e4218a9725fd7bf2d47cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9737be1e5a5646ad87de0261ab622aa3",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a778573ea44812b96ce578a10a198f",
            "value": 14
          }
        },
        "eba287ecfc63443794eb98ed7ec710af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2bd8c58bc2b47de916ebe4eef067274",
            "placeholder": "​",
            "style": "IPY_MODEL_43e7f93a793345129f71707b53df81eb",
            "value": " 14/14 [01:57&lt;00:00,  8.09s/it, acc=73.08%, loss=0.9921]"
          }
        },
        "eb284a924f1341e9ae6081de7e413ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ff9604b2bcbb47d8a5db9c25c4e712df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea709b49d2d34e979057a2d572f08433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9737be1e5a5646ad87de0261ab622aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a778573ea44812b96ce578a10a198f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2bd8c58bc2b47de916ebe4eef067274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e7f93a793345129f71707b53df81eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d132645993e44161af38e49a70973a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcff8d45d6d24ad09e73846d9b0e3f60",
              "IPY_MODEL_99918f5d23b142fd87fcacb7c35b6b9b",
              "IPY_MODEL_11fcc58415a346b1aa4c9a90e95b385c"
            ],
            "layout": "IPY_MODEL_6a23b5b95dae4485b422645cc14337aa"
          }
        },
        "dcff8d45d6d24ad09e73846d9b0e3f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a27b8c146a4d4bb988eb37ab11220b",
            "placeholder": "​",
            "style": "IPY_MODEL_7725f5d975234ff1aa1824b050e87a3a",
            "value": "Train: 100%"
          }
        },
        "99918f5d23b142fd87fcacb7c35b6b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380b80de64f7455b905afddd0dd72dfe",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f49e81779247cea92ab7c10010163b",
            "value": 14
          }
        },
        "11fcc58415a346b1aa4c9a90e95b385c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a54f21136642aab6429b6daf4b9730",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3966d1b001455c93849abbca6f2bcc",
            "value": " 14/14 [01:53&lt;00:00,  7.93s/it, acc=74.32%, loss=0.9653]"
          }
        },
        "6a23b5b95dae4485b422645cc14337aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "06a27b8c146a4d4bb988eb37ab11220b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7725f5d975234ff1aa1824b050e87a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "380b80de64f7455b905afddd0dd72dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f49e81779247cea92ab7c10010163b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33a54f21136642aab6429b6daf4b9730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3966d1b001455c93849abbca6f2bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e194b2817b7745cdb873175d03bfd449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce6be609312e4cbc86bad85cc66937a0",
              "IPY_MODEL_be77738455084cc094fc8eb71c37197f",
              "IPY_MODEL_8fc67361374c4af3bb4002768b8b530e"
            ],
            "layout": "IPY_MODEL_3f00301d5db8459da79b369022d8742e"
          }
        },
        "ce6be609312e4cbc86bad85cc66937a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0523f65fccec4227b30dbbec36e6920f",
            "placeholder": "​",
            "style": "IPY_MODEL_189076e8779d4b929760f34712faa7f1",
            "value": "Epoch 1:  11%"
          }
        },
        "be77738455084cc094fc8eb71c37197f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f8cccceeacb4e9b8c5e05ae352f0e8e",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53db75933b794f11a491d3827daebb95",
            "value": 3
          }
        },
        "8fc67361374c4af3bb4002768b8b530e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15fe4aae112e49c3bcb2374d371a504e",
            "placeholder": "​",
            "style": "IPY_MODEL_45e6428f421d46c090c80c7993dbdef4",
            "value": " 3/28 [10:36&lt;1:20:56, 194.27s/it, loss=2.3079, acc=14.06%]"
          }
        },
        "3f00301d5db8459da79b369022d8742e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0523f65fccec4227b30dbbec36e6920f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189076e8779d4b929760f34712faa7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f8cccceeacb4e9b8c5e05ae352f0e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53db75933b794f11a491d3827daebb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15fe4aae112e49c3bcb2374d371a504e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e6428f421d46c090c80c7993dbdef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1880181e6694a479ead1cfa6b254258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43cb647afff4ced847b9374f4a21f71",
              "IPY_MODEL_37ad511f2931473fa6254f9317a52666",
              "IPY_MODEL_f1c3382d27ec4d9a80a82462094417f9"
            ],
            "layout": "IPY_MODEL_5685395b2fc847029d0414ad578886bd"
          }
        },
        "c43cb647afff4ced847b9374f4a21f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba313fac71a24b1a82875564ebaab8e7",
            "placeholder": "​",
            "style": "IPY_MODEL_9104127c54c3475da0c420945cb00174",
            "value": "Train:   0%"
          }
        },
        "37ad511f2931473fa6254f9317a52666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1516f637ad1c4f948e38318e5756c36a",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e01dd99501f740ef9a211b3761e9f44c",
            "value": 0
          }
        },
        "f1c3382d27ec4d9a80a82462094417f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f25fde8e04b44d59a67c7395f296e35",
            "placeholder": "​",
            "style": "IPY_MODEL_35313b006b154501971d306bb4d34b94",
            "value": " 0/28 [02:31&lt;?, ?it/s]"
          }
        },
        "5685395b2fc847029d0414ad578886bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba313fac71a24b1a82875564ebaab8e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9104127c54c3475da0c420945cb00174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1516f637ad1c4f948e38318e5756c36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01dd99501f740ef9a211b3761e9f44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f25fde8e04b44d59a67c7395f296e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35313b006b154501971d306bb4d34b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef130110873e41f1a564db0f396de6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d412a89372ad4f5a85f5a21eda088c6c",
              "IPY_MODEL_9277aa4b0db742ccadb155b24851d502",
              "IPY_MODEL_bf196e38c79a49a68cf204d693438dac"
            ],
            "layout": "IPY_MODEL_1136f299b993463db3f53cc784cfc1dc"
          }
        },
        "d412a89372ad4f5a85f5a21eda088c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84f8536395e4fb89ead5a5d223a5b84",
            "placeholder": "​",
            "style": "IPY_MODEL_de815954edc549ffa4e038c796b27d54",
            "value": "Train:  18%"
          }
        },
        "9277aa4b0db742ccadb155b24851d502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3b9fc4dae54f72b56506267efcd7c7",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9da6cf83097344b890c69d750c7f5414",
            "value": 20
          }
        },
        "bf196e38c79a49a68cf204d693438dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae66312dcf534a30815b21e23a4c48b4",
            "placeholder": "​",
            "style": "IPY_MODEL_61662f2506fb47e6b2a415a4e8476922",
            "value": " 20/111 [13:29&lt;1:01:17, 40.41s/it, acc=0.109, loss=2.55]"
          }
        },
        "1136f299b993463db3f53cc784cfc1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "110px"
          }
        },
        "a84f8536395e4fb89ead5a5d223a5b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de815954edc549ffa4e038c796b27d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f3b9fc4dae54f72b56506267efcd7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da6cf83097344b890c69d750c7f5414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae66312dcf534a30815b21e23a4c48b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61662f2506fb47e6b2a415a4e8476922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "008e92e79f144ffe9e50adf7591df7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5df15942a99247c8a0ba57298ab182ec",
              "IPY_MODEL_b597c70d006946a3a3da913792dc6df0",
              "IPY_MODEL_34402cc7e52a4a0186bb709077b88bf1"
            ],
            "layout": "IPY_MODEL_b2fa49095d2a4cc08d7baee4a29e82bf"
          }
        },
        "5df15942a99247c8a0ba57298ab182ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_405fe12982394fdb995354cb62a343d8",
            "placeholder": "​",
            "style": "IPY_MODEL_81b557b2c8b24790be59fb294e29be63",
            "value": "Train: 100%"
          }
        },
        "b597c70d006946a3a3da913792dc6df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26c888c6935d479f9160f2e8422512d8",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20c645deb0244be99a966a9a81a46d03",
            "value": 111
          }
        },
        "34402cc7e52a4a0186bb709077b88bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d87a25a4c943b98014d1ed87222989",
            "placeholder": "​",
            "style": "IPY_MODEL_29a70762ce2a4c1585e29bc7716f13ca",
            "value": " 111/111 [54:15&lt;00:00, 29.22s/it, acc=42.7%, loss=1.594]"
          }
        },
        "b2fa49095d2a4cc08d7baee4a29e82bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "405fe12982394fdb995354cb62a343d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b557b2c8b24790be59fb294e29be63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26c888c6935d479f9160f2e8422512d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c645deb0244be99a966a9a81a46d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d87a25a4c943b98014d1ed87222989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a70762ce2a4c1585e29bc7716f13ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa066a93ffc440d58892dd66ce950297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47862a4a80a144cda2c299e0f622818f",
              "IPY_MODEL_7cc0866763b541f9bbc4040bc036407a",
              "IPY_MODEL_9d3978a6030c480583003e2a35fb185a"
            ],
            "layout": "IPY_MODEL_df70ab3ce127468ea556f5e21c59c2d1"
          }
        },
        "47862a4a80a144cda2c299e0f622818f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4099cab9d3f469bbbf7e666e81b6785",
            "placeholder": "​",
            "style": "IPY_MODEL_c168b06664524f81893a5557065b653c",
            "value": "Train: 100%"
          }
        },
        "7cc0866763b541f9bbc4040bc036407a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf55206483b4e128c73fec1593cf834",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c512aada8e4743cf984e8732b43b8ca3",
            "value": 111
          }
        },
        "9d3978a6030c480583003e2a35fb185a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13ae57591f54df8a47958159d74c11f",
            "placeholder": "​",
            "style": "IPY_MODEL_25128be083b74385bed26f750836620c",
            "value": " 111/111 [02:01&lt;00:00,  1.06it/s, acc=62.5%, loss=1.067]"
          }
        },
        "df70ab3ce127468ea556f5e21c59c2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a4099cab9d3f469bbbf7e666e81b6785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c168b06664524f81893a5557065b653c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf55206483b4e128c73fec1593cf834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c512aada8e4743cf984e8732b43b8ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f13ae57591f54df8a47958159d74c11f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25128be083b74385bed26f750836620c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787984a206a04d7aaa5c8187f7317c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9edd531925b24d49af1ff8708add9fae",
              "IPY_MODEL_be77f8e124bf4e549b6bfcc19989df8b",
              "IPY_MODEL_3c8da8c9a129415e93a1847bb8d7235b"
            ],
            "layout": "IPY_MODEL_20983d1aab9c4384addeff7fc9206415"
          }
        },
        "9edd531925b24d49af1ff8708add9fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5498873e4bff40b5bb69d4c7cd5fdcdf",
            "placeholder": "​",
            "style": "IPY_MODEL_f5d343eac8e7492a83e52904c17e0353",
            "value": "Train: 100%"
          }
        },
        "be77f8e124bf4e549b6bfcc19989df8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b5d60a3f7c4e818d632a227d76f239",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53d5040d3f054f42b85c52f317039e9f",
            "value": 111
          }
        },
        "3c8da8c9a129415e93a1847bb8d7235b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5880ff438f064bfab7482baf0de69fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_9d4758ac4da741dbae8b4c9d6e8a3944",
            "value": " 111/111 [02:01&lt;00:00,  1.07it/s, acc=70.0%, loss=0.876]"
          }
        },
        "20983d1aab9c4384addeff7fc9206415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5498873e4bff40b5bb69d4c7cd5fdcdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d343eac8e7492a83e52904c17e0353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b5d60a3f7c4e818d632a227d76f239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53d5040d3f054f42b85c52f317039e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5880ff438f064bfab7482baf0de69fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4758ac4da741dbae8b4c9d6e8a3944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c959dc0de0af4dbc827db4d98a44d9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ca57b75cff2449b85eaa0754e412a32",
              "IPY_MODEL_9dd68bba8e7f424bb643a3558f1d724c",
              "IPY_MODEL_a626f9a356034217b63213a597c3a58a"
            ],
            "layout": "IPY_MODEL_2ba674f012444a6cba860bacce608d23"
          }
        },
        "1ca57b75cff2449b85eaa0754e412a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf81aae9b9942a288b52abc1b9ce80b",
            "placeholder": "​",
            "style": "IPY_MODEL_9e953ac9a0cc48f58fcb313a9f0464eb",
            "value": "Train: 100%"
          }
        },
        "9dd68bba8e7f424bb643a3558f1d724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4d5d6e77b94915a6fcbe7909390c96",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d20d25846fc848fda9dbff444faa3ddd",
            "value": 111
          }
        },
        "a626f9a356034217b63213a597c3a58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac93d811d058445e9b59433bfa50eec6",
            "placeholder": "​",
            "style": "IPY_MODEL_67b5f3e2d0074e63ad5faca073feedda",
            "value": " 111/111 [01:57&lt;00:00,  1.14it/s, acc=74.6%, loss=0.766]"
          }
        },
        "2ba674f012444a6cba860bacce608d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "0bf81aae9b9942a288b52abc1b9ce80b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e953ac9a0cc48f58fcb313a9f0464eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f4d5d6e77b94915a6fcbe7909390c96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d20d25846fc848fda9dbff444faa3ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac93d811d058445e9b59433bfa50eec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b5f3e2d0074e63ad5faca073feedda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05f23d2921a1499db93929adb23e5af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d7da04e14274d1599437e7fe2c67bb7",
              "IPY_MODEL_5ae4405e77cc4ddeac343977b2a688d3",
              "IPY_MODEL_3c35240fd1a4485cb94ad4ce09d54f25"
            ],
            "layout": "IPY_MODEL_21e3cecb9f4645b980b84a365ee89845"
          }
        },
        "9d7da04e14274d1599437e7fe2c67bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57532d6c5c0346c4a4c793ec965e8405",
            "placeholder": "​",
            "style": "IPY_MODEL_a6576cad99a54c9fa88f7be3df6dd2a2",
            "value": "Train: 100%"
          }
        },
        "5ae4405e77cc4ddeac343977b2a688d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e178f0105f48869b3c6b4fb11b3fc2",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_554f4878ca2a4cf9b842fcf932d12cf2",
            "value": 111
          }
        },
        "3c35240fd1a4485cb94ad4ce09d54f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_275d9046affb46c7ac7b49e292c208b8",
            "placeholder": "​",
            "style": "IPY_MODEL_5b5ed592f6ef4c3b8af4eb7982f9c310",
            "value": " 111/111 [01:58&lt;00:00,  1.19it/s, acc=78.5%, loss=0.673]"
          }
        },
        "21e3cecb9f4645b980b84a365ee89845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "57532d6c5c0346c4a4c793ec965e8405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6576cad99a54c9fa88f7be3df6dd2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82e178f0105f48869b3c6b4fb11b3fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "554f4878ca2a4cf9b842fcf932d12cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "275d9046affb46c7ac7b49e292c208b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b5ed592f6ef4c3b8af4eb7982f9c310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "721b707a804946fd8ea0a970f9789f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2197dd4b64541ad84798b5b64bec5e8",
              "IPY_MODEL_9353afb621964e858e54f4da6ec20dd4",
              "IPY_MODEL_26b45c536b514ca185b128d8f3cf4451"
            ],
            "layout": "IPY_MODEL_cb58db6f87b942cca3fe9a01ae227a4c"
          }
        },
        "f2197dd4b64541ad84798b5b64bec5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b459e925236b48e9983b29fa919e41c7",
            "placeholder": "​",
            "style": "IPY_MODEL_70e0452f257d4e2a9f68b128a0170654",
            "value": "Train: 100%"
          }
        },
        "9353afb621964e858e54f4da6ec20dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3553dab7464c4de3a98a613a7d2a75fc",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45e4dc7dbcc4407ba9a385f9510a39aa",
            "value": 111
          }
        },
        "26b45c536b514ca185b128d8f3cf4451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a984e5984824cde938157ad67eaba3a",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a97585605c4490877f2d579f0b3bb3",
            "value": " 111/111 [01:58&lt;00:00,  1.12it/s, acc=79.4%, loss=0.626]"
          }
        },
        "cb58db6f87b942cca3fe9a01ae227a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b459e925236b48e9983b29fa919e41c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e0452f257d4e2a9f68b128a0170654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3553dab7464c4de3a98a613a7d2a75fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e4dc7dbcc4407ba9a385f9510a39aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a984e5984824cde938157ad67eaba3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a97585605c4490877f2d579f0b3bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d7334f0d5f4f17ac1ddd0082f0b42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d35c9f493e0d4fc9b2620cfb24d23b77",
              "IPY_MODEL_5f3e8f2e4e6e4ef29a0b1216bb1fd2f5",
              "IPY_MODEL_9850a83df19e43a69b394b47d4b36e02"
            ],
            "layout": "IPY_MODEL_aaccd54be9854efa86fe0e664a7e18c5"
          }
        },
        "d35c9f493e0d4fc9b2620cfb24d23b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1c655654c942a5bc969f4470115979",
            "placeholder": "​",
            "style": "IPY_MODEL_d5b0d5c820a74911955bd40a46875bcd",
            "value": "Train: 100%"
          }
        },
        "5f3e8f2e4e6e4ef29a0b1216bb1fd2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4948d1d2e084ea8a3abf51b08245fe7",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5daf3b85df74f86a10c48a4d3796aaf",
            "value": 111
          }
        },
        "9850a83df19e43a69b394b47d4b36e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e25a40cfbc0c40e2b8760a6b9fe768b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b4f3b0bac3f646ab99de21e7aa2f521a",
            "value": " 111/111 [01:59&lt;00:00,  1.08it/s, acc=82.0%, loss=0.560]"
          }
        },
        "aaccd54be9854efa86fe0e664a7e18c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1a1c655654c942a5bc969f4470115979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b0d5c820a74911955bd40a46875bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4948d1d2e084ea8a3abf51b08245fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5daf3b85df74f86a10c48a4d3796aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e25a40cfbc0c40e2b8760a6b9fe768b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f3b0bac3f646ab99de21e7aa2f521a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b23d8776208946568717205be1b07344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62aaec92ffe74c5fa51f88fadea5cf0c",
              "IPY_MODEL_a098f0a634d8448392a7515c08aead4d",
              "IPY_MODEL_a40c3e6b6170484eb201efb3be3759f2"
            ],
            "layout": "IPY_MODEL_e9c51cc5a16a4ec99a3bbd022c05e21e"
          }
        },
        "62aaec92ffe74c5fa51f88fadea5cf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893be78917ca47c386d7e46a37a63587",
            "placeholder": "​",
            "style": "IPY_MODEL_b3f6f6fb938340f3b67c6e18ce0bab0f",
            "value": "Train: 100%"
          }
        },
        "a098f0a634d8448392a7515c08aead4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa7bee217af4c6f94247aba855b5e8c",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abd1ac98679648b7964d44b5eedea196",
            "value": 111
          }
        },
        "a40c3e6b6170484eb201efb3be3759f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df2a08ac17784b11a2e6383623f48c4c",
            "placeholder": "​",
            "style": "IPY_MODEL_562850f9790d42c29bc1e2ec82323784",
            "value": " 111/111 [01:59&lt;00:00,  1.19it/s, acc=82.4%, loss=0.546]"
          }
        },
        "e9c51cc5a16a4ec99a3bbd022c05e21e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "893be78917ca47c386d7e46a37a63587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f6f6fb938340f3b67c6e18ce0bab0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfa7bee217af4c6f94247aba855b5e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd1ac98679648b7964d44b5eedea196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df2a08ac17784b11a2e6383623f48c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "562850f9790d42c29bc1e2ec82323784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a22dc88c7ae646b9b4c63ac7b1c3445c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d5e64d229084b3eb4e7626caf08d567",
              "IPY_MODEL_1cf47c842fb64a79aeaa316c86ecc6c9",
              "IPY_MODEL_95add7f109c749dea5a3cfc24200e45f"
            ],
            "layout": "IPY_MODEL_6a6861ee50f749788b2f6f91f7083aac"
          }
        },
        "6d5e64d229084b3eb4e7626caf08d567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a08e2518912408bba4879e14a52e377",
            "placeholder": "​",
            "style": "IPY_MODEL_d346147233124375b7777cf230f7cc1d",
            "value": "Train: 100%"
          }
        },
        "1cf47c842fb64a79aeaa316c86ecc6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c0ff40678f4341b45d123f26b574f3",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9030593e8b5a41ec87655da22e1304b1",
            "value": 111
          }
        },
        "95add7f109c749dea5a3cfc24200e45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_727dac18199d4626923670d7b2e1a8a7",
            "placeholder": "​",
            "style": "IPY_MODEL_b54a1ee9c2fa415d93cd13aa871c1df1",
            "value": " 111/111 [01:52&lt;00:00,  1.16it/s, acc=85.1%, loss=0.469]"
          }
        },
        "6a6861ee50f749788b2f6f91f7083aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2a08e2518912408bba4879e14a52e377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d346147233124375b7777cf230f7cc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c0ff40678f4341b45d123f26b574f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9030593e8b5a41ec87655da22e1304b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "727dac18199d4626923670d7b2e1a8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54a1ee9c2fa415d93cd13aa871c1df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b12b0a9db5e4d12bf818e296a97c460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dbfcb252ba3499e92d356ad0c9d5586",
              "IPY_MODEL_b2f4a0330b494b52b3073a2cb93529ba",
              "IPY_MODEL_a50b3afe5ef24cecb8e8d2698404d327"
            ],
            "layout": "IPY_MODEL_5f997aa363b64c26aeec717ccd665c93"
          }
        },
        "5dbfcb252ba3499e92d356ad0c9d5586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45634c6d93c34b128d668bdbacbd5dda",
            "placeholder": "​",
            "style": "IPY_MODEL_7d6c7cb6480e4cf0aca2475620f1c54b",
            "value": "Train: 100%"
          }
        },
        "b2f4a0330b494b52b3073a2cb93529ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a69ba2a316d4c28a6ab8c75d2bc7461",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1abb09e799544e1489e7ff4a9cd457ae",
            "value": 111
          }
        },
        "a50b3afe5ef24cecb8e8d2698404d327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89eca1fa94ae4738a7ce3267d24f1d32",
            "placeholder": "​",
            "style": "IPY_MODEL_93cba5c229c740b586b63a9593e63884",
            "value": " 111/111 [01:52&lt;00:00,  1.15it/s, acc=85.9%, loss=0.438]"
          }
        },
        "5f997aa363b64c26aeec717ccd665c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "45634c6d93c34b128d668bdbacbd5dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d6c7cb6480e4cf0aca2475620f1c54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a69ba2a316d4c28a6ab8c75d2bc7461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abb09e799544e1489e7ff4a9cd457ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89eca1fa94ae4738a7ce3267d24f1d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cba5c229c740b586b63a9593e63884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4295e11c79794e568b6ad04d8e304ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b042de611c44f7faaecbf4733356983",
              "IPY_MODEL_626dd984af294b78b4c43d2182bd9bc7",
              "IPY_MODEL_9fe83b9c33934b028feb8201eff10061"
            ],
            "layout": "IPY_MODEL_efed1c8ce5f94a5ca34b321dfec31902"
          }
        },
        "5b042de611c44f7faaecbf4733356983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc67de7987a4281ae48742ba8e5e092",
            "placeholder": "​",
            "style": "IPY_MODEL_cc76f568a6434635910c599ddcf61678",
            "value": "Train: 100%"
          }
        },
        "626dd984af294b78b4c43d2182bd9bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628cfad3988d4e5cb8dca0a777e20606",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd7d76c45568436c8e67ac7f514b2762",
            "value": 111
          }
        },
        "9fe83b9c33934b028feb8201eff10061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcc25e2d3b447398bc8730aca7dc6bb",
            "placeholder": "​",
            "style": "IPY_MODEL_5c751862e07849749f4a3806c6584c39",
            "value": " 111/111 [01:55&lt;00:00,  1.02it/s, acc=87.1%, loss=0.403]"
          }
        },
        "efed1c8ce5f94a5ca34b321dfec31902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2fc67de7987a4281ae48742ba8e5e092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc76f568a6434635910c599ddcf61678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "628cfad3988d4e5cb8dca0a777e20606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7d76c45568436c8e67ac7f514b2762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dcc25e2d3b447398bc8730aca7dc6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c751862e07849749f4a3806c6584c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ccbf6b6e5ce4977bf532f2c4e32e92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e6a02e5290b43f3a55ee6be4462c022",
              "IPY_MODEL_d17eea7022f44372a20af19df63bc19e",
              "IPY_MODEL_dbe79eb3587246409d96e5d616deac94"
            ],
            "layout": "IPY_MODEL_9501dcfe0bf54281be4b68822c6a43a1"
          }
        },
        "3e6a02e5290b43f3a55ee6be4462c022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7c3713855f493a872db13716a16e45",
            "placeholder": "​",
            "style": "IPY_MODEL_6a0fa9abb8a549658384edf6b6c11950",
            "value": "Train: 100%"
          }
        },
        "d17eea7022f44372a20af19df63bc19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b9a5507d3e4bffb80b52991b13ae5c",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a0c502ab46d4e618196da7970b1b35c",
            "value": 111
          }
        },
        "dbe79eb3587246409d96e5d616deac94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9c573d9c9aa4b9d885083f16912d30b",
            "placeholder": "​",
            "style": "IPY_MODEL_e429cf109a4744b09a70df57f2fa3fa6",
            "value": " 111/111 [01:56&lt;00:00,  1.01it/s, acc=87.5%, loss=0.384]"
          }
        },
        "9501dcfe0bf54281be4b68822c6a43a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ae7c3713855f493a872db13716a16e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0fa9abb8a549658384edf6b6c11950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b9a5507d3e4bffb80b52991b13ae5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0c502ab46d4e618196da7970b1b35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9c573d9c9aa4b9d885083f16912d30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e429cf109a4744b09a70df57f2fa3fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d6f7bc2d80a4d16bcadecc6f293de2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3580801943549a0b333183846b689d5",
              "IPY_MODEL_d4b3b249cd8c42e4a4724a5838ff5f7f",
              "IPY_MODEL_9eb11cb83c0c4da5b6a03ab2fc21670c"
            ],
            "layout": "IPY_MODEL_928cff03cfa5463eac543d23886bb4a9"
          }
        },
        "b3580801943549a0b333183846b689d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e628bb468a409e8678547b7edd10f7",
            "placeholder": "​",
            "style": "IPY_MODEL_5e316c02277a4237b417505ab9481339",
            "value": "Train: 100%"
          }
        },
        "d4b3b249cd8c42e4a4724a5838ff5f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea6c2ed7449487691e3417ccd7ba02b",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1fc0c136e3d44cdaddc3bb09451137e",
            "value": 111
          }
        },
        "9eb11cb83c0c4da5b6a03ab2fc21670c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3047b5220c3a4e9b9a09868c81a85378",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8775d46c34430794f5aa05cf30847b",
            "value": " 111/111 [01:58&lt;00:00,  1.13it/s, acc=88.0%, loss=0.374]"
          }
        },
        "928cff03cfa5463eac543d23886bb4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "35e628bb468a409e8678547b7edd10f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e316c02277a4237b417505ab9481339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dea6c2ed7449487691e3417ccd7ba02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fc0c136e3d44cdaddc3bb09451137e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3047b5220c3a4e9b9a09868c81a85378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac8775d46c34430794f5aa05cf30847b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebbf7cfe603d40af9ee8bff7a04e9d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd8d3d0134684b29a8c5200effbeb555",
              "IPY_MODEL_d91982959dda4cbeaf4b2e1e2b6a4def",
              "IPY_MODEL_15d2779279934cf3a1b587a81b65d5c6"
            ],
            "layout": "IPY_MODEL_f563bac06dff4524acac9dc7fc483d1f"
          }
        },
        "dd8d3d0134684b29a8c5200effbeb555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76c971325cb4d3f95c7e55a7eb034ad",
            "placeholder": "​",
            "style": "IPY_MODEL_41e69f67ad6a4b5fad19aab71b10241d",
            "value": "Train: 100%"
          }
        },
        "d91982959dda4cbeaf4b2e1e2b6a4def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba1d0a3476a436086444daa1983f62e",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55c6d31fb96f4308ad2d4d572d8a04fb",
            "value": 111
          }
        },
        "15d2779279934cf3a1b587a81b65d5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075fc1d655ca4db799a4dbf04c31c3f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a184084c81f84d408d0eb57f7c4b84a4",
            "value": " 111/111 [02:00&lt;00:00,  1.14it/s, acc=88.9%, loss=0.348]"
          }
        },
        "f563bac06dff4524acac9dc7fc483d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d76c971325cb4d3f95c7e55a7eb034ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e69f67ad6a4b5fad19aab71b10241d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ba1d0a3476a436086444daa1983f62e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c6d31fb96f4308ad2d4d572d8a04fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "075fc1d655ca4db799a4dbf04c31c3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a184084c81f84d408d0eb57f7c4b84a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "245834d3e79a42538cd7f4d7f31a5810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7d644c18c224c219c73cb07a2dbbd73",
              "IPY_MODEL_ec2f91426b1b424c92379077ff14ccb0",
              "IPY_MODEL_89b4f97be8c14187a66a739cbf31f67f"
            ],
            "layout": "IPY_MODEL_74de70aab5fc4aca83634d261a14988a"
          }
        },
        "c7d644c18c224c219c73cb07a2dbbd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca0d9da85fe4105b1e623d86b22cba7",
            "placeholder": "​",
            "style": "IPY_MODEL_701722d18e5c42eb8b52d0bedd492f3b",
            "value": "Train: 100%"
          }
        },
        "ec2f91426b1b424c92379077ff14ccb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0988a6f879634853aacfc11d177e909a",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60afe56c172d43cf8b769c9db1951a27",
            "value": 111
          }
        },
        "89b4f97be8c14187a66a739cbf31f67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed5ff81cfd24049aeef8c129e2774ab",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f554503e1447c7a1dab6c05180a4a7",
            "value": " 111/111 [02:01&lt;00:00,  1.12it/s, acc=89.3%, loss=0.333]"
          }
        },
        "74de70aab5fc4aca83634d261a14988a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7ca0d9da85fe4105b1e623d86b22cba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701722d18e5c42eb8b52d0bedd492f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0988a6f879634853aacfc11d177e909a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60afe56c172d43cf8b769c9db1951a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ed5ff81cfd24049aeef8c129e2774ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f554503e1447c7a1dab6c05180a4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96da132e31e74631aca5234ab4c366e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce49cdc11371480396fbf32dd8bfca73",
              "IPY_MODEL_9cd856fef40347f3ab1011b7bd307828",
              "IPY_MODEL_c67637b43ad246aca63e8c4a1b05937e"
            ],
            "layout": "IPY_MODEL_8f56833a2306415a91a2353ee04805b2"
          }
        },
        "ce49cdc11371480396fbf32dd8bfca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6146087b5b974cf4b7152a012ce1efb4",
            "placeholder": "​",
            "style": "IPY_MODEL_2e85c59a47674c34b0253a72fb8423a9",
            "value": "Train: 100%"
          }
        },
        "9cd856fef40347f3ab1011b7bd307828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b51e6351f14cf0915da5e39daec94a",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ee75f79e4924701bf6adf93e6dfec02",
            "value": 111
          }
        },
        "c67637b43ad246aca63e8c4a1b05937e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d9a9129dbef4fe1be4f0e98eb3e767f",
            "placeholder": "​",
            "style": "IPY_MODEL_d4dbe58139cf435bb86bff20614ea8ad",
            "value": " 111/111 [02:04&lt;00:00,  1.06it/s, acc=89.1%, loss=0.325]"
          }
        },
        "8f56833a2306415a91a2353ee04805b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6146087b5b974cf4b7152a012ce1efb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e85c59a47674c34b0253a72fb8423a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73b51e6351f14cf0915da5e39daec94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee75f79e4924701bf6adf93e6dfec02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d9a9129dbef4fe1be4f0e98eb3e767f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4dbe58139cf435bb86bff20614ea8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ed313250b343128733cf4a3eebfe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_823e87fd53d0482fb8f4fd43d81b2195",
              "IPY_MODEL_f565f693ce2b44a8872a25445b799f19",
              "IPY_MODEL_7b129cfeed6a4dd8b9516548d8752bf4"
            ],
            "layout": "IPY_MODEL_d30d0908cdcf48d69403006fc4d798f3"
          }
        },
        "823e87fd53d0482fb8f4fd43d81b2195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbdb400f13ff4ae29a985ed33e03edfe",
            "placeholder": "​",
            "style": "IPY_MODEL_a03d5318e8cd4de7b82721d7ac78c421",
            "value": "Train: 100%"
          }
        },
        "f565f693ce2b44a8872a25445b799f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef65bfe4a3db4a41908094f4d9766dba",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee39b6239d7c4a41b3f619d6f1440484",
            "value": 111
          }
        },
        "7b129cfeed6a4dd8b9516548d8752bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8485c359b94e87bba0a8089e2dea9b",
            "placeholder": "​",
            "style": "IPY_MODEL_7b1f2881f1d44e37866683ee137cd0d3",
            "value": " 111/111 [02:04&lt;00:00,  1.09it/s, acc=89.4%, loss=0.317]"
          }
        },
        "d30d0908cdcf48d69403006fc4d798f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "dbdb400f13ff4ae29a985ed33e03edfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03d5318e8cd4de7b82721d7ac78c421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef65bfe4a3db4a41908094f4d9766dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee39b6239d7c4a41b3f619d6f1440484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af8485c359b94e87bba0a8089e2dea9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1f2881f1d44e37866683ee137cd0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiiLeL_Xt3Nm",
        "outputId": "5e7d870d-5925-41de-c20b-5327a6f7b06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths in Google Drive\n",
        "DATASET_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "CSV_PATH     = DATASET_PATH + \"/UrbanSound8K.csv\"\n",
        "\n",
        "# Your saved models\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs\"\n",
        "FINAL_MODEL_PATH = OUTPUT_PATH + \"/final_hybrid_cnn_qnn_model.pth\"\n",
        "BEST_MODEL_PATH  = OUTPUT_PATH + \"/hybrid_cnn_qnn_best.pth\"\n",
        "\n",
        "print(DATASET_PATH)\n",
        "print(CSV_PATH)\n",
        "print(FINAL_MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeS_3xosuB88",
        "outputId": "f9fc57d3-927e-416b-98c2-16540615ba25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/kaggle/audio_leo_datasets\n",
            "/content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\n",
            "/content/drive/MyDrive/kaggle/audio_leo_outputs/final_hybrid_cnn_qnn_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pennylane pennylane-lightning[gpu] librosa soundfile torchaudio matplotlib seaborn tqdm gradio\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psbrc3pDuHK9",
        "outputId": "1a2339b9-06f3-43c3-81d7-a8a8c8076994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m142.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m911.3/911.3 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q74mtirquOlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "chrisfilo_urbansound8k_path = kagglehub.dataset_download('chrisfilo/urbansound8k')\n",
        "leoashi_audio_leo_path = kagglehub.notebook_output_download('leoashi/audio-leo')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "liAw3SmGtkzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here zero"
      ],
      "metadata": {
        "id": "zIMMQMXWtkzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane pennylane-lightning\n",
        "!pip install librosa soundfile\n",
        "!pip install torchaudio\n",
        "!pip install audiomentations\n",
        "!pip install matplotlib seaborn tqdm\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:13:35.550417Z",
          "iopub.execute_input": "2025-11-29T10:13:35.55096Z",
          "iopub.status.idle": "2025-11-29T10:16:01.830474Z",
          "shell.execute_reply.started": "2025-11-29T10:13:35.550935Z",
          "shell.execute_reply": "2025-11-29T10:16:01.82931Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "collapsed": true,
        "id": "d3CIWoNktkzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2041844-22b1-476c-efad-fb5c8a37cb6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.12/dist-packages (0.43.1)\n",
            "Requirement already satisfied: pennylane-lightning in /usr/local/lib/python3.12/dist-packages (0.43.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.17.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray==0.8.0 in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.8.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.12/dist-packages (from pennylane-lightning) (0.3.30.0.8)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.11.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchaudio) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchaudio) (3.0.3)\n",
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (2.0.2)\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.12.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (0.11.0)\n",
            "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
            "  Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4 in /usr/local/lib/python3.12/dist-packages (from audiomentations) (1.16.3)\n",
            "Collecting soxr<1.0.0,>=0.3.2 (from audiomentations)\n",
            "  Downloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2025.11.12)\n",
            "Downloading audiomentations-0.43.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18 kB)\n",
            "Downloading python_stretch-0.3.1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.5/248.5 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: soxr, python-stretch, numpy-rms, numpy-minmax, audiomentations\n",
            "  Attempting uninstall: soxr\n",
            "    Found existing installation: soxr 1.0.0\n",
            "    Uninstalling soxr-1.0.0:\n",
            "      Successfully uninstalled soxr-1.0.0\n",
            "Successfully installed audiomentations-0.43.1 numpy-minmax-0.5.0 numpy-rms-0.6.0 python-stretch-0.3.1 soxr-0.5.0.post1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pennylane-lightning[gpu]\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:01.83254Z",
          "iopub.execute_input": "2025-11-29T10:16:01.832864Z",
          "iopub.status.idle": "2025-11-29T10:16:07.535218Z",
          "shell.execute_reply.started": "2025-11-29T10:16:01.832832Z",
          "shell.execute_reply": "2025-11-29T10:16:07.534517Z"
        },
        "id": "HJ9iSde3tkzP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports\n",
        "\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Optional: if torchaudio is available (Kaggle usually has it)\n",
        "try:\n",
        "    import torchaudio\n",
        "    from torchaudio import transforms as T\n",
        "    HAS_TORCHAUDIO = True\n",
        "except ImportError:\n",
        "    HAS_TORCHAUDIO = False\n",
        "    print(\"torchaudio not found. Please install torchaudio for audio processing.\")\n",
        "\n",
        "# PennyLane for quantum layers\n",
        "import pennylane as qml\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"PennyLane version:\", qml.__version__)\n",
        "print(\"Has torchaudio:\", HAS_TORCHAUDIO)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:07.536454Z",
          "iopub.execute_input": "2025-11-29T10:16:07.536706Z",
          "iopub.status.idle": "2025-11-29T10:16:12.530741Z",
          "shell.execute_reply.started": "2025-11-29T10:16:07.53668Z",
          "shell.execute_reply": "2025-11-29T10:16:12.530112Z"
        },
        "id": "1mP8ymZitkzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76998f70-de99-4066-d84f-e8bd840620a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.9.0+cu126\n",
            "PennyLane version: 0.43.1\n",
            "Has torchaudio: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Device selection (GPU if available, else CPU)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch_device = torch.device(\"cuda\")\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "else:\n",
        "    torch_device = torch.device(\"cpu\")\n",
        "    device_name = \"CPU\"\n",
        "\n",
        "print(f\"Torch device: {torch_device} ({device_name})\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.5324Z",
          "iopub.execute_input": "2025-11-29T10:16:12.532824Z",
          "iopub.status.idle": "2025-11-29T10:16:12.649451Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.532804Z",
          "shell.execute_reply": "2025-11-29T10:16:12.648837Z"
        },
        "id": "hyqadSGFtkzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1444d26-4775-402c-b6bb-af4581320e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda (Tesla T4)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Global config and reproducibility\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS_BASELINE = 5  # we can increase later\n",
        "NUM_CLASSES = 10         # UrbanSound8K has 10 target classes\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(RANDOM_SEED)\n",
        "\n",
        "print(\"Random seed set to:\", RANDOM_SEED)\n",
        "print(\"Batch size:\", BATCH_SIZE)\n",
        "print(\"Learning rate:\", LEARNING_RATE)\n",
        "print(\"Epochs (baseline):\", NUM_EPOCHS_BASELINE)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.650128Z",
          "iopub.execute_input": "2025-11-29T10:16:12.65041Z",
          "iopub.status.idle": "2025-11-29T10:16:12.664208Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.65039Z",
          "shell.execute_reply": "2025-11-29T10:16:12.66351Z"
        },
        "id": "4xpY8xgPtkzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"GPU Count:\", torch.cuda.device_count())\n",
        "    print(\"Torch device:\", torch.device(\"cuda\"))\n",
        "else:\n",
        "    print(\"Running on CPU\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.664968Z",
          "iopub.execute_input": "2025-11-29T10:16:12.665386Z",
          "iopub.status.idle": "2025-11-29T10:16:12.674242Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.665369Z",
          "shell.execute_reply": "2025-11-29T10:16:12.673571Z"
        },
        "id": "9vHDG0ratkzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/kaggle/input\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:22:10.590559Z",
          "iopub.execute_input": "2025-11-28T20:22:10.590817Z",
          "iopub.status.idle": "2025-11-28T20:22:10.601819Z",
          "shell.execute_reply.started": "2025-11-28T20:22:10.590796Z",
          "shell.execute_reply": "2025-11-28T20:22:10.601097Z"
        },
        "id": "rI-ov5mntkzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 (fixed): Detect correct UrbanSound8K structure\n",
        "\n",
        "DATA_ROOT = \"/kaggle/input/urbansound8k\"\n",
        "\n",
        "# CASE 1 — Standard structure (metadata/ + audio/)\n",
        "csv_path_1 = os.path.join(DATA_ROOT, \"metadata\", \"UrbanSound8K.csv\")\n",
        "audio_root_1 = os.path.join(DATA_ROOT, \"audio\")\n",
        "\n",
        "# CASE 2 — Flat structure (CSV + folds directly inside root)\n",
        "csv_path_2 = os.path.join(DATA_ROOT, \"UrbanSound8K.csv\")\n",
        "fold1_path  = os.path.join(DATA_ROOT, \"fold1\")\n",
        "\n",
        "# Logic to detect which one is present\n",
        "if os.path.exists(csv_path_1) and os.path.exists(audio_root_1):\n",
        "    print(\"Detected standard UrbanSound8K structure.\")\n",
        "    METADATA_CSV = csv_path_1\n",
        "    AUDIO_ROOT   = audio_root_1\n",
        "\n",
        "elif os.path.exists(csv_path_2):\n",
        "    print(\"Detected flat UrbanSound8K structure.\")\n",
        "    METADATA_CSV = csv_path_2\n",
        "    AUDIO_ROOT   = DATA_ROOT  # folds are directly here\n",
        "\n",
        "else:\n",
        "    raise FileNotFoundError(\"Could not detect UrbanSound8K structure.\")# Cell 5: Audio + spectrogram hyperparameters\n",
        "\n",
        "SAMPLE_RATE = 16000       # we will resample all audio to this\n",
        "DURATION    = 4.0         # seconds; UrbanSound8K clips are <= 4s\n",
        "NUM_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
        "\n",
        "N_MELS      = 64          # number of Mel bands\n",
        "N_FFT       = 1024\n",
        "HOP_LENGTH  = 512\n",
        "\n",
        "print(\"Sample rate:\", SAMPLE_RATE)\n",
        "print(\"Target duration (s):\", DURATION)\n",
        "print(\"Target samples per clip:\", NUM_SAMPLES)\n",
        "print(\"Mel bins:\", N_MELS)\n",
        "\n",
        "\n",
        "print(\"METADATA_CSV:\", METADATA_CSV)\n",
        "print(\"AUDIO_ROOT:\", AUDIO_ROOT)\n",
        "print(\"CSV exists:\", os.path.exists(METADATA_CSV))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.674867Z",
          "iopub.execute_input": "2025-11-29T10:16:12.675624Z",
          "iopub.status.idle": "2025-11-29T10:16:12.706987Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.6756Z",
          "shell.execute_reply": "2025-11-29T10:16:12.706445Z"
        },
        "id": "bk98dDP8tkzR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Audio + spectrogram hyperparameters\n",
        "\n",
        "SAMPLE_RATE = 16000       # we will resample all audio to this\n",
        "DURATION    = 4.0         # seconds; UrbanSound8K clips are <= 4s\n",
        "NUM_SAMPLES = int(SAMPLE_RATE * DURATION)\n",
        "\n",
        "N_MELS      = 64          # number of Mel bands\n",
        "N_FFT       = 1024\n",
        "HOP_LENGTH  = 512\n",
        "\n",
        "print(\"Sample rate:\", SAMPLE_RATE)\n",
        "print(\"Target duration (s):\", DURATION)\n",
        "print(\"Target samples per clip:\", NUM_SAMPLES)\n",
        "print(\"Mel bins:\", N_MELS)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.70764Z",
          "iopub.execute_input": "2025-11-29T10:16:12.707865Z",
          "iopub.status.idle": "2025-11-29T10:16:12.712925Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.707845Z",
          "shell.execute_reply": "2025-11-29T10:16:12.7124Z"
        },
        "id": "7VZrWxmItkzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Audio loading and log-Mel spectrogram transform\n",
        "\n",
        "import librosa\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def load_audio(path, target_sr=SAMPLE_RATE):\n",
        "    \"\"\"Load audio file and return mono waveform tensor at target_sr.\"\"\"\n",
        "    if HAS_TORCHAUDIO:\n",
        "        waveform, sr = torchaudio.load(path)  # (channels, samples)\n",
        "        # convert to mono by averaging channels if needed\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "        if sr != target_sr:\n",
        "            resampler = T.Resample(orig_freq=sr, new_freq=target_sr)\n",
        "            waveform = resampler(waveform)\n",
        "        return waveform.squeeze(0), target_sr  # (samples,), sr\n",
        "    else:\n",
        "        # librosa fallback\n",
        "        y, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "        return torch.tensor(y, dtype=torch.float32), target_sr\n",
        "\n",
        "def pad_or_trim(waveform, num_samples=NUM_SAMPLES):\n",
        "    \"\"\"Pad with zeros or trim to a fixed number of samples.\"\"\"\n",
        "    length = waveform.shape[-1]\n",
        "    if length < num_samples:\n",
        "        pad_amount = num_samples - length\n",
        "        waveform = F.pad(waveform, (0, pad_amount))\n",
        "    elif length > num_samples:\n",
        "        waveform = waveform[:num_samples]\n",
        "    return waveform\n",
        "\n",
        "# Pre-build a MelSpectrogram transform if torchaudio is available\n",
        "if HAS_TORCHAUDIO:\n",
        "    mel_transform = T.MelSpectrogram(\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "else:\n",
        "    mel_transform = None  # we'll use librosa.melspectrogram later if needed\n",
        "\n",
        "def waveform_to_logmel(waveform):\n",
        "    \"\"\"Convert 1D waveform tensor -> log-Mel spectrogram tensor [1, n_mels, time].\"\"\"\n",
        "    waveform = waveform.unsqueeze(0)  # [1, samples]\n",
        "    if HAS_TORCHAUDIO and mel_transform is not None:\n",
        "        mel = mel_transform(waveform)  # [1, n_mels, time]\n",
        "        mel = torch.clamp(mel, min=1e-9).log()\n",
        "        return mel\n",
        "    else:\n",
        "        # librosa fallback\n",
        "        y = waveform.squeeze(0).cpu().numpy()\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=y,\n",
        "            sr=SAMPLE_RATE,\n",
        "            n_fft=N_FFT,\n",
        "            hop_length=HOP_LENGTH,\n",
        "            n_mels=N_MELS,\n",
        "        )\n",
        "        mel = np.log(np.clip(mel, a_min=1e-9, a_max=None))\n",
        "        mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)  # [1, n_mels, time]\n",
        "        return mel\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.7136Z",
          "iopub.execute_input": "2025-11-29T10:16:12.71404Z",
          "iopub.status.idle": "2025-11-29T10:16:12.804256Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.714017Z",
          "shell.execute_reply": "2025-11-29T10:16:12.803669Z"
        },
        "id": "KN0IAZd2tkzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: UrbanSoundDataset class\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, csv_path, audio_root, folds=[1], transform=None):\n",
        "        \"\"\"\n",
        "        csv_path: path to UrbanSound8K.csv\n",
        "        audio_root: folder where fold1/, fold2/, ... exist\n",
        "        folds: list of fold numbers to include (e.g. [1,2,3,4])\n",
        "        transform: function to apply to waveform (e.g., log-Mel)\n",
        "        \"\"\"\n",
        "        self.meta = pd.read_csv(csv_path)\n",
        "        self.audio_root = audio_root\n",
        "        self.folds = folds\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter rows by fold list\n",
        "        self.meta = self.meta[self.meta['fold'].isin(folds)]\n",
        "        self.meta = self.meta.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.meta.iloc[idx]\n",
        "\n",
        "        fold = f\"fold{row['fold']}\"\n",
        "        file_path = os.path.join(self.audio_root, fold, row['slice_file_name'])\n",
        "\n",
        "        label = int(row['classID'])\n",
        "\n",
        "        # Load audio\n",
        "        waveform, sr = load_audio(file_path)\n",
        "\n",
        "        # Fix length\n",
        "        waveform = pad_or_trim(waveform)\n",
        "\n",
        "        # Transform to log-Mel if provided\n",
        "        if self.transform:\n",
        "            mel = self.transform(waveform)\n",
        "            return mel, label\n",
        "\n",
        "        # Otherwise return raw waveform\n",
        "        return waveform, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.80694Z",
          "iopub.execute_input": "2025-11-29T10:16:12.807132Z",
          "iopub.status.idle": "2025-11-29T10:16:12.81379Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.807117Z",
          "shell.execute_reply": "2025-11-29T10:16:12.813022Z"
        },
        "id": "O1N6uhkUtkzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Test dataset with a single sample\n",
        "\n",
        "# use fold 1 only for testing\n",
        "test_dataset = UrbanSoundDataset(\n",
        "    csv_path=METADATA_CSV,\n",
        "    audio_root=AUDIO_ROOT,\n",
        "    folds=[1],\n",
        "    transform=waveform_to_logmel\n",
        ")\n",
        "\n",
        "mel, label = test_dataset[0]\n",
        "\n",
        "print(\"Mel shape:\", mel.shape)   # expect [1, N_MELS, time_frames]\n",
        "print(\"Label:\", label)\n",
        "print(\"Time frames (mel width):\", mel.shape[-1])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:18:53.128404Z",
          "iopub.execute_input": "2025-11-28T20:18:53.128894Z",
          "iopub.status.idle": "2025-11-28T20:18:53.306196Z",
          "shell.execute_reply.started": "2025-11-28T20:18:53.12887Z",
          "shell.execute_reply": "2025-11-28T20:18:53.305517Z"
        },
        "id": "pnFnMlvrtkzS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 (REPLACE): Lighter train and validation datasets\n",
        "\n",
        "# Use fewer folds to speed up training\n",
        "train_folds = [1, 2, 3, 4]   # was [1..8]\n",
        "val_folds   = [5]            # was [9]\n",
        "\n",
        "train_dataset = UrbanSoundDataset(\n",
        "    csv_path=METADATA_CSV,\n",
        "    audio_root=AUDIO_ROOT,\n",
        "    folds=train_folds,\n",
        "    transform=waveform_to_logmel\n",
        ")\n",
        "\n",
        "val_dataset = UrbanSoundDataset(\n",
        "    csv_path=METADATA_CSV,\n",
        "    audio_root=AUDIO_ROOT,\n",
        "    folds=val_folds,\n",
        "    transform=waveform_to_logmel\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Val samples:\", len(val_dataset))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.81449Z",
          "iopub.execute_input": "2025-11-29T10:16:12.814733Z",
          "iopub.status.idle": "2025-11-29T10:16:12.907051Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.814716Z",
          "shell.execute_reply": "2025-11-29T10:16:12.906264Z"
        },
        "id": "EYsvom8utkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 (REPLACE): DataLoaders for new train/val splits\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Quick check\n",
        "mel_batch, label_batch = next(iter(train_loader))\n",
        "print(\"Batch mel shape:\", mel_batch.shape)\n",
        "print(\"Batch labels shape:\", label_batch.shape)\n",
        "print(\"Example label:\", label_batch[0].item())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:18:57.912913Z",
          "iopub.execute_input": "2025-11-28T20:18:57.913479Z",
          "iopub.status.idle": "2025-11-28T20:18:57.930515Z",
          "shell.execute_reply.started": "2025-11-28T20:18:57.913453Z",
          "shell.execute_reply": "2025-11-28T20:18:57.92959Z"
        },
        "id": "aqEC0GzctkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Audio CNN backbone + baseline classifier\n",
        "\n",
        "class AudioCNNBackbone(nn.Module):\n",
        "    def __init__(self, in_channels=1):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 16, 32, ~63]\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 32, 16, ~31]\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 64, 8,  ~15]\n",
        "        )\n",
        "\n",
        "        # Make output feature size independent of exact time dimension\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # -> [B, 64, 1, 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = torch.flatten(x, 1)  # [B, 64]\n",
        "        return x  # embedding\n",
        "\n",
        "\n",
        "class BaselineAudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, in_channels=1):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackbone(in_channels=in_channels)\n",
        "        self.classifier = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, 64, T]\n",
        "        features = self.backbone(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Instantiate model and move to device\n",
        "baseline_model = BaselineAudioCNN(num_classes=NUM_CLASSES).to(torch_device)\n",
        "\n",
        "total_params = sum(p.numel() for p in baseline_model.parameters() if p.requires_grad)\n",
        "print(baseline_model)\n",
        "print(f\"Trainable parameters: {total_params:,}\")\n",
        "# Cell 12: Training and evaluation functions\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for mel, labels in dataloader:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for mel, labels in dataloader:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:39:28.428704Z",
          "iopub.execute_input": "2025-11-27T13:39:28.428968Z",
          "iopub.status.idle": "2025-11-27T13:39:28.450526Z",
          "shell.execute_reply.started": "2025-11-27T13:39:28.428949Z",
          "shell.execute_reply": "2025-11-27T13:39:28.449987Z"
        },
        "id": "ribRfQ-dtkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: tqdm-based training & evaluation helpers (Keras-like live progress)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch=None, num_epochs=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    desc = f\"Train\"\n",
        "    if epoch is not None and num_epochs is not None:\n",
        "        desc = f\"Train [{epoch}/{num_epochs}]\"\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=desc, leave=False)\n",
        "\n",
        "    for mel, labels in progress_bar:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # live metrics on the bar\n",
        "        current_loss = running_loss / total\n",
        "        current_acc = correct / total\n",
        "        progress_bar.set_postfix(loss=f\"{current_loss:.4f}\", acc=f\"{current_acc:.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion, device, epoch=None, num_epochs=None):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    desc = f\"Val\"\n",
        "    if epoch is not None and num_epochs is not None:\n",
        "        desc = f\"Val   [{epoch}/{num_epochs}]\"\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=desc, leave=False)\n",
        "\n",
        "    for mel, labels in progress_bar:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        current_loss = running_loss / total\n",
        "        current_acc = correct / total\n",
        "        progress_bar.set_postfix(loss=f\"{current_loss:.4f}\", acc=f\"{current_acc:.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:39:28.45202Z",
          "iopub.execute_input": "2025-11-27T13:39:28.452254Z",
          "iopub.status.idle": "2025-11-27T13:39:28.613026Z",
          "shell.execute_reply.started": "2025-11-27T13:39:28.452238Z",
          "shell.execute_reply": "2025-11-27T13:39:28.612231Z"
        },
        "id": "Ul6c9rWRtkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 13: Train baseline CNN for a few epochs (with live tqdm bars)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_BASELINE + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        baseline_model, train_loader, criterion, optimizer, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_BASELINE\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        baseline_model, val_loader, criterion, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_BASELINE\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(baseline_model.state_dict(), \"baseline_audio_cnn.pth\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-27T12:17:41.680891Z",
          "iopub.execute_input": "2025-11-27T12:17:41.681129Z",
          "iopub.status.idle": "2025-11-27T12:19:15.828945Z",
          "shell.execute_reply.started": "2025-11-27T12:17:41.681113Z",
          "shell.execute_reply": "2025-11-27T12:19:15.827877Z"
        },
        "id": "SZIZ-CX_tkzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: DataLoaders (fast version with workers again)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,      # back to 2 workers for speed\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:01:41.747278Z",
          "iopub.status.idle": "2025-11-28T15:01:41.747508Z",
          "shell.execute_reply.started": "2025-11-28T15:01:41.747397Z",
          "shell.execute_reply": "2025-11-28T15:01:41.747408Z"
        },
        "id": "ziYXra7EtkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: Training and evaluation with simple live progress\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device,\n",
        "                    epoch=None, num_epochs=None, log_interval=20):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    for batch_idx, (mel, labels) in enumerate(dataloader, start=1):\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # live progress line\n",
        "        if batch_idx % log_interval == 0 or batch_idx == num_batches:\n",
        "            cur_loss = running_loss / total\n",
        "            cur_acc  = correct / total\n",
        "            if epoch is not None and num_epochs is not None:\n",
        "                prefix = f\"Epoch {epoch}/{num_epochs} \"\n",
        "            else:\n",
        "                prefix = \"\"\n",
        "            print(\n",
        "                f\"{prefix}[{batch_idx:3d}/{num_batches:3d}] \"\n",
        "                f\"loss={cur_loss:.4f} acc={cur_acc:.4f}\",\n",
        "                end=\"\\r\"\n",
        "            )\n",
        "\n",
        "    print()  # newline after last batch\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, dataloader, criterion, device,\n",
        "             epoch=None, num_epochs=None):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    for batch_idx, (mel, labels) in enumerate(dataloader, start=1):\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:39:28.619117Z",
          "iopub.execute_input": "2025-11-27T13:39:28.619457Z",
          "iopub.status.idle": "2025-11-27T13:39:28.639282Z",
          "shell.execute_reply.started": "2025-11-27T13:39:28.619431Z",
          "shell.execute_reply": "2025-11-27T13:39:28.638598Z"
        },
        "id": "_NjuHONqtkzT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C: Train baseline CNN again (fast + live progress)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_BASELINE + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        baseline_model, train_loader, criterion, optimizer, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_BASELINE, log_interval=20\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        baseline_model, val_loader, criterion, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_BASELINE\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(baseline_model.state_dict(), \"baseline_audio_cnn.pth\")\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:39:28.640069Z",
          "iopub.execute_input": "2025-11-27T13:39:28.640325Z",
          "iopub.status.idle": "2025-11-27T13:46:53.549091Z",
          "shell.execute_reply.started": "2025-11-27T13:39:28.640303Z",
          "shell.execute_reply": "2025-11-27T13:46:53.54824Z"
        },
        "id": "VZBoS-3htkzU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14 (updated): QNN with automatic GPU/CPU device selection\n",
        "\n",
        "N_QUBITS = 8\n",
        "N_Q_LAYERS = 3\n",
        "\n",
        "def create_qml_device():\n",
        "    \"\"\"Create a PennyLane device, preferring GPU if available.\"\"\"\n",
        "    # If torch sees a CUDA device, try to use lightning.gpu\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu (GPU)\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"Could not use lightning.gpu, falling back to lightning.qubit (CPU).\")\n",
        "            print(\"Reason:\", repr(e))\n",
        "\n",
        "    # Fallback: fast CPU simulator\n",
        "    dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "    print(\"PennyLane device: lightning.qubit (CPU)\")\n",
        "    return dev\n",
        "\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"Quantum circuit with angle embedding + variational layers.\"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS))\n",
        "\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        # single-qubit rotations\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(\n",
        "                weights[l, w, 0],\n",
        "                weights[l, w, 1],\n",
        "                weights[l, w, 2],\n",
        "                wires=w,\n",
        "            )\n",
        "        # ring entanglement\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CNOT(wires=[w, (w + 1) % N_QUBITS])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(w)) for w in range(N_QUBITS)]\n",
        "\n",
        "\n",
        "# Wrap as TorchLayer factory\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    layer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "    return layer\n",
        "\n",
        "\n",
        "# Quick sanity check\n",
        "qnn_layer = create_qnn_layer()\n",
        "x_test = torch.randn(4, N_QUBITS)\n",
        "y_test = qnn_layer(x_test)\n",
        "\n",
        "print(\"QNN input shape:\", x_test.shape)\n",
        "print(\"QNN output shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:01:41.748326Z",
          "iopub.status.idle": "2025-11-28T15:01:41.748572Z",
          "shell.execute_reply.started": "2025-11-28T15:01:41.748456Z",
          "shell.execute_reply": "2025-11-28T15:01:41.748469Z"
        },
        "id": "cVGRwQnWtkzU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Hybrid Audio CNN + QNN model (Level 4 parallel heads)\n",
        "\n",
        "class HybridAudioCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, in_channels=1,\n",
        "                 alpha=1.0, beta=1.0):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackbone(in_channels=in_channels)\n",
        "\n",
        "        emb_dim = 64  # backbone outputs 64-dim features\n",
        "\n",
        "        # Classical head\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # Quantum head\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        # Combination weights\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        # x: [B, 1, 64, T]\n",
        "        features = self.backbone(x)          # [B, 64]\n",
        "\n",
        "        # Classical path\n",
        "        logits_classical = self.classical_head(features)  # [B, C]\n",
        "\n",
        "        # Quantum path: compress -> tanh -> QNN -> linear\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))     # [B, 8] in [-1, 1]\n",
        "        q_outputs = self.qnn(q_inputs)                    # [B, 8]\n",
        "        logits_quantum = self.quantum_head(q_outputs)     # [B, C]\n",
        "\n",
        "        # Combine\n",
        "        logits = self.alpha * logits_classical + self.beta * logits_quantum\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_classical, logits_quantum\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Instantiate hybrid model\n",
        "hybrid_model = HybridAudioCNNQNN(num_classes=NUM_CLASSES).to(torch_device)\n",
        "\n",
        "total_params_hybrid = sum(p.numel() for p in hybrid_model.parameters() if p.requires_grad)\n",
        "print(hybrid_model)\n",
        "print(f\"Hybrid model trainable parameters: {total_params_hybrid:,}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:46:53.85448Z",
          "iopub.execute_input": "2025-11-27T13:46:53.854723Z",
          "iopub.status.idle": "2025-11-27T13:46:53.884665Z",
          "shell.execute_reply.started": "2025-11-27T13:46:53.854705Z",
          "shell.execute_reply": "2025-11-27T13:46:53.883937Z"
        },
        "id": "7dVhHx-ctkzU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 16: Train hybrid CNN + QNN model\n",
        "\n",
        "NUM_EPOCHS_HYBRID = 3   # start small; can increase later\n",
        "HYBRID_LR = 5e-4        # often a bit smaller than baseline LR\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=HYBRID_LR)\n",
        "\n",
        "best_val_acc_hybrid = 0.0\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_HYBRID + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model, train_loader, criterion, optimizer_hybrid, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_HYBRID, log_interval=20\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model, val_loader, criterion, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_HYBRID\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc_hybrid:\n",
        "        best_val_acc_hybrid = val_acc\n",
        "        torch.save(hybrid_model.state_dict(), \"hybrid_audio_cnn_qnn.pth\")\n",
        "\n",
        "    print(\n",
        "        f\"[HYBRID] Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"Best hybrid val acc:\", best_val_acc_hybrid)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-27T12:27:23.566837Z",
          "iopub.execute_input": "2025-11-27T12:27:23.567134Z",
          "iopub.status.idle": "2025-11-27T12:31:01.927426Z",
          "shell.execute_reply.started": "2025-11-27T12:27:23.567115Z",
          "shell.execute_reply": "2025-11-27T12:31:01.925848Z"
        },
        "id": "oAh7XLxjtkzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Bigger CNN backbone + larger hybrid model\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    def __init__(self, in_channels=1):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 32, 32, ~63]\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 64, 16, ~31]\n",
        "            nn.Dropout(0.15),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 128, 8, ~15]\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),   # [B, 256, 4, ~7]\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # -> [B, 256, 1, 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = torch.flatten(x, 1)  # [B, 256]\n",
        "        return x\n",
        "\n",
        "\n",
        "class HybridAudioCNNQNNBig(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES, in_channels=1,\n",
        "                 alpha=1.0, beta=1.0):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackboneBig(in_channels=in_channels)\n",
        "\n",
        "        emb_dim = 256  # bigger embedding\n",
        "\n",
        "        # Classical head: a bit larger MLP\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # Quantum head: compress to N_QUBITS, then QNN, then FC\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        features = self.backbone(x)                 # [B, 256]\n",
        "\n",
        "        # Classical branch\n",
        "        logits_classical = self.classical_head(features)  # [B, C]\n",
        "\n",
        "        # Quantum branch\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))      # [B, N_QUBITS]\n",
        "        q_outputs = self.qnn(q_inputs)                    # [B, N_QUBITS]\n",
        "        logits_quantum = self.quantum_head(q_outputs)     # [B, C]\n",
        "\n",
        "        logits = self.alpha * logits_classical + self.beta * logits_quantum\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_classical, logits_quantum\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Instantiate big hybrid model\n",
        "hybrid_model_big = HybridAudioCNNQNNBig(num_classes=NUM_CLASSES).to(torch_device)\n",
        "\n",
        "total_params_big = sum(p.numel() for p in hybrid_model_big.parameters() if p.requires_grad)\n",
        "print(hybrid_model_big)\n",
        "print(f\"Big hybrid model trainable parameters: {total_params_big:,}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:46:53.885446Z",
          "iopub.execute_input": "2025-11-27T13:46:53.885773Z",
          "iopub.status.idle": "2025-11-27T13:46:53.922118Z",
          "shell.execute_reply.started": "2025-11-27T13:46:53.885753Z",
          "shell.execute_reply": "2025-11-27T13:46:53.921536Z"
        },
        "id": "1ImNegrXtkzU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Test training run for big hybrid CNN + QNN\n",
        "\n",
        "NUM_EPOCHS_HYBRID_BIG = 3\n",
        "HYBRID_BIG_LR = 5e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_hybrid_big = optim.Adam(hybrid_model_big.parameters(), lr=HYBRID_BIG_LR)\n",
        "\n",
        "best_val_acc_hybrid_big = 0.0\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_HYBRID_BIG + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model_big, train_loader, criterion, optimizer_hybrid_big, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_HYBRID_BIG, log_interval=20\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model_big, val_loader, criterion, torch_device,\n",
        "        epoch=epoch, num_epochs=NUM_EPOCHS_HYBRID_BIG\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc_hybrid_big:\n",
        "        best_val_acc_hybrid_big = val_acc\n",
        "        torch.save(hybrid_model_big.state_dict(), \"hybrid_audio_cnn_qnn_big.pth\")\n",
        "\n",
        "    print(\n",
        "        f\"[HYBRID-BIG] Epoch {epoch:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"Best big hybrid val acc:\", best_val_acc_hybrid_big)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T13:46:53.922763Z",
          "iopub.execute_input": "2025-11-27T13:46:53.923Z",
          "iopub.status.idle": "2025-11-27T14:53:43.181532Z",
          "shell.execute_reply.started": "2025-11-27T13:46:53.922977Z",
          "shell.execute_reply": "2025-11-27T14:53:43.1807Z"
        },
        "id": "_XAWLfSjtkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Hybrid big backbone device:\", next(hybrid_model_big.backbone.parameters()).device)\n",
        "\n",
        "# Correct QNN info\n",
        "dev = hybrid_model_big.qnn.qnode.device\n",
        "print(\"QNN device class:\", type(dev))\n",
        "print(\"QNN device name:\", dev.name)\n",
        "print(\"QNN device wires:\", dev.wires)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:01:41.749401Z",
          "iopub.status.idle": "2025-11-28T15:01:41.749748Z",
          "shell.execute_reply.started": "2025-11-28T15:01:41.749571Z",
          "shell.execute_reply": "2025-11-28T15:01:41.749587Z"
        },
        "id": "iiBhnRR5tkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20: Full-training config + autosave / resume helpers\n",
        "\n",
        "FULL_NUM_EPOCHS = 15          # you can increase later if you want\n",
        "FULL_LR = 5e-4                 # learning rate for full training\n",
        "\n",
        "CKPT_PATH = \"/kaggle/working/hybrid_big_ckpt.pth\"\n",
        "HISTORY_CSV = \"/kaggle/working/hybrid_big_history.csv\"\n",
        "\n",
        "print(\"Checkpoint path:\", CKPT_PATH)\n",
        "print(\"History CSV path:\", HISTORY_CSV)\n",
        "\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, best_val_acc, history, path=CKPT_PATH):\n",
        "    \"\"\"Save model, optimizer, epoch, best val acc, and history.\"\"\"\n",
        "    ckpt = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"history\": history,\n",
        "    }\n",
        "    torch.save(ckpt, path)\n",
        "    # Also save history to CSV for easy inspection\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame(history)\n",
        "    df.to_csv(HISTORY_CSV, index=False)\n",
        "    print(f\"[AUTOSAVE] Saved checkpoint at epoch {epoch} to {path}\")\n",
        "\n",
        "\n",
        "def load_checkpoint_if_exists(model, optimizer, path=CKPT_PATH):\n",
        "    \"\"\"Load checkpoint if it exists; otherwise start from scratch.\"\"\"\n",
        "    if os.path.exists(path):\n",
        "        ckpt = torch.load(path, map_location=torch_device)\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
        "        start_epoch = ckpt[\"epoch\"] + 1\n",
        "        best_val_acc = ckpt.get(\"best_val_acc\", 0.0)\n",
        "        history = ckpt.get(\"history\", [])\n",
        "        print(f\"[RESUME] Loaded checkpoint from {path}, starting at epoch {start_epoch}\")\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_val_acc = 0.0\n",
        "        history = []\n",
        "        print(\"[RESUME] No checkpoint found, starting from scratch.\")\n",
        "    return start_epoch, best_val_acc, history\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T15:00:54.774378Z",
          "iopub.execute_input": "2025-11-27T15:00:54.775219Z",
          "iopub.status.idle": "2025-11-27T15:00:54.783021Z",
          "shell.execute_reply.started": "2025-11-27T15:00:54.775188Z",
          "shell.execute_reply": "2025-11-27T15:00:54.782262Z"
        },
        "id": "fmBw_cQFtkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 21: Full hybrid training with autosave & resume\n",
        "\n",
        "# Make sure model is on the right device\n",
        "hybrid_model_big = hybrid_model_big.to(torch_device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_hybrid_big = optim.Adam(hybrid_model_big.parameters(), lr=FULL_LR)\n",
        "\n",
        "# Try to resume from checkpoint if it exists\n",
        "start_epoch, best_val_acc_hybrid_big, history = load_checkpoint_if_exists(\n",
        "    hybrid_model_big, optimizer_hybrid_big, CKPT_PATH\n",
        ")\n",
        "\n",
        "print(f\"Training from epoch {start_epoch} to {FULL_NUM_EPOCHS}\")\n",
        "print(f\"Current best val acc: {best_val_acc_hybrid_big:.4f}\")\n",
        "\n",
        "for epoch in range(start_epoch, FULL_NUM_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model_big, train_loader, criterion, optimizer_hybrid_big, torch_device,\n",
        "        epoch=epoch, num_epochs=FULL_NUM_EPOCHS, log_interval=20\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model_big, val_loader, criterion, torch_device,\n",
        "        epoch=epoch, num_epochs=FULL_NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    # Update best and autosave\n",
        "    if val_acc > best_val_acc_hybrid_big:\n",
        "        best_val_acc_hybrid_big = val_acc\n",
        "\n",
        "    # Append to history\n",
        "    history.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": float(train_loss),\n",
        "        \"train_acc\": float(train_acc),\n",
        "        \"val_loss\": float(val_loss),\n",
        "        \"val_acc\": float(val_acc),\n",
        "        \"best_val_acc_so_far\": float(best_val_acc_hybrid_big),\n",
        "    })\n",
        "\n",
        "    save_checkpoint(\n",
        "        hybrid_model_big, optimizer_hybrid_big,\n",
        "        epoch, best_val_acc_hybrid_big, history, CKPT_PATH\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"[FULL-HYBRID] Epoch {epoch:02d}/{FULL_NUM_EPOCHS} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f} | \"\n",
        "        f\"Best Val Acc: {best_val_acc_hybrid_big:.4f}\"\n",
        "    )\n",
        "\n",
        "print(\"=== Full training finished ===\")\n",
        "print(\"Best big hybrid val acc:\", best_val_acc_hybrid_big)\n",
        "print(\"Checkpoint saved at:\", CKPT_PATH)\n",
        "print(\"History CSV saved at:\", HISTORY_CSV)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T15:39:29.633377Z",
          "iopub.execute_input": "2025-11-27T15:39:29.633745Z",
          "iopub.status.idle": "2025-11-27T18:27:15.23774Z",
          "shell.execute_reply.started": "2025-11-27T15:39:29.633715Z",
          "shell.execute_reply": "2025-11-27T18:27:15.236938Z"
        },
        "id": "mDUeTm5BtkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/kaggle/working\"))\n",
        "print(\"Checkpoint exists:\",\n",
        "      os.path.exists(\"/kaggle/working/hybrid_big_ckpt.pth\"))\n",
        "print(\"History exists:\",\n",
        "      os.path.exists(\"/kaggle/working/hybrid_big_history.csv\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:02:26.050748Z",
          "iopub.execute_input": "2025-11-28T15:02:26.051069Z",
          "iopub.status.idle": "2025-11-28T15:02:26.055824Z",
          "shell.execute_reply.started": "2025-11-28T15:02:26.051046Z",
          "shell.execute_reply": "2025-11-28T15:02:26.055211Z"
        },
        "id": "SXUMnWj3tkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "BEST_MODEL_PATH = \"/kaggle/working/hybrid_big_best.pth\"\n",
        "shutil.copy(\"/kaggle/working/hybrid_big_ckpt.pth\", BEST_MODEL_PATH)\n",
        "print(\"Copied best model to:\", BEST_MODEL_PATH)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:02:27.69942Z",
          "iopub.execute_input": "2025-11-28T15:02:27.699693Z",
          "iopub.status.idle": "2025-11-28T15:02:27.716769Z",
          "shell.execute_reply.started": "2025-11-28T15:02:27.699672Z",
          "shell.execute_reply": "2025-11-28T15:02:27.715842Z"
        },
        "id": "QjmW8qCBtkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "\n",
        "print(\"Best model:\")\n",
        "display(FileLink(\"/kaggle/working/hybrid_big_best.pth\"))\n",
        "\n",
        "print(\"Training history:\")\n",
        "display(FileLink(\"/kaggle/working/hybrid_big_history.csv\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:02:29.04951Z",
          "iopub.execute_input": "2025-11-28T15:02:29.049785Z",
          "iopub.status.idle": "2025-11-28T15:02:29.057473Z",
          "shell.execute_reply.started": "2025-11-28T15:02:29.049763Z",
          "shell.execute_reply": "2025-11-28T15:02:29.056899Z"
        },
        "id": "Vd9fcG1AtkzV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here"
      ],
      "metadata": {
        "id": "g8qlaznptkzW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "qyQzXCGatkzW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Big CNN backbone with dynamic flatten size\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    def __init__(self, in_channels=1, input_shape=(1, 64, 126)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # --- compute flatten dim from a fake mel sample ---\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, *input_shape)  # (B, C, n_mels, time)\n",
        "            out = self.conv(dummy)\n",
        "            flat_dim = out.view(1, -1).shape[1]\n",
        "\n",
        "        self.embedding = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flat_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.embedding(x)\n",
        "        return x  # [batch, 128]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.063469Z",
          "iopub.status.idle": "2025-11-29T10:16:13.063755Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.063592Z",
          "shell.execute_reply": "2025-11-29T10:16:13.063605Z"
        },
        "id": "mDT5uEZQtkzW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridAudioCNNQNN_Big(nn.Module):\n",
        "    def __init__(self, num_classes=10, in_channels=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = AudioCNNBackboneBig(in_channels=in_channels)\n",
        "        emb_dim = 128          # from backbone\n",
        "        self.n_qubits = 8      # quantum wires\n",
        "\n",
        "        # --- NEW: projection 128 -> 8 for QNN ---\n",
        "        self.qproj = nn.Linear(emb_dim, self.n_qubits)\n",
        "\n",
        "        # Classical head\n",
        "        self.class_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4096, 128),    # <-- use 4096 instead of 10752\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # QNN setup\n",
        "        weight_shapes = {\"weights\": (2, self.n_qubits, 3)}\n",
        "        dev = qml.device(\"lightning.gpu\", wires=self.n_qubits)\n",
        "\n",
        "        @qml.qnode(dev, interface=\"torch\")\n",
        "        def qnode(inputs, weights):\n",
        "            # inputs has shape (n_qubits,)\n",
        "            qml.AngleEmbedding(inputs, wires=range(self.n_qubits))\n",
        "            qml.StronglyEntanglingLayers(weights, wires=range(self.n_qubits))\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
        "\n",
        "        self.qnn = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "        self.quantum_head = nn.Linear(self.n_qubits, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.backbone(x)           # [B, 128]\n",
        "\n",
        "        # classical\n",
        "        out_classical = self.class_head(emb)\n",
        "\n",
        "        # quantum path: 128 -> 8 -> QNN\n",
        "        q_in = self.qproj(emb)           # [B, 8]\n",
        "        q_out = self.qnn(q_in)           # [B, 8]\n",
        "        out_quantum = self.quantum_head(q_out)\n",
        "\n",
        "        return (out_classical + out_quantum) / 2\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:10:21.014413Z",
          "iopub.execute_input": "2025-11-29T11:10:21.015096Z",
          "iopub.status.idle": "2025-11-29T11:10:21.022512Z",
          "shell.execute_reply.started": "2025-11-29T11:10:21.01507Z",
          "shell.execute_reply": "2025-11-29T11:10:21.021823Z"
        },
        "id": "Zdj-YFEhtkzW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "num_classes = 10\n",
        "hybrid_model_big = HybridAudioCNNQNN_Big(num_classes=num_classes).to(torch_device)\n",
        "print(\"Device:\", torch_device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:10:22.029315Z",
          "iopub.execute_input": "2025-11-29T11:10:22.029845Z",
          "iopub.status.idle": "2025-11-29T11:10:22.053228Z",
          "shell.execute_reply.started": "2025-11-29T11:10:22.029817Z",
          "shell.execute_reply": "2025-11-29T11:10:22.052251Z"
        },
        "id": "uXGcc2mztkzW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:12.907912Z",
          "iopub.execute_input": "2025-11-29T10:16:12.908116Z",
          "iopub.status.idle": "2025-11-29T10:16:12.912386Z",
          "shell.execute_reply.started": "2025-11-29T10:16:12.908099Z",
          "shell.execute_reply": "2025-11-29T10:16:12.911701Z"
        },
        "id": "zyyrI6KxtkzW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/kaggle/input/urbansound8k\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:22:12.76435Z",
          "iopub.execute_input": "2025-11-28T20:22:12.764563Z",
          "iopub.status.idle": "2025-11-28T20:22:12.776296Z",
          "shell.execute_reply.started": "2025-11-28T20:22:12.764523Z",
          "shell.execute_reply": "2025-11-28T20:22:12.77558Z"
        },
        "id": "baqrRLXTtkze"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_ROOT = \"/kaggle/input/urbansound8k\"\n",
        "\n",
        "METADATA_CSV = os.path.join(DATA_ROOT, \"UrbanSound8K.csv\")\n",
        "AUDIO_ROOT   = DATA_ROOT   # <-- folds are directly here\n",
        "\n",
        "print(\"CSV exists:\", METADATA_CSV, os.path.exists(METADATA_CSV))\n",
        "print(\"Audio root exists:\", AUDIO_ROOT, os.path.exists(AUDIO_ROOT))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:22:12.777113Z",
          "iopub.execute_input": "2025-11-28T20:22:12.777943Z",
          "iopub.status.idle": "2025-11-28T20:22:12.787422Z",
          "shell.execute_reply.started": "2025-11-28T20:22:12.77792Z",
          "shell.execute_reply": "2025-11-28T20:22:12.786719Z"
        },
        "id": "JKWpgyhftkze"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Audio loading and log-Mel spectrogram transform\n",
        "\n",
        "import librosa\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def load_audio(path, target_sr=SAMPLE_RATE):\n",
        "    \"\"\"Load audio file and return mono waveform tensor at target_sr.\"\"\"\n",
        "    if HAS_TORCHAUDIO:\n",
        "        waveform, sr = torchaudio.load(path)  # (channels, samples)\n",
        "        # convert to mono by averaging channels if needed\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "        if sr != target_sr:\n",
        "            resampler = T.Resample(orig_freq=sr, new_freq=target_sr)\n",
        "            waveform = resampler(waveform)\n",
        "        return waveform.squeeze(0), target_sr  # (samples,), sr\n",
        "    else:\n",
        "        # librosa fallback\n",
        "        y, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "        return torch.tensor(y, dtype=torch.float32), target_sr\n",
        "\n",
        "def pad_or_trim(waveform, num_samples=NUM_SAMPLES):\n",
        "    \"\"\"Pad with zeros or trim to a fixed number of samples.\"\"\"\n",
        "    length = waveform.shape[-1]\n",
        "    if length < num_samples:\n",
        "        pad_amount = num_samples - length\n",
        "        waveform = F.pad(waveform, (0, pad_amount))\n",
        "    elif length > num_samples:\n",
        "        waveform = waveform[:num_samples]\n",
        "    return waveform\n",
        "\n",
        "# Pre-build a MelSpectrogram transform if torchaudio is available\n",
        "if HAS_TORCHAUDIO:\n",
        "    mel_transform = T.MelSpectrogram(\n",
        "        sample_rate=SAMPLE_RATE,\n",
        "        n_fft=N_FFT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "        n_mels=N_MELS\n",
        "    )\n",
        "else:\n",
        "    mel_transform = None  # we'll use librosa.melspectrogram later if needed\n",
        "\n",
        "def waveform_to_logmel(waveform):\n",
        "    \"\"\"Convert 1D waveform tensor -> log-Mel spectrogram tensor [1, n_mels, time].\"\"\"\n",
        "    waveform = waveform.unsqueeze(0)  # [1, samples]\n",
        "    if HAS_TORCHAUDIO and mel_transform is not None:\n",
        "        mel = mel_transform(waveform)  # [1, n_mels, time]\n",
        "        mel = torch.clamp(mel, min=1e-9).log()\n",
        "        return mel\n",
        "    else:\n",
        "        # librosa fallback\n",
        "        y = waveform.squeeze(0).cpu().numpy()\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=y,\n",
        "            sr=SAMPLE_RATE,\n",
        "            n_fft=N_FFT,\n",
        "            hop_length=HOP_LENGTH,\n",
        "            n_mels=N_MELS,\n",
        "        )\n",
        "        mel = np.log(np.clip(mel, a_min=1e-9, a_max=None))\n",
        "        mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)  # [1, n_mels, time]\n",
        "        return mel\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.066446Z",
          "iopub.status.idle": "2025-11-29T10:16:13.066712Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.066568Z",
          "shell.execute_reply": "2025-11-29T10:16:13.066582Z"
        },
        "id": "fqcgpI4ttkze"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: UrbanSoundDataset class\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, csv_path, audio_root, folds=[1], transform=None):\n",
        "        \"\"\"\n",
        "        csv_path: path to UrbanSound8K.csv\n",
        "        audio_root: folder where fold1/, fold2/, ... exist\n",
        "        folds: list of fold numbers to include (e.g. [1,2,3,4])\n",
        "        transform: function to apply to waveform (e.g., log-Mel)\n",
        "        \"\"\"\n",
        "        self.meta = pd.read_csv(csv_path)\n",
        "        self.audio_root = audio_root\n",
        "        self.folds = folds\n",
        "        self.transform = transform\n",
        "\n",
        "        # Filter rows by fold list\n",
        "        self.meta = self.meta[self.meta['fold'].isin(folds)]\n",
        "        self.meta = self.meta.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.meta.iloc[idx]\n",
        "\n",
        "        fold = f\"fold{row['fold']}\"\n",
        "        file_path = os.path.join(self.audio_root, fold, row['slice_file_name'])\n",
        "\n",
        "        label = int(row['classID'])\n",
        "\n",
        "        # Load audio\n",
        "        waveform, sr = load_audio(file_path)\n",
        "\n",
        "        # Fix length\n",
        "        waveform = pad_or_trim(waveform)\n",
        "\n",
        "        # Transform to log-Mel if provided\n",
        "        if self.transform:\n",
        "            mel = self.transform(waveform)\n",
        "            return mel, label\n",
        "\n",
        "        # Otherwise return raw waveform\n",
        "        return waveform, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.067874Z",
          "iopub.status.idle": "2025-11-29T10:16:13.068693Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.06851Z",
          "shell.execute_reply": "2025-11-29T10:16:13.068527Z"
        },
        "id": "6RSSFQB_tkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A1 — Datasets\n",
        "\n",
        "# folds: same split we used before\n",
        "train_folds = [1, 2, 3, 4]\n",
        "val_folds   = [5]\n",
        "\n",
        "train_dataset = UrbanSoundDataset(\n",
        "    csv_path=METADATA_CSV,\n",
        "    audio_root=AUDIO_ROOT,\n",
        "    folds=train_folds,\n",
        "    transform=waveform_to_logmel\n",
        ")\n",
        "\n",
        "val_dataset = UrbanSoundDataset(\n",
        "    csv_path=METADATA_CSV,\n",
        "    audio_root=AUDIO_ROOT,\n",
        "    folds=val_folds,\n",
        "    transform=waveform_to_logmel\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Val samples:\", len(val_dataset))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.069861Z",
          "iopub.status.idle": "2025-11-29T10:16:13.070188Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.070006Z",
          "shell.execute_reply": "2025-11-29T10:16:13.070019Z"
        },
        "id": "FcSkb9wGtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A2 — Data loaders\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.071202Z",
          "iopub.status.idle": "2025-11-29T10:16:13.071438Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.071324Z",
          "shell.execute_reply": "2025-11-29T10:16:13.071336Z"
        },
        "id": "EZrywPDdtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A3 — Init BIG model\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", torch_device)\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "hybrid_model_big = HybridAudioCNNQNN_Big(num_classes=num_classes).to(torch_device)\n",
        "\n",
        "print(\"Model ready on GPU.\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.072125Z",
          "iopub.status.idle": "2025-11-29T10:16:13.072437Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.07228Z",
          "shell.execute_reply": "2025-11-29T10:16:13.072293Z"
        },
        "id": "Kl0mFC6ltkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A3b — training function\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch, num_epochs, log_interval=20):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if (batch_idx + 1) % log_interval == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}] | Batch [{batch_idx+1}/{len(dataloader)}] \"\n",
        "                  f\"loss={loss.item():.4f}\")\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.073419Z",
          "iopub.status.idle": "2025-11-29T10:16:13.073732Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.073576Z",
          "shell.execute_reply": "2025-11-29T10:16:13.07359Z"
        },
        "id": "5I4d6gjQtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A3c — evaluation function\n",
        "def evaluate(model, dataloader, criterion, device, epoch, num_epochs):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    print(f\"[VAL] Epoch {epoch}/{num_epochs} loss={epoch_loss:.4f} acc={epoch_acc:.4f}\")\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.074488Z",
          "iopub.status.idle": "2025-11-29T10:16:13.074813Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.074645Z",
          "shell.execute_reply": "2025-11-29T10:16:13.07466Z"
        },
        "id": "Kyk0Ea_ztkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A4 — Optimizer + Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_big = torch.optim.Adam(hybrid_model_big.parameters(), lr=5e-4)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.075921Z",
          "iopub.status.idle": "2025-11-29T10:16:13.076254Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.076072Z",
          "shell.execute_reply": "2025-11-29T10:16:13.076085Z"
        },
        "id": "JPlSKs5stkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "x = x.to(torch_device)\n",
        "with torch.no_grad():\n",
        "    emb = hybrid_model_big.backbone(x)\n",
        "    print(\"Input batch:\", x.shape)\n",
        "    print(\"Embedding:\", emb.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:22:12.96338Z",
          "iopub.execute_input": "2025-11-28T20:22:12.963642Z",
          "iopub.status.idle": "2025-11-28T20:22:17.876398Z",
          "shell.execute_reply.started": "2025-11-28T20:22:12.963616Z",
          "shell.execute_reply": "2025-11-28T20:22:17.875618Z"
        },
        "id": "3dt0p8netkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A5 — TRAIN BIG MODEL\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "\n",
        "NUM_EPOCHS_BIG = 12\n",
        "CKPT = \"/kaggle/working/hybrid_big_ckpt.pth\"\n",
        "BEST = \"/kaggle/working/hybrid_big_best.pth\"\n",
        "HISTORY = \"/kaggle/working/hybrid_big_history.csv\"\n",
        "\n",
        "best_val_acc = 0\n",
        "\n",
        "# init CSV\n",
        "with open(HISTORY, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
        "\n",
        "print(\"=== Training Big Hybrid Model ===\")\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_BIG + 1):\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model_big, train_loader,\n",
        "        criterion, optimizer_big, torch_device,\n",
        "        epoch, NUM_EPOCHS_BIG, log_interval=20\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model_big, val_loader,\n",
        "        criterion, torch_device, epoch, NUM_EPOCHS_BIG\n",
        "    )\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        \"model_state_dict\": hybrid_model_big.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer_big.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"best_val_acc\": best_val_acc\n",
        "    }, CKPT)\n",
        "    print(f\"[CKPT] saved at epoch {epoch}\")\n",
        "\n",
        "    # Save best\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(hybrid_model_big.state_dict(), BEST)\n",
        "        print(f\"[BEST] updated → {BEST} (acc={best_val_acc:.4f})\")\n",
        "\n",
        "    # Append to CSV\n",
        "    with open(HISTORY, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "\n",
        "print(\"\\n=== Training Finished ===\")\n",
        "print(\"Best Validation Acc:\", best_val_acc)\n",
        "print(\"Checkpoint:\", CKPT)\n",
        "print(\"History:\", HISTORY)\n",
        "print(\"Best Model:\", BEST)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T15:35:03.490365Z",
          "iopub.execute_input": "2025-11-28T15:35:03.490681Z",
          "iopub.status.idle": "2025-11-28T17:19:23.773587Z",
          "shell.execute_reply.started": "2025-11-28T15:35:03.490653Z",
          "shell.execute_reply": "2025-11-28T17:19:23.77269Z"
        },
        "id": "oO8vHTDJtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A6 — Show saved files\n",
        "import os\n",
        "print(os.listdir(\"/kaggle/working\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:29:37.681313Z",
          "iopub.execute_input": "2025-11-28T17:29:37.682213Z",
          "iopub.status.idle": "2025-11-28T17:29:37.687196Z",
          "shell.execute_reply.started": "2025-11-28T17:29:37.682182Z",
          "shell.execute_reply": "2025-11-28T17:29:37.686536Z"
        },
        "id": "AMDY8qkHtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import FileLink\n",
        "\n",
        "print(\"Best model:\")\n",
        "display(FileLink(\"/kaggle/working/hybrid_big_best.pth\"))\n",
        "\n",
        "print(\"\\nHistory:\")\n",
        "display(FileLink(\"/kaggle/working/hybrid_big_history.csv\"))\n",
        "\n",
        "print(\"\\nCheckpoint:\")\n",
        "display(FileLink(\"/kaggle/working/hybrid_big_ckpt.pth\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T17:36:27.501809Z",
          "iopub.execute_input": "2025-11-28T17:36:27.502552Z",
          "iopub.status.idle": "2025-11-28T17:36:27.512565Z",
          "shell.execute_reply.started": "2025-11-28T17:36:27.50252Z",
          "shell.execute_reply": "2025-11-28T17:36:27.511939Z"
        },
        "id": "gTxJTGUstkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R1 – ResNet18-style backbone for log-mel spectrograms\n",
        "\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class AudioResNetBackbone(nn.Module):\n",
        "    def __init__(self, in_channels=1, emb_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        # Base ResNet18 (no pretrained weights to avoid download)\n",
        "        base = models.resnet18(weights=None)\n",
        "\n",
        "        # Adapt first conv to 1-channel input (mel spectrogram)\n",
        "        base.conv1 = nn.Conv2d(\n",
        "            in_channels, 64,\n",
        "            kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "\n",
        "        # Remove the final FC layer, keep everything up to avgpool\n",
        "        self.features = nn.Sequential(\n",
        "            base.conv1,\n",
        "            base.bn1,\n",
        "            base.relu,\n",
        "            base.maxpool,\n",
        "            base.layer1,\n",
        "            base.layer2,\n",
        "            base.layer3,\n",
        "            base.layer4,\n",
        "            base.avgpool,      # -> [B, 512, 1, 1]\n",
        "        )\n",
        "\n",
        "        # Projection from 512 -> emb_dim\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Flatten(),      # [B, 512]\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, emb_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.proj(x)\n",
        "        return x          # [B, emb_dim]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.077194Z",
          "iopub.status.idle": "2025-11-29T10:16:13.077503Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.077339Z",
          "shell.execute_reply": "2025-11-29T10:16:13.077352Z"
        },
        "id": "_iJVcnhhtkzf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R2 – Hybrid ResNet + QNN (10 qubits)\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "class HybridAudioResNetQNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, in_channels=1, emb_dim=128, n_qubits=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_qubits = n_qubits\n",
        "\n",
        "        # Stronger backbone\n",
        "        self.backbone = AudioResNetBackbone(in_channels=in_channels, emb_dim=emb_dim)\n",
        "\n",
        "        # Classical head\n",
        "        self.class_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # 128 -> n_qubits for quantum input\n",
        "        self.qproj = nn.Linear(emb_dim, n_qubits)\n",
        "\n",
        "        # Quantum device\n",
        "        dev = qml.device(\"lightning.gpu\", wires=n_qubits)\n",
        "\n",
        "        weight_shapes = {\"weights\": (2, n_qubits, 3)}\n",
        "\n",
        "        @qml.qnode(dev, interface=\"torch\")\n",
        "        def qnode(inputs, weights):\n",
        "            # inputs: [n_qubits]\n",
        "            qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "            qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "        self.qnn = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "        # Quantum head\n",
        "        self.quantum_head = nn.Linear(n_qubits, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN embedding\n",
        "        emb = self.backbone(x)          # [B, emb_dim]\n",
        "\n",
        "        # Classical path\n",
        "        out_classical = self.class_head(emb)\n",
        "\n",
        "        # Quantum path\n",
        "        q_in = self.qproj(emb)          # [B, n_qubits]\n",
        "        q_out = self.qnn(q_in)          # [B, n_qubits]\n",
        "        out_quantum = self.quantum_head(q_out)\n",
        "\n",
        "        # Combine\n",
        "        return (out_classical + out_quantum) / 2\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.078576Z",
          "iopub.status.idle": "2025-11-29T10:16:13.078873Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.078723Z",
          "shell.execute_reply": "2025-11-29T10:16:13.078735Z"
        },
        "id": "ThJ9q4-htkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R3 – Init ResNet+QNN model, loss, optimizer\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", torch_device)\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "resnet_hybrid = HybridAudioResNetQNN(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_channels=1,\n",
        "    emb_dim=128,\n",
        "    n_qubits=10      # 2 more qubits than before\n",
        ").to(torch_device)\n",
        "\n",
        "criterion_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = torch.optim.Adam(resnet_hybrid.parameters(), lr=5e-4)\n",
        "\n",
        "print(\"Trainable params:\", sum(p.numel() for p in resnet_hybrid.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.079866Z",
          "iopub.status.idle": "2025-11-29T10:16:13.080064Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.079971Z",
          "shell.execute_reply": "2025-11-29T10:16:13.079979Z"
        },
        "id": "sHpu2ot8tkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R5 – Sanity check shapes\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch = x_batch.to(torch_device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb = resnet_hybrid.backbone(x_batch)\n",
        "    q_in = resnet_hybrid.qproj(emb)\n",
        "    q_out = resnet_hybrid.qnn(q_in)\n",
        "\n",
        "print(\"Input:\", x_batch.shape)\n",
        "print(\"Embedding:\", emb.shape)\n",
        "print(\"QNN input:\", q_in.shape)\n",
        "print(\"QNN output:\", q_out.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.082186Z",
          "iopub.status.idle": "2025-11-29T10:16:13.08249Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.082356Z",
          "shell.execute_reply": "2025-11-29T10:16:13.082372Z"
        },
        "id": "yCwP9Ozctkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "resnet_hybrid = HybridAudioResNetQNN(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_channels=1,\n",
        "    emb_dim=128,\n",
        "    n_qubits=10\n",
        ").to(torch_device)\n",
        "\n",
        "criterion_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = torch.optim.Adam(resnet_hybrid.parameters(), lr=5e-4)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.083497Z",
          "iopub.status.idle": "2025-11-29T10:16:13.083722Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.083611Z",
          "shell.execute_reply": "2025-11-29T10:16:13.083622Z"
        },
        "id": "HUPUhRn-tkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "CKPT_R = \"/kaggle/working/hybrid_resnet_qnn_ckpt.pth\"\n",
        "BEST_R = \"/kaggle/working/hybrid_resnet_qnn_best.pth\"\n",
        "HIST_R = \"/kaggle/working/hybrid_resnet_qnn_history.csv\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:28:10.199598Z",
          "iopub.execute_input": "2025-11-28T20:28:10.200373Z",
          "iopub.status.idle": "2025-11-28T20:28:10.204201Z",
          "shell.execute_reply.started": "2025-11-28T20:28:10.200346Z",
          "shell.execute_reply": "2025-11-28T20:28:10.203316Z"
        },
        "id": "6T1c_2kWtkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "\n",
        "CKPT_R = \"/kaggle/working/hybrid_resnet_qnn_ckpt.pth\"\n",
        "HIST_R = \"/kaggle/working/hybrid_resnet_qnn_history.csv\"\n",
        "\n",
        "print(os.listdir(\"/kaggle/working\"))\n",
        "\n",
        "hist = pd.read_csv(HIST_R)\n",
        "print(hist.tail())   # last logged epochs\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T20:28:12.103176Z",
          "iopub.execute_input": "2025-11-28T20:28:12.103433Z",
          "iopub.status.idle": "2025-11-28T20:28:12.115679Z",
          "shell.execute_reply.started": "2025-11-28T20:28:12.103414Z",
          "shell.execute_reply": "2025-11-28T20:28:12.114928Z"
        },
        "id": "ZxuODkPOtkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R2' – Hybrid ResNet + smaller 8-qubit QNN\n",
        "\n",
        "import pennylane as qml\n",
        "import torch.nn as nn\n",
        "\n",
        "class HybridAudioResNetQNN_8Q(nn.Module):\n",
        "    def __init__(self, num_classes=10, in_channels=1, emb_dim=128, n_qubits=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_qubits = n_qubits\n",
        "\n",
        "        # Stronger CNN backbone\n",
        "        self.backbone = AudioResNetBackbone(in_channels=in_channels, emb_dim=emb_dim)\n",
        "\n",
        "        # Classical head (same as before)\n",
        "        self.class_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # 128 -> n_qubits for quantum input\n",
        "        self.qproj = nn.Linear(emb_dim, n_qubits)\n",
        "\n",
        "        # Quantum device (GPU if available, else CPU)\n",
        "        dev = qml.device(\"lightning.gpu\", wires=n_qubits) if torch.cuda.is_available() \\\n",
        "              else qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "        # shallower circuit: 1 layer instead of 2\n",
        "        weight_shapes = {\"weights\": (1, n_qubits, 3)}\n",
        "\n",
        "        @qml.qnode(dev, interface=\"torch\")\n",
        "        def qnode(inputs, weights):\n",
        "            qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "            qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "        self.qnn = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.quantum_head = nn.Linear(n_qubits, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN embedding\n",
        "        emb = self.backbone(x)          # [B, emb_dim]\n",
        "\n",
        "        # Classical path\n",
        "        out_classical = self.class_head(emb)\n",
        "\n",
        "        # Quantum path\n",
        "        q_in = self.qproj(emb)          # [B, n_qubits]\n",
        "        q_out = self.qnn(q_in)          # [B, n_qubits]\n",
        "        out_quantum = self.quantum_head(q_out)\n",
        "\n",
        "        # Combine\n",
        "        return (out_classical + out_quantum) / 2\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.08639Z",
          "iopub.status.idle": "2025-11-29T10:16:13.086777Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.086504Z",
          "shell.execute_reply": "2025-11-29T10:16:13.086513Z"
        },
        "id": "IJKLn51ktkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R4 – Train ResNet+QNN hybrid\n",
        "\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "NUM_EPOCHS_RESNET = 15  # adjust if you want longer/shorter\n",
        "\n",
        "CKPT_R = \"/kaggle/working/hybrid_resnet_qnn_ckpt.pth\"\n",
        "BEST_R = \"/kaggle/working/hybrid_resnet_qnn_best.pth\"\n",
        "HIST_R = \"/kaggle/working/hybrid_resnet_qnn_history.csv\"\n",
        "\n",
        "best_val_acc_resnet = 0.0\n",
        "\n",
        "# Init history CSV\n",
        "with open(HIST_R, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
        "\n",
        "print(\"=== Training ResNet + QNN Hybrid ===\")\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_RESNET + 1):\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        resnet_hybrid, train_loader,\n",
        "        criterion_resnet, optimizer_resnet,\n",
        "        torch_device, epoch, NUM_EPOCHS_RESNET, log_interval=20\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = evaluate(\n",
        "        resnet_hybrid, val_loader,\n",
        "        criterion_resnet, torch_device, epoch, NUM_EPOCHS_RESNET\n",
        "    )\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        \"model_state_dict\": resnet_hybrid.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer_resnet.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"best_val_acc\": best_val_acc_resnet,\n",
        "    }, CKPT_R)\n",
        "    print(f\"[RESNET-CKPT] saved at epoch {epoch}\")\n",
        "\n",
        "    # Save best\n",
        "    if val_acc > best_val_acc_resnet:\n",
        "        best_val_acc_resnet = val_acc\n",
        "        torch.save(resnet_hybrid.state_dict(), BEST_R)\n",
        "        print(f\"[RESNET-BEST] updated → {BEST_R} (acc={best_val_acc_resnet:.4f})\")\n",
        "\n",
        "    # Log CSV\n",
        "    with open(HIST_R, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "\n",
        "print(\"\\n=== ResNet+QNN Training Finished ===\")\n",
        "print(\"Best Val Acc:\", best_val_acc_resnet)\n",
        "print(\"Checkpoint:\", CKPT_R)\n",
        "print(\"Best Model:\", BEST_R)\n",
        "print(\"History:\", HIST_R)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:16:13.085222Z",
          "iopub.status.idle": "2025-11-29T10:16:13.08552Z",
          "shell.execute_reply.started": "2025-11-29T10:16:13.085352Z",
          "shell.execute_reply": "2025-11-29T10:16:13.085366Z"
        },
        "id": "qjtcJidftkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R3' – Init 8-qubit hybrid model\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", torch_device)\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "resnet_hybrid = HybridAudioResNetQNN_8Q(\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_channels=1,\n",
        "    emb_dim=128,\n",
        "    n_qubits=8\n",
        ").to(torch_device)\n",
        "\n",
        "criterion_resnet = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = torch.optim.Adam(resnet_hybrid.parameters(), lr=5e-4)\n",
        "\n",
        "print(\"Trainable params:\", sum(p.numel() for p in resnet_hybrid.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T00:05:59.924018Z",
          "iopub.execute_input": "2025-11-29T00:05:59.924322Z",
          "iopub.status.idle": "2025-11-29T00:06:00.130121Z",
          "shell.execute_reply.started": "2025-11-29T00:05:59.924298Z",
          "shell.execute_reply": "2025-11-29T00:06:00.129511Z"
        },
        "id": "fNLURcNxtkzg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R4' – Train ResNet + 8-qubit QNN (shorter run)\n",
        "\n",
        "import csv, os, pandas as pd\n",
        "\n",
        "NUM_EPOCHS_RESNET = 10   # shorter than 15 → less than previous 3h+ run\n",
        "\n",
        "CKPT_R = \"/kaggle/working/hybrid_resnet_8q_ckpt.pth\"\n",
        "BEST_R = \"/kaggle/working/hybrid_resnet_8q_best.pth\"\n",
        "HIST_R = \"/kaggle/working/hybrid_resnet_8q_history.csv\"\n",
        "\n",
        "best_val_acc_resnet = 0.0\n",
        "\n",
        "# init history CSV\n",
        "with open(HIST_R, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
        "\n",
        "print(\"=== Training ResNet + 8Q QNN Hybrid ===\")\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS_RESNET + 1):\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        resnet_hybrid, train_loader,\n",
        "        criterion_resnet, optimizer_resnet,\n",
        "        torch_device, epoch, NUM_EPOCHS_RESNET, log_interval=20\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = evaluate(\n",
        "        resnet_hybrid, val_loader,\n",
        "        criterion_resnet, torch_device, epoch, NUM_EPOCHS_RESNET\n",
        "    )\n",
        "\n",
        "    # checkpoint\n",
        "    torch.save({\n",
        "        \"model_state_dict\": resnet_hybrid.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer_resnet.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"best_val_acc\": best_val_acc_resnet,\n",
        "    }, CKPT_R)\n",
        "    print(f\"[8Q-CKPT] saved at epoch {epoch}\")\n",
        "\n",
        "    # best\n",
        "    if val_acc > best_val_acc_resnet:\n",
        "        best_val_acc_resnet = val_acc\n",
        "        torch.save(resnet_hybrid.state_dict(), BEST_R)\n",
        "        print(f\"[8Q-BEST] updated -> {BEST_R} (acc={best_val_acc_resnet:.4f})\")\n",
        "\n",
        "    # history\n",
        "    with open(HIST_R, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "\n",
        "print(\"\\n=== 8Q ResNet+QNN Training Finished ===\")\n",
        "print(\"Best Val Acc:\", best_val_acc_resnet)\n",
        "print(\"Checkpoint:\", CKPT_R)\n",
        "print(\"Best Model:\", BEST_R)\n",
        "print(\"History:\", HIST_R)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T00:06:22.104208Z",
          "iopub.execute_input": "2025-11-29T00:06:22.104819Z",
          "iopub.status.idle": "2025-11-29T01:01:54.551327Z",
          "shell.execute_reply.started": "2025-11-29T00:06:22.104796Z",
          "shell.execute_reply": "2025-11-29T01:01:54.550377Z"
        },
        "id": "zlsR56ZHtkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "_QDYKHyBtkzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 0 – Start session & copy files from previous notebook run\n",
        "\n",
        "import os, shutil, sys\n",
        "\n",
        "print(\"INPUT root:\", os.listdir(\"/kaggle/input\"))\n",
        "\n",
        "NOTEBOOK_DIR = \"audio-leo\"   # <-- this is the key fix\n",
        "\n",
        "print(f\"Files in /kaggle/input/{NOTEBOOK_DIR}:\")\n",
        "print(os.listdir(f\"/kaggle/input/{NOTEBOOK_DIR}\"))\n",
        "\n",
        "FILES_TO_COPY = [\n",
        "    \"hybrid_resnet_8q_best.pth\",\n",
        "    \"hybrid_resnet_8q_ckpt.pth\",\n",
        "    \"hybrid_resnet_8q_history.csv\",\n",
        "    \"hybrid_resnet_qnn_best.pth\",\n",
        "    \"hybrid_resnet_qnn_ckpt.pth\",\n",
        "    \"hybrid_resnet_qnn_history.csv\",\n",
        "]\n",
        "\n",
        "src_root = f\"/kaggle/input/{NOTEBOOK_DIR}\"\n",
        "dst_root = \"/kaggle/working\"\n",
        "os.makedirs(dst_root, exist_ok=True)\n",
        "\n",
        "for fname in FILES_TO_COPY:\n",
        "    src = os.path.join(src_root, fname)\n",
        "    dst = os.path.join(dst_root, fname)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "        print(\"Copied:\", src, \"->\", dst)\n",
        "    else:\n",
        "        print(\"NOT FOUND in input:\", src)\n",
        "\n",
        "print(\"\\nNow in /kaggle/working:\")\n",
        "print(os.listdir(\"/kaggle/working\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:51:49.009849Z",
          "iopub.execute_input": "2025-11-29T10:51:49.010119Z",
          "iopub.status.idle": "2025-11-29T10:51:49.510225Z",
          "shell.execute_reply.started": "2025-11-29T10:51:49.010099Z",
          "shell.execute_reply": "2025-11-29T10:51:49.509429Z"
        },
        "id": "N5sA7oL-tkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane pennylane-lightning\n",
        "!pip install torchaudio librosa soundfile\n",
        "!pip install matplotlib seaborn tqdm\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T10:48:58.839282Z",
          "iopub.execute_input": "2025-11-29T10:48:58.839848Z",
          "iopub.status.idle": "2025-11-29T10:49:08.689172Z",
          "shell.execute_reply.started": "2025-11-29T10:48:58.839821Z",
          "shell.execute_reply": "2025-11-29T10:49:08.688414Z"
        },
        "id": "YEIuCuCytkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pennylane as qml\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:41.365464Z",
          "iopub.execute_input": "2025-11-29T11:00:41.366076Z",
          "iopub.status.idle": "2025-11-29T11:00:41.370499Z",
          "shell.execute_reply.started": "2025-11-29T11:00:41.366022Z",
          "shell.execute_reply": "2025-11-29T11:00:41.36985Z"
        },
        "id": "hbwXnT02tkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20 – Correct UrbanSound8K paths for flat layout\n",
        "\n",
        "METADATA_CSV = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\n",
        "AUDIO_ROOT   = \"/kaggle/input/urbansound8k\"   # <-- root, not /audio\n",
        "\n",
        "print(\"CSV exists:\", os.path.exists(METADATA_CSV))\n",
        "print(\"Audio exists:\", os.path.exists(AUDIO_ROOT))\n",
        "print(\"Example fold1 exists:\", os.path.exists(os.path.join(AUDIO_ROOT, \"fold1\")))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:41.894768Z",
          "iopub.execute_input": "2025-11-29T11:00:41.895047Z",
          "iopub.status.idle": "2025-11-29T11:00:41.902948Z",
          "shell.execute_reply.started": "2025-11-29T11:00:41.895026Z",
          "shell.execute_reply": "2025-11-29T11:00:41.902197Z"
        },
        "id": "sA0RUgFvtkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "import torchaudio.transforms as T\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, csv_path, audio_root, folds, transform=None):\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.df = self.df[self.df.fold.isin(folds)]\n",
        "        self.audio_root = audio_root\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        fold = row.fold\n",
        "        fname = row.slice_file_name\n",
        "        label = row.classID\n",
        "\n",
        "        path = f\"{self.audio_root}/fold{fold}/{fname}\"\n",
        "        wav, sr = torchaudio.load(path)\n",
        "\n",
        "        if self.transform:\n",
        "            wav = self.transform(wav)\n",
        "\n",
        "        return wav, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:42.919471Z",
          "iopub.execute_input": "2025-11-29T11:00:42.919962Z",
          "iopub.status.idle": "2025-11-29T11:00:42.925602Z",
          "shell.execute_reply.started": "2025-11-29T11:00:42.919936Z",
          "shell.execute_reply": "2025-11-29T11:00:42.924944Z"
        },
        "id": "JdN1UasTtkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "transform_waveform_to_logmel = T.MelSpectrogram(\n",
        "    sample_rate=44100,\n",
        "    n_fft=1024,\n",
        "    hop_length=512,\n",
        "    n_mels=64\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:44.033912Z",
          "iopub.execute_input": "2025-11-29T11:00:44.034652Z",
          "iopub.status.idle": "2025-11-29T11:00:44.039741Z",
          "shell.execute_reply.started": "2025-11-29T11:00:44.034627Z",
          "shell.execute_reply": "2025-11-29T11:00:44.039153Z"
        },
        "id": "5QwLANmjtkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, csv_path, audio_root, folds, transform=None):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        self.df = df[df['fold'].isin(folds)]\n",
        "        self.audio_root = audio_root\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.audio_root, f\"fold{row['fold']}\", row['slice_file_name'])\n",
        "        wav = load_audio(path)\n",
        "        wav = pad_or_trim(wav)\n",
        "\n",
        "        mel = self.transform(wav) if self.transform else wav\n",
        "        return mel.unsqueeze(0), row['classID']\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:44.708935Z",
          "iopub.execute_input": "2025-11-29T11:00:44.709537Z",
          "iopub.status.idle": "2025-11-29T11:00:44.714428Z",
          "shell.execute_reply.started": "2025-11-29T11:00:44.709514Z",
          "shell.execute_reply": "2025-11-29T11:00:44.71373Z"
        },
        "id": "X_ox5Phytkzh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5\n",
        "train_folds = [1,2,3,4]\n",
        "val_folds   = [5]\n",
        "\n",
        "train_dataset = UrbanSoundDataset(\n",
        "    METADATA_CSV, AUDIO_ROOT, train_folds, transform_waveform_to_logmel\n",
        ")\n",
        "\n",
        "val_dataset = UrbanSoundDataset(\n",
        "    METADATA_CSV, AUDIO_ROOT, val_folds, transform_waveform_to_logmel\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Val samples:\", len(val_dataset))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:45.269332Z",
          "iopub.execute_input": "2025-11-29T11:00:45.270043Z",
          "iopub.status.idle": "2025-11-29T11:00:45.3005Z",
          "shell.execute_reply.started": "2025-11-29T11:00:45.270019Z",
          "shell.execute_reply": "2025-11-29T11:00:45.299706Z"
        },
        "id": "PnT6orY5tkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6 — Audio loading + log-mel transform\n",
        "import librosa\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "TARGET_SR = 32000\n",
        "TARGET_SAMPLES = 16000\n",
        "\n",
        "def load_audio(path, target_sr=TARGET_SR):\n",
        "    \"\"\"Load wav file and resample.\"\"\"\n",
        "    audio, sr = librosa.load(path, sr=None)\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "    return audio\n",
        "\n",
        "def pad_or_trim(waveform, max_len=TARGET_SAMPLES):\n",
        "    \"\"\"Pad or trim waveform to a fixed length.\"\"\"\n",
        "    if len(waveform) > max_len:\n",
        "        return waveform[:max_len]\n",
        "    else:\n",
        "        return np.pad(waveform, (0, max_len - len(waveform)))\n",
        "\n",
        "def waveform_to_logmel(waveform, sr=TARGET_SR, n_mels=64):\n",
        "    \"\"\"Convert waveform to log-mel spectrogram.\"\"\"\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=waveform,\n",
        "        sr=sr,\n",
        "        n_mels=n_mels,\n",
        "        fmin=20,\n",
        "        fmax=sr//2\n",
        "    )\n",
        "    logmel = librosa.power_to_db(mel).astype(np.float32)\n",
        "    return logmel\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:45.90983Z",
          "iopub.execute_input": "2025-11-29T11:00:45.910117Z",
          "iopub.status.idle": "2025-11-29T11:00:45.91695Z",
          "shell.execute_reply.started": "2025-11-29T11:00:45.910096Z",
          "shell.execute_reply": "2025-11-29T11:00:45.915929Z"
        },
        "id": "7HN0zuVYtkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7 — Dataset (FIXED PATHS)\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, audio_root, transform=None):\n",
        "        self.df = df\n",
        "        self.audio_root = audio_root\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # IMPORTANT: use the fold subfolder\n",
        "        fold = f\"fold{row['fold']}\"\n",
        "        audio_path = os.path.join(self.audio_root, fold, row[\"slice_file_name\"])\n",
        "\n",
        "        audio = load_audio(audio_path)\n",
        "        audio = pad_or_trim(audio)\n",
        "        mel = waveform_to_logmel(audio)\n",
        "\n",
        "        X = torch.tensor(mel).unsqueeze(0)  # (1, 64, time)\n",
        "        y = torch.tensor(row[\"classID\"]).long()\n",
        "\n",
        "        return X, y\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:46.624682Z",
          "iopub.execute_input": "2025-11-29T11:00:46.625367Z",
          "iopub.status.idle": "2025-11-29T11:00:46.630429Z",
          "shell.execute_reply.started": "2025-11-29T11:00:46.625341Z",
          "shell.execute_reply": "2025-11-29T11:00:46.629723Z"
        },
        "id": "Wx0oHXiKtkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8 — Load CSV & create datasets (FIXED ROOT)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "METADATA_CSV = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\n",
        "AUDIO_ROOT   = \"/kaggle/input/urbansound8k\"  # <-- NO /audio here\n",
        "\n",
        "df = pd.read_csv(METADATA_CSV)\n",
        "\n",
        "train_folds = [1, 2, 3, 4]\n",
        "val_folds   = [5]\n",
        "\n",
        "train_df = df[df.fold.isin(train_folds)]\n",
        "val_df   = df[df.fold.isin(val_folds)]\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, AUDIO_ROOT)\n",
        "val_dataset   = UrbanSoundDataset(val_df, AUDIO_ROOT)\n",
        "\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Val samples:\", len(val_dataset))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:00:47.289401Z",
          "iopub.execute_input": "2025-11-29T11:00:47.289652Z",
          "iopub.status.idle": "2025-11-29T11:00:47.311853Z",
          "shell.execute_reply.started": "2025-11-29T11:00:47.289633Z",
          "shell.execute_reply": "2025-11-29T11:00:47.311058Z"
        },
        "id": "scP6kVlAtkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 – Hybrid 8Q model (FIXED fc size)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class HybridResnet8Q(nn.Module):   # or HybridAudioCNN8Q – use your class name\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # --- your CNN backbone (keep as you have it now) ---\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),        # [B, 32, 32, 63]\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),        # [B, 64, 16, 31]\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),        # [B, 64, 8, 15] -> 64*8*8 = 4096 after crop\n",
        "        )\n",
        "\n",
        "        # --- FIX: work out the correct flatten size automatically ---\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, 64, 126)   # shape of your mel: [1,64,126]\n",
        "            feat = self.cnn(dummy)\n",
        "            flat_dim = feat.view(1, -1).size(1)  # should be 4096 on your setup\n",
        "\n",
        "        # --- classical head (uses flat_dim instead of hard-coded 10752) ---\n",
        "        self.class_head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(flat_dim, 128),   # <- FIXED: was 10752, now flat_dim (4096)\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # --- your QNN head (keep exactly as you had it) ---\n",
        "        # self.qnn_layer = ...\n",
        "        # self.quantum_head = nn.Linear(...)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, 64, 126] mel\n",
        "        feat = self.cnn(x)                  # [B, C, H, W]\n",
        "        out_classical = self.class_head(feat)\n",
        "\n",
        "        # if you have a QNN head, keep your original logic here:\n",
        "        # q_in = ...       # prepare features\n",
        "        # q_out = self.qnn_layer(q_in)\n",
        "        # out_quantum = self.quantum_head(q_out)\n",
        "        # return (out_classical + out_quantum) / 2\n",
        "\n",
        "        return out_classical\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:15:19.80451Z",
          "iopub.execute_input": "2025-11-29T11:15:19.805325Z",
          "iopub.status.idle": "2025-11-29T11:15:19.812414Z",
          "shell.execute_reply.started": "2025-11-29T11:15:19.805296Z",
          "shell.execute_reply": "2025-11-29T11:15:19.811477Z"
        },
        "id": "kesVcPxntkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 – Device, model, criterion, optimizer\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "num_classes = 10\n",
        "model = HybridResnet8Q(num_classes=num_classes).to(device)  # same class name as above\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:16:26.765604Z",
          "iopub.execute_input": "2025-11-29T11:16:26.766222Z",
          "iopub.status.idle": "2025-11-29T11:16:26.787621Z",
          "shell.execute_reply.started": "2025-11-29T11:16:26.766196Z",
          "shell.execute_reply": "2025-11-29T11:16:26.78667Z"
        },
        "id": "NXLneG-Wtkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11 – Dataloaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=0,      # <— was 2, set to 0 to avoid multiprocessing issues\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0,      # <— same here\n",
        ")\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:16:32.964471Z",
          "iopub.execute_input": "2025-11-29T11:16:32.96518Z",
          "iopub.status.idle": "2025-11-29T11:16:32.970235Z",
          "shell.execute_reply.started": "2025-11-29T11:16:32.965124Z",
          "shell.execute_reply": "2025-11-29T11:16:32.969457Z"
        },
        "id": "jMF1spPJtkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12 — Train one epoch\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    running_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        running_correct += (preds == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "    return running_loss / total, running_correct / total\n",
        "\n",
        "\n",
        "# CELL 12B — Evaluate\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    running_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device).float()\n",
        "            y = y.to(device)\n",
        "\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            preds = out.argmax(1)\n",
        "            running_correct += (preds == y).sum().item()\n",
        "            total += x.size(0)\n",
        "\n",
        "    return running_loss / total, running_correct / total\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:16:33.565171Z",
          "iopub.execute_input": "2025-11-29T11:16:33.565774Z",
          "iopub.status.idle": "2025-11-29T11:16:33.57236Z",
          "shell.execute_reply.started": "2025-11-29T11:16:33.565754Z",
          "shell.execute_reply": "2025-11-29T11:16:33.571605Z"
        },
        "id": "HcAW3lfatkzi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13 — Train model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "EPOCHS = 20\n",
        "best_acc = 0\n",
        "\n",
        "HIST = \"history.csv\"\n",
        "CKPT = \"best_model.pth\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f\"[{epoch}/{EPOCHS}] Train loss={train_loss:.4f} acc={train_acc:.4f} | Val loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), CKPT)\n",
        "        print(f\"Saved BEST model at epoch {epoch} (acc={best_acc:.4f})\")\n",
        "\n",
        "    # Append training log\n",
        "    with open(HIST, \"a\") as f:\n",
        "        f.write(f\"{epoch},{train_loss},{train_acc},{val_loss},{val_acc}\\n\")\n",
        "\n",
        "print(\"=== Training Finished ===\")\n",
        "print(\"Best Val Accuracy:\", best_acc)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:16:34.024305Z",
          "iopub.execute_input": "2025-11-29T11:16:34.024736Z",
          "iopub.status.idle": "2025-11-29T11:16:35.162353Z",
          "shell.execute_reply.started": "2025-11-29T11:16:34.024714Z",
          "shell.execute_reply": "2025-11-29T11:16:35.161345Z"
        },
        "id": "rCZDbSK5tkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and device selection\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"PennyLane version:\", qml.__version__)\n",
        "\n",
        "# Torch device: GPU if available, otherwise CPU (works on Kaggle and on laptop)\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:12:49.140179Z",
          "iopub.execute_input": "2025-11-29T13:12:49.14072Z",
          "iopub.status.idle": "2025-11-29T13:12:49.146163Z",
          "shell.execute_reply.started": "2025-11-29T13:12:49.140694Z",
          "shell.execute_reply": "2025-11-29T13:12:49.145304Z"
        },
        "id": "srkn31Hwtkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 (UPDATED): Heavier audio CNN backbone\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    \"\"\"\n",
        "    Input:  [B, 1, n_mels, T]\n",
        "    Output: [B, emb_dim] embedding (emb_dim=256)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),          # [B, 32, n_mels/2, T/2]\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),          # [B, 64, n_mels/4, T/4]\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),          # [B, 128, n_mels/8, T/8]\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),          # [B, 256, n_mels/16, T/16]\n",
        "        )\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)           # [B, 256, 1, 1]\n",
        "        x = torch.flatten(x, 1)           # [B, 256]\n",
        "        return x\n",
        "\n",
        "# Quick shape check\n",
        "with torch.no_grad():\n",
        "    dummy = torch.randn(4, 1, 64, 126)\n",
        "    backbone_big = AudioCNNBackboneBig(in_channels=1)\n",
        "    out = backbone_big(dummy)\n",
        "    print(\"BackboneBig output shape:\", out.shape)   # [4, 256]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:12:51.074664Z",
          "iopub.execute_input": "2025-11-29T13:12:51.075351Z",
          "iopub.status.idle": "2025-11-29T13:12:51.109459Z",
          "shell.execute_reply.started": "2025-11-29T13:12:51.075327Z",
          "shell.execute_reply": "2025-11-29T13:12:51.108656Z"
        },
        "id": "LbvVmFaMtkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: PennyLane QNN setup with automatic GPU/CPU device selection\n",
        "\n",
        "# We keep qubit count small to make training feasible.\n",
        "N_QUBITS = 8\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    \"\"\"\n",
        "    Create a PennyLane device.\n",
        "    Preference:\n",
        "      1. lightning.gpu (if CUDA is available and plugin works)\n",
        "      2. lightning.qubit (fast CPU)\n",
        "      3. default.qubit (fallback)\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        # Try GPU device\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu (GPU)\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"Could not use lightning.gpu, reason:\", repr(e))\n",
        "\n",
        "    # Try fast CPU device\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit (CPU)\")\n",
        "        return dev\n",
        "    except Exception as e:\n",
        "        print(\"Could not use lightning.qubit, reason:\", repr(e))\n",
        "\n",
        "    # Final fallback\n",
        "    dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "    print(\"PennyLane device: default.qubit (CPU, basic)\")\n",
        "    return dev\n",
        "\n",
        "\n",
        "# Variational circuit\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    inputs:  shape [N_QUBITS]\n",
        "    weights: shape [N_Q_LAYERS, N_QUBITS, 3]\n",
        "    returns: expectation values on each qubit -> [N_QUBITS]\n",
        "    \"\"\"\n",
        "    # Encode features\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "\n",
        "    # Variational layers\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            # 3 trainable angles per qubit\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        # Simple entangling pattern (ring of CZ gates)\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w + 1) % N_QUBITS])\n",
        "\n",
        "    # Measurements\n",
        "    return [qml.expval(qml.PauliZ(w)) for w in range(N_QUBITS)]\n",
        "\n",
        "\n",
        "# Weight shape for TorchLayer\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    layer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "    return layer\n",
        "\n",
        "\n",
        "# Sanity check that the QNN works\n",
        "qnn_layer = create_qnn_layer()\n",
        "x_test = torch.randn(4, N_QUBITS)   # batch of 4, each 8 features\n",
        "y_test = qnn_layer(x_test)\n",
        "print(\"QNN input shape:\", x_test.shape)\n",
        "print(\"QNN output shape:\", y_test.shape)  # [4, 8]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:12:53.324993Z",
          "iopub.execute_input": "2025-11-29T13:12:53.325665Z",
          "iopub.status.idle": "2025-11-29T13:12:53.492406Z",
          "shell.execute_reply.started": "2025-11-29T13:12:53.325635Z",
          "shell.execute_reply": "2025-11-29T13:12:53.491681Z"
        },
        "id": "EQFRIsXWtkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 (UPDATED): Hybrid model using the big backbone\n",
        "\n",
        "class HybridAudioCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes: int,\n",
        "                 in_channels: int = 1,\n",
        "                 alpha: float = 1.0,\n",
        "                 beta: float = 0.5):\n",
        "        \"\"\"\n",
        "        alpha, beta: weights for classical and quantum logits.\n",
        "        Slightly down-weight quantum head (beta) at start for stability.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = AudioCNNBackboneBig(in_channels=in_channels)\n",
        "        emb_dim = self.backbone.emb_dim   # 256\n",
        "\n",
        "        # Classical head: a bit deeper\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Quantum path\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads: bool = False):\n",
        "        features = self.backbone(x)                  # [B, emb_dim]\n",
        "\n",
        "        # Classical path\n",
        "        logits_classical = self.classical_head(features)\n",
        "\n",
        "        # Quantum path\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))   # [B, N_QUBITS] in [-1,1]\n",
        "        q_outputs = self.qnn(q_inputs)                  # [B, N_QUBITS]\n",
        "        logits_quantum = self.quantum_head(q_outputs)   # [B, num_classes]\n",
        "\n",
        "        logits = self.alpha * logits_classical + self.beta * logits_quantum\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_classical, logits_quantum\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Re-instantiate model with updated architecture\n",
        "NUM_CLASSES = num_classes  # from Cell 9 metadata\n",
        "hybrid_model = HybridAudioCNNQNN(num_classes=NUM_CLASSES).to(torch_device)\n",
        "\n",
        "total_params = sum(p.numel() for p in hybrid_model.parameters() if p.requires_grad)\n",
        "print(hybrid_model)\n",
        "print(f\"Hybrid model trainable parameters: {total_params:,}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:12:54.594602Z",
          "iopub.execute_input": "2025-11-29T13:12:54.59509Z",
          "iopub.status.idle": "2025-11-29T13:12:54.629419Z",
          "shell.execute_reply.started": "2025-11-29T13:12:54.595067Z",
          "shell.execute_reply": "2025-11-29T13:12:54.628826Z"
        },
        "id": "b_qwVTmJtkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Sanity check for forward pass (this also confirms bug-free dimensions)\n",
        "\n",
        "with torch.no_grad():\n",
        "    dummy_batch = torch.randn(32, 1, 64, 126).to(torch_device)\n",
        "    hybrid_model.eval()\n",
        "    out = hybrid_model(dummy_batch)\n",
        "    print(\"Model output shape:\", out.shape)   # expected [32, NUM_CLASSES]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:12:57.425082Z",
          "iopub.execute_input": "2025-11-29T13:12:57.425703Z",
          "iopub.status.idle": "2025-11-29T13:12:58.842725Z",
          "shell.execute_reply.started": "2025-11-29T13:12:57.425681Z",
          "shell.execute_reply": "2025-11-29T13:12:58.84209Z"
        },
        "id": "bu9mBV3ptkzj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Training and validation loops (works with your existing DataLoaders)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch=None, num_epochs=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    desc = \"Train\"\n",
        "    if epoch is not None and num_epochs is not None:\n",
        "        desc = f\"Train [{epoch}/{num_epochs}]\"\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=desc, leave=False)\n",
        "\n",
        "    for mel, labels in progress_bar:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(mel)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"loss\": f\"{running_loss / total:.4f}\",\n",
        "            \"acc\": f\"{100.0 * correct / total:.2f}%\"\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in dataloader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:01.904253Z",
          "iopub.execute_input": "2025-11-29T13:13:01.904877Z",
          "iopub.status.idle": "2025-11-29T13:13:01.913229Z",
          "shell.execute_reply.started": "2025-11-29T13:13:01.904851Z",
          "shell.execute_reply": "2025-11-29T13:13:01.9124Z"
        },
        "id": "nx98WkcZtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Example training loop usage (plug in your own train_loader / val_loader)\n",
        "\n",
        "# Assume you already defined:\n",
        "#   train_loader, val_loader = ...\n",
        "# and maybe a scheduler, etc.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(hybrid_model.parameters(), lr=1e-3)\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model, train_loader, criterion, optimizer,\n",
        "        device=torch_device, epoch=epoch, num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model, val_loader, criterion, device=torch_device\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T11:29:56.894923Z",
          "iopub.execute_input": "2025-11-29T11:29:56.895646Z",
          "iopub.status.idle": "2025-11-29T13:04:52.136692Z",
          "shell.execute_reply.started": "2025-11-29T11:29:56.895619Z",
          "shell.execute_reply": "2025-11-29T13:04:52.135916Z"
        },
        "id": "1ylyaarBtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Load UrbanSound8K CSV metadata\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "CSV_PATH = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\n",
        "DATASET_PATH = \"/kaggle/input/urbansound8k\"\n",
        "\n",
        "metadata = pd.read_csv(CSV_PATH)\n",
        "print(metadata.head())\n",
        "\n",
        "class_names = sorted(metadata[\"class\"].unique())\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Num classes:\", num_classes)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:05.888811Z",
          "iopub.execute_input": "2025-11-29T13:13:05.889098Z",
          "iopub.status.idle": "2025-11-29T13:13:05.916871Z",
          "shell.execute_reply.started": "2025-11-29T13:13:05.889076Z",
          "shell.execute_reply": "2025-11-29T13:13:05.916231Z"
        },
        "id": "8IpHu1WVtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10 (UPDATED): UrbanSoundDataset with MelSpectrogram + AmplitudeToDB\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, dataset_path, sr=22050, n_mels=64, duration=4.0):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dataset_path = dataset_path\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.samples = int(sr * duration)\n",
        "\n",
        "        # Mel spectrogram (power)\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2.0\n",
        "        )\n",
        "\n",
        "        # Safest way to convert to dB across torchaudio versions:\n",
        "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
        "            stype=\"power\",  # because MelSpectrogram(power=2.0)\n",
        "            top_db=80.0\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def load_audio(self, row):\n",
        "        fold = row[\"fold\"]\n",
        "        file_name = row[\"slice_file_name\"]\n",
        "        path = f\"{self.dataset_path}/fold{fold}/{file_name}\"\n",
        "\n",
        "        y, sr = librosa.load(path, sr=self.sr)\n",
        "\n",
        "        # Pad / crop to fixed length\n",
        "        if len(y) < self.samples:\n",
        "            y = np.pad(y, (0, self.samples - len(y)))\n",
        "        else:\n",
        "            y = y[:self.samples]\n",
        "\n",
        "        return torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        waveform = self.load_audio(row)              # [T]\n",
        "\n",
        "        mel = self.mel_transform(waveform.unsqueeze(0))  # [1, n_mels, T']\n",
        "        mel_db = self.db_transform(mel)                  # [1, n_mels, T']\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:08.62433Z",
          "iopub.execute_input": "2025-11-29T13:13:08.625012Z",
          "iopub.status.idle": "2025-11-29T13:13:08.632772Z",
          "shell.execute_reply.started": "2025-11-29T13:13:08.624989Z",
          "shell.execute_reply": "2025-11-29T13:13:08.632025Z"
        },
        "id": "Xz_h2itPtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Train/validation split based on folds (recommended)\n",
        "\n",
        "train_df = metadata[metadata[\"fold\"] <= 8]   # folds 1–8\n",
        "val_df   = metadata[metadata[\"fold\"] == 9]   # fold 9\n",
        "test_df  = metadata[metadata[\"fold\"] == 10]  # fold 10 (optional)\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Validation size:\", len(val_df))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:09.804354Z",
          "iopub.execute_input": "2025-11-29T13:13:09.804921Z",
          "iopub.status.idle": "2025-11-29T13:13:09.812696Z",
          "shell.execute_reply.started": "2025-11-29T13:13:09.804898Z",
          "shell.execute_reply": "2025-11-29T13:13:09.811854Z"
        },
        "id": "xsK4bractkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12 (UPDATED): Create dataloaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH)\n",
        "val_dataset   = UrbanSoundDataset(val_df, DATASET_PATH)\n",
        "\n",
        "# Slightly bigger batch + more workers → better GPU utilization\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "print(\"Loader ready.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:12.887943Z",
          "iopub.execute_input": "2025-11-29T13:13:12.888328Z",
          "iopub.status.idle": "2025-11-29T13:13:12.897182Z",
          "shell.execute_reply.started": "2025-11-29T13:13:12.888304Z",
          "shell.execute_reply": "2025-11-29T13:13:12.896475Z"
        },
        "id": "Y7aIEvITtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14 (UPDATED): Train Hybrid CNN+QNN\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    hybrid_model.parameters(),\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "NUM_EPOCHS = 15\n",
        "history = []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        hybrid_model, train_loader, criterion, optimizer,\n",
        "        device=torch_device, epoch=epoch, num_epochs=NUM_EPOCHS\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = evaluate(\n",
        "        hybrid_model, val_loader, criterion, device=torch_device\n",
        "    )\n",
        "\n",
        "    history.append([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T13:13:14.589741Z",
          "iopub.execute_input": "2025-11-29T13:13:14.590289Z",
          "iopub.status.idle": "2025-11-29T17:11:16.586577Z",
          "shell.execute_reply.started": "2025-11-29T13:13:14.590264Z",
          "shell.execute_reply": "2025-11-29T17:11:16.585792Z"
        },
        "id": "pTIisPoItkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Save model (fixed path)\n",
        "\n",
        "import os\n",
        "\n",
        "SAVE_PATH = \"/kaggle/working/hybrid_cnn_qnn_best.pth\"\n",
        "torch.save(hybrid_model.state_dict(), SAVE_PATH)\n",
        "\n",
        "print(\"Saved model to:\", SAVE_PATH)\n",
        "print(\"Existing files in /kaggle/working:\")\n",
        "print(os.listdir(\"/kaggle/working\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:20:27.125225Z",
          "iopub.execute_input": "2025-11-29T17:20:27.125808Z",
          "iopub.status.idle": "2025-11-29T17:20:27.138106Z",
          "shell.execute_reply.started": "2025-11-29T17:20:27.125782Z",
          "shell.execute_reply": "2025-11-29T17:20:27.137338Z"
        },
        "id": "xxtI84EVtkzk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Load model (fixed path)\n",
        "\n",
        "import os\n",
        "\n",
        "LOAD_PATH = \"/kaggle/working/hybrid_cnn_qnn_best.pth\"\n",
        "\n",
        "if not os.path.exists(LOAD_PATH):\n",
        "    raise FileNotFoundError(f\"Model file not found at: {LOAD_PATH}\")\n",
        "\n",
        "model2 = HybridAudioCNNQNN(num_classes=num_classes).to(torch_device)\n",
        "model2.load_state_dict(torch.load(LOAD_PATH, map_location=torch_device))\n",
        "model2.eval()\n",
        "\n",
        "print(\"Model loaded from:\", LOAD_PATH)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:20:51.68497Z",
          "iopub.execute_input": "2025-11-29T17:20:51.685535Z",
          "iopub.status.idle": "2025-11-29T17:20:51.731239Z",
          "shell.execute_reply.started": "2025-11-29T17:20:51.685509Z",
          "shell.execute_reply": "2025-11-29T17:20:51.730642Z"
        },
        "id": "Tg95TR0Jtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Predict a single audio file\n",
        "\n",
        "def predict_audio(path):\n",
        "    y, sr = librosa.load(path, sr=22050)\n",
        "\n",
        "    # pad/crop\n",
        "    if len(y) < 22050*4:\n",
        "        y = np.pad(y, (0, 22050*4 - len(y)))\n",
        "    else:\n",
        "        y = y[:22050*4]\n",
        "\n",
        "    y_t = torch.tensor(y).float()\n",
        "\n",
        "    mel = train_dataset.mel_transform(y_t.unsqueeze(0))\n",
        "    mel = torchaudio.functional.amplitude_to_DB(mel, multiplier=10, amin=1e-10)\n",
        "\n",
        "    mel = mel.unsqueeze(0).to(torch_device)  # [1,1,64,T]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model2(mel)\n",
        "        pred = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    print(\"Prediction:\", class_names[pred])\n",
        "    return pred\n",
        "\n",
        "# example:\n",
        "# predict_audio(\"/kaggle/input/urbansound8k/fold1/7061-6-0-0.wav\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:21:15.024315Z",
          "iopub.execute_input": "2025-11-29T17:21:15.024805Z",
          "iopub.status.idle": "2025-11-29T17:21:15.030501Z",
          "shell.execute_reply.started": "2025-11-29T17:21:15.024781Z",
          "shell.execute_reply": "2025-11-29T17:21:15.029565Z"
        },
        "id": "vmKJ6w7Jtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Confusion Matrix\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model2.eval()\n",
        "with torch.no_grad():\n",
        "    for mel, labels in val_loader:\n",
        "        mel = mel.to(torch_device)\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        preds = model2(mel).argmax(1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:21:21.536414Z",
          "iopub.execute_input": "2025-11-29T17:21:21.536689Z",
          "iopub.status.idle": "2025-11-29T17:22:10.028416Z",
          "shell.execute_reply.started": "2025-11-29T17:21:21.536669Z",
          "shell.execute_reply": "2025-11-29T17:22:10.027683Z"
        },
        "id": "K1NoG6q0tkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20: Compare the two heads independently\n",
        "\n",
        "def forward_separate(x):\n",
        "    logits, classical, quantum = hybrid_model(x, return_heads=True)\n",
        "    return classical, quantum\n",
        "\n",
        "with torch.no_grad():\n",
        "    mel, labels = next(iter(val_loader))\n",
        "    mel = mel.to(torch_device)\n",
        "\n",
        "    classical_logits, quantum_logits = forward_separate(mel)\n",
        "\n",
        "print(\"Classical logits shape:\", classical_logits.shape)\n",
        "print(\"Quantum logits shape:\", quantum_logits.shape)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:22:34.964252Z",
          "iopub.execute_input": "2025-11-29T17:22:34.96528Z",
          "iopub.status.idle": "2025-11-29T17:22:39.925775Z",
          "shell.execute_reply.started": "2025-11-29T17:22:34.965251Z",
          "shell.execute_reply": "2025-11-29T17:22:39.925058Z"
        },
        "id": "5CFfSEUrtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 21: Install and import Gradio\n",
        "\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:26:25.019195Z",
          "iopub.execute_input": "2025-11-29T17:26:25.019977Z",
          "iopub.status.idle": "2025-11-29T17:26:35.419221Z",
          "shell.execute_reply.started": "2025-11-29T17:26:25.019947Z",
          "shell.execute_reply": "2025-11-29T17:26:35.418553Z"
        },
        "id": "U6J2Uus-tkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 22: Preprocessing and prediction function for uploaded audio\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_single_audio(path, sr=22050, duration=4.0):\n",
        "    \"\"\"\n",
        "    Load an audio file and convert it into the same log-mel format\n",
        "    used during training, using train_dataset's transforms.\n",
        "    \"\"\"\n",
        "    target_len = int(sr * duration)\n",
        "\n",
        "    # Load\n",
        "    y, sr = librosa.load(path, sr=sr)\n",
        "\n",
        "    # Pad / crop to fixed length\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    else:\n",
        "        y = y[:target_len]\n",
        "\n",
        "    y_t = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    # Use the same transforms as the training dataset\n",
        "    mel = train_dataset.mel_transform(y_t.unsqueeze(0))   # [1, n_mels, T]\n",
        "    mel_db = train_dataset.db_transform(mel)              # [1, n_mels, T]\n",
        "\n",
        "    # Add batch dimension for model: [1, 1, n_mels, T]\n",
        "    mel_db = mel_db.unsqueeze(0)\n",
        "    return mel_db\n",
        "\n",
        "\n",
        "def classify_audio_gradio(audio_path):\n",
        "    \"\"\"\n",
        "    Gradio callback:\n",
        "    - audio_path: path to uploaded/recorded file\n",
        "    Returns:\n",
        "      - dict[label] = prob (for Gradio Label)\n",
        "      - string \"PRED: <label> (prob%)\"\n",
        "    \"\"\"\n",
        "    if audio_path is None:\n",
        "        return {}, \"No audio provided.\"\n",
        "\n",
        "    # Preprocess\n",
        "    mel_db = preprocess_single_audio(audio_path)   # [1, 1, 64, T]\n",
        "    mel_db = mel_db.to(torch_device)\n",
        "\n",
        "    # Model inference\n",
        "    hybrid_model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = hybrid_model(mel_db)             # [1, num_classes]\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]  # [num_classes]\n",
        "\n",
        "    # Build dict for Gradio Label (label -> prob)\n",
        "    label_probs = {\n",
        "        class_names[i]: float(probs[i]) for i in range(len(class_names))\n",
        "    }\n",
        "\n",
        "    # Top-3\n",
        "    top3_idx = np.argsort(probs)[::-1][:3]\n",
        "    top3_labels = [class_names[i] for i in top3_idx]\n",
        "    top3_probs = [probs[i] for i in top3_idx]\n",
        "\n",
        "    pred_label = top3_labels[0]\n",
        "    pred_prob = top3_probs[0]\n",
        "\n",
        "    pred_text = \"PRED: {} ({:.2f}%)\\n\\nTop 3:\\n\".format(pred_label, pred_prob * 100.0)\n",
        "    for rank, (lbl, p) in enumerate(zip(top3_labels, top3_probs), start=1):\n",
        "        pred_text += f\"{rank}) {lbl}: {p*100:.2f}%\\n\"\n",
        "\n",
        "    return label_probs, pred_text\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:26:59.439732Z",
          "iopub.execute_input": "2025-11-29T17:26:59.440967Z",
          "iopub.status.idle": "2025-11-29T17:26:59.450073Z",
          "shell.execute_reply.started": "2025-11-29T17:26:59.44093Z",
          "shell.execute_reply": "2025-11-29T17:26:59.449444Z"
        },
        "id": "n0QDHHKXtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 23: Launch Gradio interface\n",
        "\n",
        "audio_input = gr.Audio(\n",
        "    sources=[\"upload\", \"microphone\"],\n",
        "    type=\"filepath\",\n",
        "    label=\"Upload or record an UrbanSound8K-style clip (wav)\"\n",
        ")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=classify_audio_gradio,\n",
        "    inputs=audio_input,\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Top-3 probabilities\"),\n",
        "        gr.Textbox(label=\"Prediction (PRED + Top 3)\")\n",
        "    ],\n",
        "    title=\"Hybrid CNN + QNN UrbanSound Classifier\",\n",
        "    description=\"Upload a sound and get the top-3 predicted classes. 'PRED' is the highest-probability class.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:27:08.884845Z",
          "iopub.execute_input": "2025-11-29T17:27:08.885699Z",
          "iopub.status.idle": "2025-11-29T17:37:51.235429Z",
          "shell.execute_reply.started": "2025-11-29T17:27:08.885672Z",
          "shell.execute_reply": "2025-11-29T17:37:51.234716Z"
        },
        "id": "dOzYJebYtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: List working directory contents\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Files available in /kaggle/working/:\")\n",
        "for f in os.listdir(\"/kaggle/working\"):\n",
        "    print(\" -\", f)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:38:22.010023Z",
          "iopub.execute_input": "2025-11-29T17:38:22.010739Z",
          "iopub.status.idle": "2025-11-29T17:38:22.015828Z",
          "shell.execute_reply.started": "2025-11-29T17:38:22.01071Z",
          "shell.execute_reply": "2025-11-29T17:38:22.015033Z"
        },
        "id": "Lmie95I4tkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: Save final clean model\n",
        "import torch\n",
        "\n",
        "FINAL_MODEL_PATH = \"/kaggle/working/final_hybrid_cnn_qnn_model.pth\"\n",
        "torch.save(hybrid_model.state_dict(), FINAL_MODEL_PATH)\n",
        "\n",
        "print(\"Saved final model to:\", FINAL_MODEL_PATH)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:38:46.758416Z",
          "iopub.execute_input": "2025-11-29T17:38:46.758715Z",
          "iopub.status.idle": "2025-11-29T17:38:46.771993Z",
          "shell.execute_reply.started": "2025-11-29T17:38:46.758694Z",
          "shell.execute_reply": "2025-11-29T17:38:46.771413Z"
        },
        "id": "ls7KvsyVtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C: Save training history\n",
        "import pandas as pd\n",
        "\n",
        "history_df = pd.DataFrame(history, columns=[\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n",
        "HISTORY_PATH = \"/kaggle/working/final_training_history.csv\"\n",
        "\n",
        "history_df.to_csv(HISTORY_PATH, index=False)\n",
        "print(\"Saved training history to:\", HISTORY_PATH)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:39:11.249119Z",
          "iopub.execute_input": "2025-11-29T17:39:11.249899Z",
          "iopub.status.idle": "2025-11-29T17:39:11.26435Z",
          "shell.execute_reply.started": "2025-11-29T17:39:11.249873Z",
          "shell.execute_reply": "2025-11-29T17:39:11.263668Z"
        },
        "id": "ap_S1EdTtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D: Save confusion matrix image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# generate again\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "hybrid_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for mel, labels in val_loader:\n",
        "        mel = mel.to(torch_device)\n",
        "        labels = labels.to(torch_device)\n",
        "        preds = hybrid_model(mel).argmax(1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "\n",
        "CM_PATH = \"/kaggle/working/confusion_matrix.png\"\n",
        "plt.savefig(CM_PATH)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved confusion matrix to:\", CM_PATH)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:39:33.534676Z",
          "iopub.execute_input": "2025-11-29T17:39:33.535525Z",
          "iopub.status.idle": "2025-11-29T17:40:01.891356Z",
          "shell.execute_reply.started": "2025-11-29T17:39:33.535494Z",
          "shell.execute_reply": "2025-11-29T17:40:01.890568Z"
        },
        "id": "NZ63y0zqtkzl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E: Create a README file describing your saved model\n",
        "\n",
        "readme_text = f\"\"\"\n",
        "Hybrid CNN + QNN Audio Classifier\n",
        "=================================\n",
        "\n",
        "Models saved:\n",
        " - final_hybrid_cnn_qnn_model.pth  (Main model)\n",
        " - hybrid_cnn_qnn_best.pth         (Best checkpoint during training)\n",
        " - *_ckpt.pth                      (Intermediate checkpoints)\n",
        "\n",
        "Dataset:\n",
        " - UrbanSound8K\n",
        "\n",
        "Model details:\n",
        " - Backbone: AudioCNNBackboneBig (256-d embedding)\n",
        " - Quantum layer: {N_QUBITS} qubits, {N_Q_LAYERS} layers\n",
        " - Combination: alpha=1.0, beta=0.5\n",
        " - Training device: {torch_device}\n",
        "\n",
        "Included files:\n",
        " - final_training_history.csv\n",
        " - confusion_matrix.png\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/kaggle/working/README.txt\", \"w\") as f:\n",
        "    f.write(readme_text)\n",
        "\n",
        "print(\"Saved README to /kaggle/working/README.txt\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:40:27.851081Z",
          "iopub.execute_input": "2025-11-29T17:40:27.851486Z",
          "iopub.status.idle": "2025-11-29T17:40:27.857785Z",
          "shell.execute_reply.started": "2025-11-29T17:40:27.851457Z",
          "shell.execute_reply": "2025-11-29T17:40:27.856993Z"
        },
        "id": "S6MicOtatkzm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell F: Zip all saved artifacts\n",
        "\n",
        "!zip -r /kaggle/working/final_hybrid_model_package.zip /kaggle/working/\n",
        "print(\"Created /kaggle/working/final_hybrid_model_package.zip\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-29T17:40:47.47423Z",
          "iopub.execute_input": "2025-11-29T17:40:47.474829Z",
          "iopub.status.idle": "2025-11-29T17:41:06.445731Z",
          "shell.execute_reply.started": "2025-11-29T17:40:47.474804Z",
          "shell.execute_reply": "2025-11-29T17:41:06.444827Z"
        },
        "id": "fTjq6syytkzm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab version :"
      ],
      "metadata": {
        "id": "vo9M-B84tkzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import librosa\n",
        "import torchaudio\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "W2AUPGL4uWkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = pd.read_csv(CSV_PATH)\n",
        "print(metadata.head())\n",
        "\n",
        "class_names = sorted(metadata[\"class\"].unique())\n",
        "num_classes = len(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuQ5uBi1uYeY",
        "outputId": "28b83e81-b790-47e6-bff3-abf77b57148c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  \n",
            "0          dog_bark  \n",
            "1  children_playing  \n",
            "2  children_playing  \n",
            "3  children_playing  \n",
            "4  children_playing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, dataset_path, sr=22050, n_mels=64, duration=4.0):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dataset_path = dataset_path\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.samples = int(sr * duration)\n",
        "\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2\n",
        "        )\n",
        "\n",
        "        self.db_transform = torchaudio.transforms.AmplitudeToDB(stype=\"power\", top_db=80)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def load_audio(self, row):\n",
        "        fold = row[\"fold\"]\n",
        "        file_name = row[\"slice_file_name\"]\n",
        "        path = f\"{self.dataset_path}/fold{fold}/{file_name}\"\n",
        "\n",
        "        y, sr = librosa.load(path, sr=self.sr)\n",
        "\n",
        "        if len(y) < self.samples:\n",
        "            y = np.pad(y, (0, self.samples - len(y)))\n",
        "        else:\n",
        "            y = y[:self.samples]\n",
        "\n",
        "        return torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        waveform = self.load_audio(row)\n",
        "\n",
        "        mel = self.mel_transform(waveform.unsqueeze(0))\n",
        "        mel_db = self.db_transform(mel)\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n"
      ],
      "metadata": {
        "id": "ZlUoH2U7ubFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = metadata[metadata[\"fold\"] <= 8]\n",
        "val_df   = metadata[metadata[\"fold\"] == 9]\n"
      ],
      "metadata": {
        "id": "OnlQrDf8ud9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH)\n",
        "val_dataset   = UrbanSoundDataset(val_df, DATASET_PATH)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=1)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False, num_workers=1)\n"
      ],
      "metadata": {
        "id": "QkW-Jfg8ugmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================\n",
        "# STEP 9 — Hybrid Model (CNN Backbone + QNN Head)\n",
        "# ===========================================================\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch Device:\", torch_device)\n",
        "\n",
        "# --------------------------\n",
        "# 9.1: PennyLane device setup\n",
        "# --------------------------\n",
        "\n",
        "N_QUBITS = 8\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    \"\"\"\n",
        "    Prefer GPU → then lightning.qubit → fallback default.qubit.\n",
        "    Works on Kaggle AND Colab.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU not available for PennyLane:\", e)\n",
        "\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "    print(\"PennyLane device: default.qubit\")\n",
        "    return dev\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 9.2: QNode + TorchLayer\n",
        "# --------------------------\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    inputs: [N_QUBITS]\n",
        "    weights: [N_Q_LAYERS, N_QUBITS, 3]\n",
        "    output: expvals [N_QUBITS]\n",
        "    \"\"\"\n",
        "    # Embed classical features\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "\n",
        "    # Variational layers\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "\n",
        "        # Entanglement ring\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w+1) % N_QUBITS])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "    return qlayer\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 9.3: Big CNN Backbone\n",
        "# --------------------------\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    \"\"\"\n",
        "    Input shape: [B, 1, n_mels, T]\n",
        "    Output: 256-d embedding\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# 9.4: Hybrid CNN + QNN model\n",
        "# --------------------------\n",
        "\n",
        "class HybridAudioCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes, alpha=1.0, beta=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        # CNN Backbone\n",
        "        self.backbone = AudioCNNBackboneBig()\n",
        "        emb_dim = self.backbone.emb_dim  # 256\n",
        "\n",
        "        # Classical head\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Quantum head\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        # Mixture weights\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # ---- Classical path\n",
        "        logits_c = self.classical_head(features)\n",
        "\n",
        "        # ---- Quantum path\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))\n",
        "        q_out = self.qnn(q_inputs)\n",
        "        logits_q = self.quantum_head(q_out)\n",
        "\n",
        "        # ---- Combine\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n",
        "\n",
        "\n",
        "# --------------------------\n",
        "# Quick test\n",
        "# --------------------------\n",
        "\n",
        "hybrid_model = HybridAudioCNNQNN(num_classes=num_classes).to(torch_device)\n",
        "\n",
        "dummy = torch.randn(2, 1, 64, 126).to(torch_device)\n",
        "out = hybrid_model(dummy)\n",
        "\n",
        "print(\"Hybrid model output:\", out.shape)\n",
        "print(\"Step 9 is working!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-uJuF7SuiL9",
        "outputId": "4a01ab19-0d4c-49ff-8611-763d4af1edc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Device: cuda\n",
            "PennyLane device: lightning.gpu\n",
            "Hybrid model output: torch.Size([2, 10])\n",
            "Step 9 is working!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_colab = HybridAudioCNNQNN(num_classes=num_classes).to(torch.device(\"cuda\"))\n",
        "model_colab.load_state_dict(torch.load(FINAL_MODEL_PATH, map_location=\"cuda\"))\n",
        "model_colab.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4FkBY4zvSfl",
        "outputId": "e60cf8e3-cb80-4fd9-884e-ef54151cf594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridAudioCNNQNN(\n",
              "  (backbone): AudioCNNBackboneBig(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): ReLU()\n",
              "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (10): ReLU()\n",
              "      (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (14): ReLU()\n",
              "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classical_head): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.3, inplace=False)\n",
              "    (7): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              "  (fc_to_q): Linear(in_features=256, out_features=8, bias=True)\n",
              "  (qnn): <Quantum Torch Layer: func=qnn_circuit>\n",
              "  (quantum_head): Linear(in_features=8, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# STEP 10 — Step-up Training (COLAB + KAGGLE SAFE AMP)\n",
        "# ======================================================\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "device = torch_device  # usually \"cuda\"\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model_colab.parameters(),\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=10\n",
        ")\n",
        "\n",
        "# AMP scaler (old API but fully compatible)\n",
        "scaler = GradScaler()\n",
        "\n",
        "\n",
        "def train_one_epoch_amp(model, dataloader, criterion, optimizer, device, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    from tqdm.auto import tqdm\n",
        "    pbar = tqdm(dataloader, desc=\"Train\", leave=False)\n",
        "\n",
        "    for mel, labels in pbar:\n",
        "        mel = mel.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{running_loss/total:.4f}\",\n",
        "            \"acc\":  f\"{100.0 * correct/total:.2f}%\"\n",
        "        })\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in dataloader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "# ==============================================\n",
        "# Continue training for EXTRA_EPOCHS\n",
        "# ==============================================\n",
        "\n",
        "EXTRA_EPOCHS = 7\n",
        "\n",
        "for epoch in range(1, EXTRA_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch_amp(\n",
        "        model_colab, train_loader, criterion, optimizer, device, scaler\n",
        "    )\n",
        "    val_loss, val_acc = evaluate(model_colab, val_loader, criterion, device)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[FT Epoch {epoch:02d}] \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "\n",
        "# ==============================================\n",
        "# Save fine-tuned weights\n",
        "# ==============================================\n",
        "\n",
        "FT_MODEL_PATH = OUTPUT_PATH + \"/final_hybrid_cnn_qnn_model_finetuned_colab.pth\"\n",
        "torch.save(model_colab.state_dict(), FT_MODEL_PATH)\n",
        "print(\"Saved fine-tuned model to:\", FT_MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "997c8c2dee5642c7a2d37bfc9ab4d1b7",
            "d0bcb14b08314411bdca24b91cd727f0",
            "b9bb13e0a74140498e6b0541fad3b6fb",
            "b1d14bab06cd42b1a8c0c9a43ec16452",
            "67952384a9e14971bc0f30edc257ee29",
            "bd348dc5a0d241dfbc36023fa7ea4466",
            "33a50d6989d447d1a80060150e047d72",
            "2ad0fe19ffd441c291dbeb89f3d6b55a",
            "aa6ed41e10f8457b832a7049a141da98",
            "801455c43ef0445d9d6d489baa39e169",
            "5882b760b0d3433c9bc5f064b63d82a1",
            "ec26e924ac8c4a67b2e23f4f9d58d615",
            "7632cf560422424589d69566748b932e",
            "9918a6e4da7c4c4a83b20b42388c9922",
            "4cbd57c2c5c84a9b97375d0b41553600",
            "2cdf271d89004794924ec5a8a873bc5b",
            "b70295aede5f4bf19bb9f9f8459b96fc",
            "b175f62429384c12924457a03f3f12a8",
            "3a0755a00f484ffcbcd32313211f24fa",
            "786dd17ecfcf4c7c9518468775c62975",
            "6d1a0bab80fe41008b7f24b1ed191f74",
            "d4fd0f4e56ed4f16a70fab9dc139188d",
            "c5c9f694f9ef48a29e2a0b7f7413db05",
            "073f7f47cca34c8194a133ce0cb004ed",
            "ad7b1871c5734b118d735d46a7a4d645",
            "21f5ff2663544121ba9643a7531b48be",
            "be18476941e34a1483361f6b33bc27c7",
            "497b6c3d8c50471c8bb1749e803a68b8",
            "6cb5aef1b57f4199964a7219da82b48d",
            "2cd6ef7b6fd247c0b4bb8a439da9ad0e",
            "7f0378297888477380ee6edaebcc390a",
            "5a88591e147b48e0becd9135ac0cccf0",
            "2c62569ab74040f2be41eaa58951a89c",
            "c62f23ebbbb2459d8983f4ef4f20ba53",
            "b1dff32f20c54949912402d98534f4c2",
            "04ad33548e0f40e488b5d58e1177f606",
            "7143b75d73c646a289a9744ff49c650f",
            "b6f8f40d6e0e421db0b347e7e15f75aa",
            "30424a97a29549fb9bcf1ce63469b7ef",
            "8ed644d26150469aa2da4fd547cc9cdd",
            "4b612d03e0214706a405782bd9e6e890",
            "52f595f5ff1f4ac485cd056f1e967658",
            "610a58d58e0247a79d4f7e046f712f60",
            "1b61822ddbe84cdebfeba3acf5405db2",
            "280fb856de264e0e9c9e3088925021eb",
            "55e04b05c2eb451daca4a3ab8b5d1da9",
            "6187837960a34c8b9a4c82d3e1dd0d8a",
            "d2aedd3af4e34c9b87b01ae7cedf0c3f",
            "79def67722924daabc1f264b3044ab93",
            "ae85463a8fe64e489cacf61bfc44017d",
            "eedb0155abed4ead89d133a0e7d364d1",
            "4ec4f4ec55e040cd8e99c1b70aeeebb5",
            "2589799e39c44ab1babf8a28499b64b9",
            "bb35b7c190aa485bb916c807b556eed9",
            "8c7c72f7e0474f39a9aa82be0b5b1cc4",
            "9176f1ae339c48ffa504468e93802f6a",
            "ade70d62e0204efbac87cbfeda080615",
            "a10d58d3e3cb4529ba17e1cd476f13d0",
            "752a18615e864ef68667a07f903a1955",
            "8a8226d7605142a781a6cff1a8920004",
            "cf524b91712a46bc8b7a30b3b779f40f",
            "f115d47d13884590921550e8aa03deb1",
            "4bb49aa6e3ef46ad9b2561141274a09d",
            "71e31d44f0c7479fbe7fa08cb453aa89",
            "0ddeedfe69744a84a8897833e34f82fd",
            "e35af60662b04a6f8f18496bf50513e1",
            "faea1f34809f4c78a9a1b2250bf5573a",
            "4d75d8ccf43f4d39ab7b09f135fb0fd8",
            "cabe6b473f394f46a53e313620c0cc42",
            "618a0a78fa9a4de68d1aeb895596fc80",
            "0877ff1c32824410b51cb496166c4e90",
            "570fec5b81a045928a5779fb5bbf1dbc",
            "9546d1ca8b2348f684088b82ff1d74d6",
            "32acce55a3fd4dae81b1997b2aaf4212",
            "e6cc0c7488b1485d98e297b91f5ae7da",
            "b48d1995a3d644349ee2b7f8772b8608",
            "892662eb6006466a87ea9a3cb3544809"
          ]
        },
        "collapsed": true,
        "id": "-ZycgBlxvXq2",
        "outputId": "6c7e2f79-fa77-4997-f035-bbff9bd8fd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-818980047.py:23: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "997c8c2dee5642c7a2d37bfc9ab4d1b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-818980047.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 01] train_loss=0.6235, train_acc=97.99% | val_loss=1.1835, val_acc=75.49%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec26e924ac8c4a67b2e23f4f9d58d615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 02] train_loss=0.6151, train_acc=98.18% | val_loss=1.0571, val_acc=79.78%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c9f694f9ef48a29e2a0b7f7413db05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 03] train_loss=0.5933, train_acc=98.94% | val_loss=1.0224, val_acc=80.64%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c62f23ebbbb2459d8983f4ef4f20ba53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 04] train_loss=0.5849, train_acc=99.21% | val_loss=1.1599, val_acc=77.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "280fb856de264e0e9c9e3088925021eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 05] train_loss=0.5705, train_acc=99.52% | val_loss=1.1062, val_acc=79.04%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9176f1ae339c48ffa504468e93802f6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 06] train_loss=0.5644, train_acc=99.68% | val_loss=1.1337, val_acc=77.57%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faea1f34809f4c78a9a1b2250bf5573a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT Epoch 07] train_loss=0.5577, train_acc=99.80% | val_loss=1.0954, val_acc=77.70%\n",
            "Saved fine-tuned model to: /content/drive/MyDrive/kaggle/audio_leo_outputs/final_hybrid_cnn_qnn_model_finetuned_colab.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell FT-1: Load fine-tuned Colab model\n",
        "\n",
        "FT_MODEL_PATH = OUTPUT_PATH + \"/final_hybrid_cnn_qnn_model_finetuned_colab.pth\"\n",
        "print(\"Loading fine-tuned model from:\", FT_MODEL_PATH)\n",
        "\n",
        "model_ft = HybridAudioCNNQNN(num_classes=num_classes).to(torch_device)\n",
        "model_ft.load_state_dict(torch.load(FT_MODEL_PATH, map_location=torch_device))\n",
        "model_ft.eval()\n",
        "\n",
        "print(\"Fine-tuned model loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fan3Y5HYvBz",
        "outputId": "c9f1be2c-6811-4379-a6cc-3074a47cc40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fine-tuned model from: /content/drive/MyDrive/kaggle/audio_leo_outputs/final_hybrid_cnn_qnn_model_finetuned_colab.pth\n",
            "PennyLane device: lightning.gpu\n",
            "Fine-tuned model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell FT-2: Updated Gradio classify function using fine-tuned model\n",
        "\n",
        "def classify_audio_gradio(audio_path):\n",
        "    if audio_path is None:\n",
        "        return {}, \"No audio provided.\"\n",
        "\n",
        "    mel_db = preprocess_single_audio(audio_path)   # [1, 1, 64, T]\n",
        "    mel_db = mel_db.to(torch_device)\n",
        "\n",
        "    model_ft.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model_ft(mel_db)\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    label_probs = {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
        "\n",
        "    top3_idx = np.argsort(probs)[::-1][:3]\n",
        "    top3_labels = [class_names[i] for i in top3_idx]\n",
        "    top3_probs = [probs[i] for i in top3_idx]\n",
        "\n",
        "    pred_label = top3_labels[0]\n",
        "    pred_prob = top3_probs[0]\n",
        "\n",
        "    pred_text = \"PRED: {} ({:.2f}%)\\n\\nTop 3:\\n\".format(pred_label, pred_prob * 100.0)\n",
        "    for rank, (lbl, p) in enumerate(zip(top3_labels, top3_probs), start=1):\n",
        "        pred_text += f\"{rank}) {lbl}: {p*100:.2f}%\\n\"\n",
        "\n",
        "    return label_probs, pred_text\n"
      ],
      "metadata": {
        "id": "14OhG5xeYvZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install & import Gradio\n",
        "!pip install -q gradio\n",
        "\n",
        "import gradio as gr\n"
      ],
      "metadata": {
        "id": "xpr7BvXpZDUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New: preprocess audio that comes from Gradio as (sr, numpy_array)\n",
        "\n",
        "def preprocess_audio_array(audio_array, sr_in, sr_target=22050, duration=4.0):\n",
        "    \"\"\"\n",
        "    audio_array: np.array from Gradio (shape [T] or [T, channels])\n",
        "    sr_in: original sample rate from Gradio\n",
        "    Returns: mel_db tensor [1, 1, n_mels, T'] on torch_device\n",
        "    \"\"\"\n",
        "    y = np.array(audio_array, dtype=np.float32)\n",
        "\n",
        "    # If stereo, convert to mono\n",
        "    if y.ndim > 1:\n",
        "        y = np.mean(y, axis=1)\n",
        "\n",
        "    # Resample if needed\n",
        "    if sr_in != sr_target:\n",
        "        y = librosa.resample(y, orig_sr=sr_in, target_sr=sr_target)\n",
        "\n",
        "    target_len = int(sr_target * duration)\n",
        "    if len(y) < target_len:\n",
        "        y = np.pad(y, (0, target_len - len(y)))\n",
        "    else:\n",
        "        y = y[:target_len]\n",
        "\n",
        "    y_t = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    # Use the SAME transforms as the training dataset\n",
        "    mel = train_dataset.mel_transform(y_t.unsqueeze(0))  # [1, n_mels, T]\n",
        "    mel_db = train_dataset.db_transform(mel)             # [1, n_mels, T]\n",
        "\n",
        "    mel_db = mel_db.unsqueeze(0)                         # [1, 1, n_mels, T]\n",
        "    mel_db = mel_db.to(torch_device)\n",
        "\n",
        "    return mel_db\n"
      ],
      "metadata": {
        "id": "sImKL3jfbr5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated classify function that accepts Gradio's (sr, audio) input\n",
        "\n",
        "def classify_audio_gradio(gradio_audio):\n",
        "    \"\"\"\n",
        "    gradio_audio: (sample_rate, np.ndarray) from gr.Audio(type=\"numpy\")\n",
        "    Returns:\n",
        "      - dict(label -> prob) for gr.Label\n",
        "      - text summary for gr.Textbox\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if gradio_audio is None:\n",
        "            return {}, \"No audio provided.\"\n",
        "\n",
        "        sr_in, audio_array = gradio_audio\n",
        "\n",
        "        # Preprocess to log-mel on correct device\n",
        "        mel_db = preprocess_audio_array(audio_array, sr_in)  # [1, 1, 64, T]\n",
        "\n",
        "        model_ft.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model_ft(mel_db)\n",
        "            probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        # Build dict for Gradio label\n",
        "        label_probs = {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
        "\n",
        "        # Top-3\n",
        "        top3_idx = np.argsort(probs)[::-1][:3]\n",
        "        top3_labels = [class_names[i] for i in top3_idx]\n",
        "        top3_probs = [probs[i] for i in top3_idx]\n",
        "\n",
        "        pred_label = top3_labels[0]\n",
        "        pred_prob = top3_probs[0]\n",
        "\n",
        "        pred_text = \"PRED: {} ({:.2f}%)\\n\\nTop 3:\\n\".format(pred_label, pred_prob * 100.0)\n",
        "        for rank, (lbl, p) in enumerate(zip(top3_labels, top3_probs), start=1):\n",
        "            pred_text += f\"{rank}) {lbl}: {p*100:.2f}%\\n\"\n",
        "\n",
        "        return label_probs, pred_text\n",
        "\n",
        "    except Exception as e:\n",
        "        # If anything goes wrong, show the error in the textbox instead of a red Gradio error\n",
        "        return {}, f\"ERROR during classification:\\n{repr(e)}\"\n"
      ],
      "metadata": {
        "id": "2IYU2IErbuvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relaunch Gradio UI (using numpy audio)\n",
        "\n",
        "audio_input = gr.Audio(\n",
        "    sources=[\"upload\", \"microphone\"],\n",
        "    type=\"numpy\",  # IMPORTANT: now we expect (sr, np.ndarray)\n",
        "    label=\"Upload or record an UrbanSound8K-style clip (wav/mp3)\"\n",
        ")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=classify_audio_gradio,\n",
        "    inputs=audio_input,\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Top-3 probabilities\"),\n",
        "        gr.Textbox(label=\"Prediction (PRED + Top 3)\")\n",
        "    ],\n",
        "    title=\"Hybrid CNN + QNN UrbanSound Classifier (Fine-tuned in Colab)\",\n",
        "    description=\"Upload a sound and get the top-3 predicted classes. 'PRED' is the highest-probability class.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "NSq9wYPIbwwy",
        "outputId": "e5fb35a5-f3d0-476b-a744-662752a686ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://59ba9223a04a2a27b0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://59ba9223a04a2a27b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fixing the overfitting and data spliting :"
      ],
      "metadata": {
        "id": "psij-7jCwzVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fast debug mode: use small subset and fewer folds\n",
        "FAST_DEBUG = True  # set to False for THE BIG TRAINING\n"
      ],
      "metadata": {
        "id": "OWl5gGMC0HzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell S1 (updated): UrbanSound8K split with optional fast debug mode\n",
        "\n",
        "metadata = pd.read_csv(CSV_PATH)\n",
        "\n",
        "if FAST_DEBUG:\n",
        "    # Use fewer folds and sample subset for quick experiments\n",
        "    train_folds = [1, 2]      # small amount of data\n",
        "    val_folds   = [3]\n",
        "    test_folds  = [4]         # just to have something\n",
        "\n",
        "    train_df = metadata[metadata[\"fold\"].isin(train_folds)].reset_index(drop=True)\n",
        "    val_df   = metadata[metadata[\"fold\"].isin(val_folds)].reset_index(drop=True)\n",
        "    test_df  = metadata[metadata[\"fold\"].isin(test_folds)].reset_index(drop=True)\n",
        "\n",
        "    # use only a fraction (e.g. 30%) of training data\n",
        "    train_df = train_df.sample(frac=0.3, random_state=0).reset_index(drop=True)\n",
        "\n",
        "    print(\"**FAST DEBUG MODE**\")\n",
        "else:\n",
        "    # Full protocol for BIG TRAINING\n",
        "    train_folds = list(range(1, 9))  # 1-8\n",
        "    val_folds   = [9]\n",
        "    test_folds  = [10]\n",
        "\n",
        "    train_df = metadata[metadata[\"fold\"].isin(train_folds)].reset_index(drop=True)\n",
        "    val_df   = metadata[metadata[\"fold\"].isin(val_folds)].reset_index(drop=True)\n",
        "    test_df  = metadata[metadata[\"fold\"].isin(test_folds)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Val samples:\", len(val_df))\n",
        "print(\"Test samples:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6lVig9yxFdM",
        "outputId": "6d448390-e9f0-4270-ed73-cef0d290f562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**FAST DEBUG MODE**\n",
            "Train samples: 528\n",
            "Val samples: 925\n",
            "Test samples: 990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell S2: UrbanSoundDataset with optional augmentation\n",
        "\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, dataset_path, sr=22050, n_mels=64, duration=4.0, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dataset_path = dataset_path\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.samples = int(sr * duration)\n",
        "        self.augment = augment\n",
        "\n",
        "        # Mel spectrogram (power)\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2.0\n",
        "        )\n",
        "        # dB\n",
        "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
        "            stype=\"power\",\n",
        "            top_db=80.0\n",
        "        )\n",
        "\n",
        "        # Augmentation on mel: time & freq masking\n",
        "        if augment:\n",
        "            self.time_mask = torchaudio.transforms.TimeMasking(time_mask_param=20)\n",
        "            self.freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=8)\n",
        "        else:\n",
        "            self.time_mask = None\n",
        "            self.freq_mask = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def load_audio(self, row):\n",
        "        fold = row[\"fold\"]\n",
        "        file_name = row[\"slice_file_name\"]\n",
        "        path = f\"{self.dataset_path}/fold{fold}/{file_name}\"\n",
        "\n",
        "        y, sr = librosa.load(path, sr=self.sr)\n",
        "\n",
        "        if len(y) < self.samples:\n",
        "            y = np.pad(y, (0, self.samples - len(y)))\n",
        "        else:\n",
        "            y = y[:self.samples]\n",
        "\n",
        "        return torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        waveform = self.load_audio(row)          # [T]\n",
        "\n",
        "        mel = self.mel_transform(waveform.unsqueeze(0))   # [1, n_mels, T']\n",
        "        mel_db = self.db_transform(mel)                  # [1, n_mels, T']\n",
        "\n",
        "        if self.augment and self.time_mask is not None:\n",
        "            mel_db = self.time_mask(mel_db)\n",
        "            mel_db = self.freq_mask(mel_db)\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n"
      ],
      "metadata": {
        "id": "7LdALd0xxnL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell S3: Dataloaders: train (augmented), val, test\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   DATASET_PATH, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  DATASET_PATH, augment=False)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n",
        "print(\"Test batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqzGRaBvxp5E",
        "outputId": "7880cc03-4b82-4db7-9de8-b15b1c1ff37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 9\n",
            "Val batches: 15\n",
            "Test batches: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell S4: Hybrid model with a bit more dropout regularization\n",
        "\n",
        "import pennylane as qml\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "N_QUBITS = 8\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU device failed, fallback to lightning.qubit:\", e)\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except:\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w+1) % N_QUBITS])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.05),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.15),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class HybridAudioCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes, alpha=1.0, beta=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackboneBig()\n",
        "        emb_dim = self.backbone.emb_dim\n",
        "\n",
        "        # Classical head with a bit more dropout\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # Quantum path\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        logits_c = self.classical_head(features)\n",
        "\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))\n",
        "        q_out = self.qnn(q_inputs)\n",
        "        logits_q = self.quantum_head(q_out)\n",
        "\n",
        "        #logits = self.alpha * logits_c + self.beta * logits_q #for debuging set to of\n",
        "        logits = logits_c   # ignore quantum head in fast debug\n",
        "\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n",
        "\n",
        "\n",
        "num_classes = len(metadata[\"class\"].unique())\n",
        "model_for_big = HybridAudioCNNQNN(num_classes=num_classes).to(torch_device)\n",
        "\n",
        "print(\"Hybrid model ready. Params:\",\n",
        "      sum(p.numel() for p in model_for_big.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ujemiu3xxcm",
        "outputId": "e92220fb-4bf6-4633-ee84-4ffcc555335a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n",
            "PennyLane device: lightning.gpu\n",
            "Hybrid model ready. Params: 491484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell S5: Training config with weight decay + early stopping\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model_for_big.parameters(),\n",
        "    lr=3e-4,\n",
        "    weight_decay=5e-4,   # a bit stronger regularization\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "#MAX_EPOCHS = 20 / PATIENCE = 5  # early stopping patience\n",
        "MAX_EPOCHS = 5   # for FAST_DEBUG; we’ll increase later\n",
        "PATIENCE = 3\n",
        "\n",
        "\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "history = []\n",
        "\n",
        "def train_one_epoch_amp(model, dataloader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    from tqdm.auto import tqdm\n",
        "    pbar = tqdm(dataloader, desc=\"Train\", leave=False)\n",
        "\n",
        "    for mel, labels in pbar:\n",
        "        mel = mel.to(torch_device)\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(torch_device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{running_loss/total:.4f}\",\n",
        "            acc=f\"{100.0*correct/total:.2f}%\"\n",
        "        )\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "def evaluate_plain(model, dataloader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in dataloader:\n",
        "            mel = mel.to(torch_device)\n",
        "            labels = labels.to(torch_device)\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch_amp(model_for_big, train_loader)\n",
        "    val_loss, val_acc = evaluate_plain(model_for_big, val_loader)\n",
        "\n",
        "    history.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_acc\": val_acc,\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    # Early stopping logic\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(model_for_big.state_dict(),\n",
        "                   OUTPUT_PATH + \"/hybrid_cnn_qnn_big_pretrain_best.pth\")\n",
        "        print(\"  -> New best model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  -> No improvement ({patience_counter}/{PATIENCE})\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280,
          "referenced_widgets": [
            "0c96776290724b90a27ad34cb497f03a",
            "d4d5cd2af2e147cca0f7e1120d4dc87f",
            "9540021ae13c4d669edeee28836c3dc9",
            "44616b9fb25a40ebb31f9c187b4e46f2",
            "12038b3b16bd4efaa5848fb3fe53a0e1",
            "0dc58817165b4583bc6986445f134e93",
            "a62be1ad8fb543d2931f4c0237bd1801",
            "1e747ecf50644d51b72396a997cadfe9",
            "c5efa0aee28d431483f59e63fabf6ba9",
            "0461951189164733b083e9aae761b303",
            "0f98dc7c8f334d3bb788bdab4a43730c",
            "fe35e20873bb4b4bba4d3b0c12fbdde2",
            "e5df3d09481640ff85a71658391a4224",
            "3be72b2682b34f20ac759b5504f0b501",
            "85981f5dcb9d4c36af7494d875f6e300",
            "22bf6bd1e25d46d2a5d4fcc3df5ffc49",
            "3c8112341c444d06ae72b5e7497c5310",
            "bc12b21db07b45f7837297f074b3b48c",
            "f6792589aa6543d1891edf9b68e6796d",
            "9c1208cec3494efd84f8b023981a2882",
            "9e179110b4d54c3a84ca162b4fe2a7df",
            "86b5db52353c43ea8be2352934c2a3a9",
            "fec1fb65d88041ffae5f9cce4c10311b",
            "c8374ccff1854fbcadd4a34c9c187d71",
            "c1e02ce200a14095b89904a0c08181e0",
            "d0a2c8a703cb43d4b45d4ee949b83dde",
            "e4c8630f44e34443a652159f2daf4ab0",
            "091baa76a18c44f4b654ac773f4f3c17",
            "2588e151cdcd46baac131cd01827875e",
            "f7710d20cb44449bb9964895cbc44f69",
            "29a9e15107bf4f33b61e122eafc630ad",
            "a967380430564df4a7102de3e3763691",
            "830ddfada0384c6bb4a012d740c21562",
            "59f2f33927e94c3ba5d37f9ab9865893",
            "df091e75fbe24f4497ac78b0c2b0e2c1",
            "83f1fff6e4104898b19319fbb8e61dbd",
            "b73eaa86e2cf4a7b835c99a05bc0246e",
            "331e288bce19401dbc57ee6ab1f9fcc5",
            "21bc6c8760624b84945693a355fa5d71",
            "19d47eee79bf4264b9510db3a269d22e",
            "1e49daf36a7f4ae0b3ddf190dd5d473c",
            "952b027bd697476c89779c78c24453e9",
            "231003f2ea034a6aa800a810ba927ba6",
            "a7d86aaf4be644b085c45cf111102e85",
            "df040bfad19446f7a648c7f000cdb1a6",
            "81ae03d95dfc4c828d7f9705bdb8ff12",
            "b7ebb8a3a1954c54b46599b1da0d3dcc",
            "32f95e3a249c46658f11d81a098b2073",
            "781eeb7797c34d5ab08c13f89200093f",
            "5bf924747a884285b8c9dee2c88f0922",
            "fc97b268be4a452ab800e3f62cf1014c",
            "4d22bf901b874799830e8635b42383f8",
            "b96d87f7fe524b40acc45b42c2761209",
            "6c43afba6e6f4aa288a67c1a3255a76e",
            "b42b322317984535a9ecc27e70ce1204"
          ]
        },
        "id": "Bg96K9_yx0QG",
        "outputId": "1bc314dd-a366-4fb3-fbab-a5ad61a221f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2004615306.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c96776290724b90a27ad34cb497f03a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2004615306.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(torch_device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=2.2844, train_acc=14.58% | val_loss=2.2917, val_acc=21.19%\n",
            "  -> New best model saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe35e20873bb4b4bba4d3b0c12fbdde2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02: train_loss=2.2049, train_acc=20.45% | val_loss=2.2520, val_acc=24.11%\n",
            "  -> New best model saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fec1fb65d88041ffae5f9cce4c10311b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03: train_loss=2.1216, train_acc=26.33% | val_loss=2.2040, val_acc=26.05%\n",
            "  -> New best model saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59f2f33927e94c3ba5d37f9ab9865893"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04: train_loss=2.0662, train_acc=27.65% | val_loss=2.1664, val_acc=24.22%\n",
            "  -> No improvement (1/3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df040bfad19446f7a648c7f000cdb1a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05: train_loss=2.0204, train_acc=29.55% | val_loss=2.1464, val_acc=26.59%\n",
            "  -> New best model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C1: checkpoint path (keep this exactly as you set it)\n",
        "\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_cnn_qnn_big_pretrain_best.pth\"\n",
        "print(\"Checkpoint:\", CHECKPOINT_PATH)\n"
      ],
      "metadata": {
        "id": "nmcvHc2Vx4z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e0b85a-9ff4-4962-cd3d-ee7a8241960c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint: /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_cnn_qnn_big_pretrain_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C2: Hybrid model with dropout regularization (EXACTLY as in Kaggle)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "N_QUBITS = 8\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU device failed, fallback to lightning.qubit:\", e)\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except Exception:\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w+1) % N_QUBITS])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.05),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.15),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.2),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class HybridAudioCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes, alpha=1.0, beta=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackboneBig()\n",
        "        emb_dim = self.backbone.emb_dim\n",
        "\n",
        "        # classical head\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "        # quantum path\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        logits_c = self.classical_head(features)\n",
        "\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))\n",
        "        q_out = self.qnn(q_inputs)\n",
        "        logits_q = self.quantum_head(q_out)\n",
        "\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsiMRdba2TMT",
        "outputId": "2a48a14b-4aa1-4686-e66f-12f6234ba4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D1: load UrbanSound8K metadata and make train/val/test splits\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "CSV_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\"\n",
        "DATASET_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "\n",
        "metadata = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Same split as Kaggle big training: folds 1–8 train, 9 val, 10 test\n",
        "train_folds = list(range(1, 9))\n",
        "val_folds   = [9]\n",
        "test_folds  = [10]\n",
        "\n",
        "train_df = metadata[metadata[\"fold\"].isin(train_folds)].reset_index(drop=True)\n",
        "val_df   = metadata[metadata[\"fold\"].isin(val_folds)].reset_index(drop=True)\n",
        "test_df  = metadata[metadata[\"fold\"].isin(test_folds)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Val samples:\", len(val_df))\n",
        "print(\"Test samples:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpyf9chh6RK1",
        "outputId": "62548388-7df2-45f6-e242-3c94da4f4122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 7079\n",
            "Val samples: 816\n",
            "Test samples: 837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D2: UrbanSoundDataset definition\n",
        "\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, dataset_path, sr=22050, n_mels=64, duration=4.0, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dataset_path = dataset_path\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.samples = int(sr * duration)\n",
        "        self.augment = augment\n",
        "\n",
        "        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2.0,\n",
        "        )\n",
        "\n",
        "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
        "            stype=\"power\",\n",
        "            top_db=80.0\n",
        "        )\n",
        "\n",
        "        if augment:\n",
        "            self.time_mask = torchaudio.transforms.TimeMasking(time_mask_param=20)\n",
        "            self.freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=8)\n",
        "        else:\n",
        "            self.time_mask = None\n",
        "            self.freq_mask = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def load_audio(self, row):\n",
        "        fold = row[\"fold\"]\n",
        "        file_name = row[\"slice_file_name\"]\n",
        "        path = f\"{self.dataset_path}/fold{fold}/{file_name}\"\n",
        "\n",
        "        y, sr = librosa.load(path, sr=self.sr)\n",
        "\n",
        "        if len(y) < self.samples:\n",
        "            y = np.pad(y, (0, self.samples - len(y)))\n",
        "        else:\n",
        "            y = y[:self.samples]\n",
        "\n",
        "        return torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        waveform = self.load_audio(row)\n",
        "\n",
        "        mel = self.mel_transform(waveform.unsqueeze(0))\n",
        "        mel_db = self.db_transform(mel)\n",
        "\n",
        "        if self.augment and self.time_mask is not None:\n",
        "            mel_db = self.time_mask(mel_db)\n",
        "            mel_db = self.freq_mask(mel_db)\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n"
      ],
      "metadata": {
        "id": "dCtS1lI16tyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D3: dataloaders for train / val / test\n",
        "\n",
        "BATCH_SIZE = 512  # try 128 first; if still plenty of VRAM, you can bump to 256\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   DATASET_PATH, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  DATASET_PATH, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n",
        "print(\"Test batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYAnV-f56yfN",
        "outputId": "829b53e9-e0ea-4a5e-fbc3-25e8f8988341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 14\n",
            "Val batches: 2\n",
            "Test batches: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C3: instantiate model and load the Kaggle-trained weights\n",
        "\n",
        "# UrbanSound8K has 10 classes\n",
        "num_classes = 10\n",
        "print(\"num_classes:\", num_classes)\n",
        "\n",
        "model_colab = HybridAudioCNNQNN(num_classes=num_classes).to(torch_device)\n",
        "\n",
        "state = torch.load(CHECKPOINT_PATH, map_location=torch_device)\n",
        "\n",
        "missing, unexpected = model_colab.load_state_dict(state, strict=False)\n",
        "\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "model_colab.eval()  # or .train() if you want to continue training\n",
        "print(\"Checkpoint loaded into Colab model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu53582S60I0",
        "outputId": "738ce9dc-f563-4fc8-a6d2-db57519a45d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes: 10\n",
            "PennyLane device: lightning.gpu\n",
            "Missing keys: []\n",
            "Unexpected keys: []\n",
            "Checkpoint loaded into Colab model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C4: continue training in Colab from the loaded checkpoint\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.AdamW(model_colab.parameters(), lr=3e-4, weight_decay=5e-4)\n",
        "scaler = GradScaler()\n",
        "\n",
        "MAX_EPOCHS = 3      # small number for Colab fine-tune\n",
        "PATIENCE = 3\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "def train_one_epoch_amp(model, dataloader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    from tqdm.auto import tqdm\n",
        "    pbar = tqdm(dataloader, desc=\"Train\", leave=False)\n",
        "\n",
        "    for mel, labels in pbar:\n",
        "        mel = mel.to(torch_device)\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(torch_device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=f\"{running_loss/total:.4f}\",\n",
        "                         acc=f\"{100.0*correct/total:.2f}%\")\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def evaluate_plain(model, dataloader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in dataloader:\n",
        "            mel = mel.to(torch_device)\n",
        "            labels = labels.to(torch_device)\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch_amp(model_colab, train_loader)\n",
        "    val_loss, val_acc = evaluate_plain(model_colab, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        print(\"  -> New best in Colab\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  -> No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping in Colab.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "57ef480cff0c438e8baeb7f7b3d7bd6a",
            "f7c3d1e0c939429c87fb92e7ca441ec9",
            "963e938f06a846c89a13f9abecd6a943",
            "f813e7c7ff854039aa021fb834170207",
            "adfa4b343d574ef39a93e92924cf874a",
            "7ce5929c58b04cf5aff93e81b595787f",
            "48a4bd9e8f574c7c985ef6c81e917d96",
            "48ad34ab6db34ce7bdb029cad3134b5b",
            "b79721e213444016afb570da0d906030",
            "c5856b90b83f422b8b0ad33d94fa3d13",
            "f3d3830124e6495ba55dd0700ee238d7",
            "8526b299b7a045eb8237b9782b752f98",
            "b80a4f488a85490db8d34bad2fca334b",
            "06a5e8177c6e48c2af6a9f7d3bf90e9c",
            "c4888cec127445d59d8d5feafe7fd252",
            "39510bedb6b7420daaadacd91db0ef8b",
            "ae7138cccb7040ec8dfd9207bb1fbfd9",
            "7f2c5f00842f42d4b60abd7c38d3676e",
            "d699ca2848b344e38226172b899d0d00",
            "2810d97edeb049a194516f8c0506435d",
            "8b3bd89b30a44e96ba30871f9ed221e3",
            "c7dd37bcca7f4267b3a1f216733e20f7",
            "440b7a439c774ecd9a3d3de730f5eecd",
            "9303607605034a2b8b936a24c3bbcb4b",
            "049b24ca69034225ac8e9e81b501bf0c",
            "8234d99de75c4dc8865e42cd58b3b091",
            "074e89bd78c440d8abe216f2ff5cb929",
            "8138247b157047c895f7cb57fcbf2d15",
            "401d88c79d374f668625ec60ee40e482",
            "1da5083a92fd416bb1e3cd0aeca4279c",
            "396bacbfee9845a5a826472be2a2c337",
            "2a30e699df5d46d28590832195a9bb7c",
            "8adcf78c33b643f2b2f4c97ce15fd51d"
          ]
        },
        "id": "z4d5A4uC7DAM",
        "outputId": "27e13b1a-60bd-4191-8b42-a8032ebb432a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1242217572.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57ef480cff0c438e8baeb7f7b3d7bd6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1242217572.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(torch_device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=1.1778, train_acc=72.16% | val_loss=1.2199, val_acc=72.55%\n",
            "  -> New best in Colab\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8526b299b7a045eb8237b9782b752f98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02: train_loss=1.1624, train_acc=73.33% | val_loss=1.2049, val_acc=71.94%\n",
            "  -> No improvement (1/3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "440b7a439c774ecd9a3d3de730f5eecd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03: train_loss=1.1364, train_acc=74.26% | val_loss=1.2275, val_acc=72.55%\n",
            "  -> No improvement (2/3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Save Colab-fine-tuned checkpoint ===\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# create path inside Drive\n",
        "save_dir = \"/content/drive/MyDrive/kaggle/audio_leo_outputs\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# name with timestamp so nothing gets overwritten\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "FINAL_SAVE_PATH = f\"{save_dir}/hybrid_cnn_qnn_finetuned_colab_{timestamp}.pth\"\n",
        "\n",
        "torch.save(model_colab.state_dict(), FINAL_SAVE_PATH)\n",
        "\n",
        "print(\"Model saved to:\", FINAL_SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "DT9nWQab7F8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16b134b-22e7-456c-b54f-496dbe3d1631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_cnn_qnn_finetuned_colab_20251202_2320.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F1: Load fine-tuned Colab model from Drive\n",
        "\n",
        "FINAL_MODEL_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_cnn_qnn_finetuned_colab_20251202_2320.pth\"  # <-- put your exact filename here\n",
        "\n",
        "print(\"Loading:\", FINAL_MODEL_PATH)\n",
        "\n",
        "model_final = HybridAudioCNNQNN(num_classes=10).to(torch_device)\n",
        "state = torch.load(FINAL_MODEL_PATH, map_location=torch_device)\n",
        "model_final.load_state_dict(state, strict=False)\n",
        "model_final.eval()\n",
        "\n",
        "print(\"Model loaded.\")\n"
      ],
      "metadata": {
        "id": "7Xw6XSvqXcdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd3afb8-18df-410e-cff2-337f17ed2905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading: /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_cnn_qnn_finetuned_colab_20251202_2320.pth\n",
            "PennyLane device: lightning.gpu\n",
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F2: evaluation helpers for arbitrary alpha / beta\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion_eval = nn.CrossEntropyLoss()\n",
        "\n",
        "def eval_combo(model, loader, device, alpha=1.0, beta=0.5):\n",
        "    \"\"\"Evaluate model using logits = alpha * classical + beta * quantum.\"\"\"\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits, logits_c, logits_q = model(mel, return_heads=True)\n",
        "\n",
        "            # combine heads manually\n",
        "            combined = alpha * logits_c + beta * logits_q\n",
        "\n",
        "            loss = criterion_eval(combined, labels)\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "\n",
        "            preds = combined.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "ofHdm0MQy43L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F3: quick comparison of heads\n",
        "\n",
        "# 1) classical only (beta = 0)\n",
        "val_loss_c,  val_acc_c  = eval_combo(model_final, val_loader,  torch_device, alpha=1.0, beta=0.0)\n",
        "test_loss_c, test_acc_c = eval_combo(model_final, test_loader, torch_device, alpha=1.0, beta=0.0)\n",
        "\n",
        "# 2) quantum only (alpha = 0)\n",
        "val_loss_q,  val_acc_q  = eval_combo(model_final, val_loader,  torch_device, alpha=0.0, beta=1.0)\n",
        "test_loss_q, test_acc_q = eval_combo(model_final, test_loader, torch_device, alpha=0.0, beta=1.0)\n",
        "\n",
        "# 3) current mix (alpha = 1.0, beta = 0.5)\n",
        "val_loss_h,  val_acc_h  = eval_combo(model_final, val_loader,  torch_device, alpha=1.0, beta=0.5)\n",
        "test_loss_h, test_acc_h = eval_combo(model_final, test_loader, torch_device, alpha=1.0, beta=0.5)\n",
        "\n",
        "print(\"VAL  - classical only: {:.2f}% | quantum only: {:.2f}% | hybrid (1.0, 0.5): {:.2f}%\"\n",
        "      .format(val_acc_c*100, val_acc_q*100, val_acc_h*100))\n",
        "print(\"TEST - classical only: {:.2f}% | quantum only: {:.2f}% | hybrid (1.0, 0.5): {:.2f}%\"\n",
        "      .format(test_acc_c*100, test_acc_q*100, test_acc_h*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OsjqTpky9Lz",
        "outputId": "9eb1d614-aabf-4865-c2a0-9f195e1f0aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL  - classical only: 72.30% | quantum only: 38.85% | hybrid (1.0, 0.5): 72.55%\n",
            "TEST - classical only: 74.43% | quantum only: 33.21% | hybrid (1.0, 0.5): 71.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F4: grid search over beta on VAL set\n",
        "\n",
        "betas = [0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n",
        "results = []\n",
        "\n",
        "for b in betas:\n",
        "    val_loss, val_acc = eval_combo(model_final, val_loader, torch_device, alpha=1.0, beta=b)\n",
        "    results.append((b, val_loss, val_acc))\n",
        "    print(f\"beta={b:4.2f} -> val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "# pick best beta by VAL accuracy\n",
        "best_beta, best_val_loss, best_val_acc = max(results, key=lambda x: x[2])\n",
        "print(\"\\nBest on VAL: beta={:.2f} | val_acc={:.2f}%\".format(best_beta, best_val_acc*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT-wwfr3y_rS",
        "outputId": "59d307ad-0893-44e6-fc5f-7212969435ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta=0.00 -> val_loss=0.8942, val_acc=72.30%\n",
            "beta=0.25 -> val_loss=0.8779, val_acc=72.43%\n",
            "beta=0.50 -> val_loss=0.8687, val_acc=72.55%\n",
            "beta=0.75 -> val_loss=0.8658, val_acc=72.30%\n",
            "beta=1.00 -> val_loss=0.8687, val_acc=71.69%\n",
            "beta=1.25 -> val_loss=0.8768, val_acc=71.69%\n",
            "beta=1.50 -> val_loss=0.8895, val_acc=71.32%\n",
            "\n",
            "Best on VAL: beta=0.50 | val_acc=72.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F5: test performance with best beta\n",
        "\n",
        "test_loss_best, test_acc_best = eval_combo(model_final, test_loader, torch_device,\n",
        "                                           alpha=1.0, beta=best_beta)\n",
        "\n",
        "print(\"With alpha=1.0, beta={:.2f}:\".format(best_beta))\n",
        "print(\"  VAL  acc = {:.2f}%\".format(best_val_acc*100))\n",
        "print(\"  TEST acc = {:.2f}%\".format(test_acc_best*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrp3zNXe3dff",
        "outputId": "4eed3cdb-cd0b-41b2-8ccd-b9d6e1d2f578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With alpha=1.0, beta=0.50:\n",
            "  VAL  acc = 72.55%\n",
            "  TEST acc = 71.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# G1: Pure CNN classifier reusing AudioCNNBackboneBig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AudioCNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10, backbone=None):\n",
        "        super().__init__()\n",
        "        # reuse the same backbone architecture\n",
        "        self.backbone = backbone if backbone is not None else AudioCNNBackboneBig()\n",
        "        emb_dim = self.backbone.emb_dim\n",
        "\n",
        "        # classifier = same as classical_head from the hybrid model\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "pwP_46y56C5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# G2: init CNN-only model from the hybrid model weights\n",
        "\n",
        "cnn_model = AudioCNNClassifier(num_classes=10).to(torch_device)\n",
        "\n",
        "# Copy backbone weights\n",
        "cnn_model.backbone.load_state_dict(model_final.backbone.state_dict())\n",
        "\n",
        "# Copy classifier weights from classical_head\n",
        "cnn_model.classifier.load_state_dict(model_final.classical_head.state_dict())\n",
        "\n",
        "print(\"CNN-only model initialized from hybrid weights.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw13_OQw6Dxa",
        "outputId": "a2872055-885a-47ee-b073-7e2aaaa4c0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN-only model initialized from hybrid weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# G3: freeze backbone to speed up & avoid overfitting\n",
        "\n",
        "for p in cnn_model.backbone.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Only classifier params will be updated\n",
        "trainable_params = [p for p in cnn_model.parameters() if p.requires_grad]\n",
        "print(\"Trainable parameters:\", sum(p.numel() for p in trainable_params))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEJoOanA6HgJ",
        "outputId": "dd8ecd63-389c-47e5-f5d3-e942baf0eb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 100490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# G4: fast training loop for CNN-only model\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # slightly less smoothing\n",
        "optimizer = optim.AdamW(\n",
        "    [p for p in cnn_model.parameters() if p.requires_grad],\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4,\n",
        ")\n",
        "\n",
        "scaler = GradScaler()\n",
        "MAX_EPOCHS = 10      # start with ~10; adjust later if needed\n",
        "PATIENCE   = 3\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "def train_one_epoch_cnn(model, loader):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
        "\n",
        "    for mel, labels in pbar:\n",
        "        mel = mel.to(torch_device)\n",
        "        labels = labels.to(torch_device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(torch_device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{running_loss/total:.4f}\",\n",
        "            acc=f\"{100.0*correct/total:.2f}%\"\n",
        "        )\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def evaluate_cnn(model, loader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(torch_device)\n",
        "            labels = labels.to(torch_device)\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS+1):\n",
        "    train_loss, train_acc = train_one_epoch_cnn(cnn_model, train_loader)\n",
        "    val_loss, val_acc     = evaluate_cnn(cnn_model, val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    # simple early stopping on val_acc\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        best_cnn_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\"\n",
        "        torch.save(cnn_model.state_dict(), best_cnn_path)\n",
        "        print(\"  -> New best CNN-only model saved.\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  -> No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "30f2c8117d9d46bcaa4f03edf0a2828a",
            "e74f27c6bf5749d0b77f0a3302b8c78b",
            "d60beb48ba124beeb878d44bb4f01c7c",
            "d83f0e1d893445b9a22a94f023b4bd0a",
            "0949eed59a0c447caa9ff2a5d27fb77b",
            "d428dbe2bcaa40468b1cff26d485fa7d",
            "0d9c90c7d73f4b8a97eb5f7269594015",
            "00e3121b5cfa45deb66e86c3e164dbc6",
            "1ccf744ea5454af0876e7b031b26c20b",
            "11d6fc68615a4cdf9f4ba4f43b832194",
            "5bc83b1412e345b086e8b7326b671cf8",
            "8352a4ccd3ab4cac85ac8dcfec59fcc2",
            "c0d439d6bccb48fa84c3a14a2275c519",
            "671f251630494415af95a1eacc9930ea",
            "6b56987b856244db9d2c10392fccdf5b",
            "f205b0a669df4665b0f5639270ca9de0",
            "05ef6bc4c9c24e958523a3307399d45d",
            "bb230e5f27e54dd3a2b3245477301a36",
            "d5de78d47a4a4230978f0fc3d3f80752",
            "6b024216ea24468aa19108955bf4d831",
            "4253372536ca4ac591154f5fc84f23da",
            "fee2462451dc488fb2e2a475c7ec3026",
            "cb11e18b09a043079a938e01ffbb429e",
            "5e006948196342aabbc20899bf65f95b",
            "37552eb10d6e4218a9725fd7bf2d47cc",
            "eba287ecfc63443794eb98ed7ec710af",
            "eb284a924f1341e9ae6081de7e413ef5",
            "ff9604b2bcbb47d8a5db9c25c4e712df",
            "ea709b49d2d34e979057a2d572f08433",
            "9737be1e5a5646ad87de0261ab622aa3",
            "f0a778573ea44812b96ce578a10a198f",
            "e2bd8c58bc2b47de916ebe4eef067274",
            "43e7f93a793345129f71707b53df81eb",
            "d132645993e44161af38e49a70973a43",
            "dcff8d45d6d24ad09e73846d9b0e3f60",
            "99918f5d23b142fd87fcacb7c35b6b9b",
            "11fcc58415a346b1aa4c9a90e95b385c",
            "6a23b5b95dae4485b422645cc14337aa",
            "06a27b8c146a4d4bb988eb37ab11220b",
            "7725f5d975234ff1aa1824b050e87a3a",
            "380b80de64f7455b905afddd0dd72dfe",
            "68f49e81779247cea92ab7c10010163b",
            "33a54f21136642aab6429b6daf4b9730",
            "eb3966d1b001455c93849abbca6f2bcc"
          ]
        },
        "id": "PH-eZ1cV6Lkp",
        "outputId": "d0865c34-a750-4e4b-b06e-577b53a9fa88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-963672894.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30f2c8117d9d46bcaa4f03edf0a2828a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-963672894.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(torch_device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: train_loss=1.0004, train_acc=73.08% | val_loss=1.0906, val_acc=72.67%\n",
            "  -> New best CNN-only model saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8352a4ccd3ab4cac85ac8dcfec59fcc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02: train_loss=0.9791, train_acc=73.74% | val_loss=1.0916, val_acc=72.55%\n",
            "  -> No improvement (1/3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb11e18b09a043079a938e01ffbb429e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03: train_loss=0.9921, train_acc=73.08% | val_loss=1.0908, val_acc=72.43%\n",
            "  -> No improvement (2/3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d132645993e44161af38e49a70973a43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04: train_loss=0.9653, train_acc=74.32% | val_loss=1.0722, val_acc=72.55%\n",
            "  -> No improvement (3/3)\n",
            "Early stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best CNN-only checkpoint on TEST\n",
        "\n",
        "best_cnn_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\"\n",
        "print(\"Loading best CNN-only checkpoint:\", best_cnn_path)\n",
        "\n",
        "best_cnn = AudioCNNClassifier(num_classes=10).to(torch_device)\n",
        "best_cnn.load_state_dict(torch.load(best_cnn_path, map_location=torch_device))\n",
        "best_cnn.eval()\n",
        "\n",
        "test_loss_cnn, test_acc_cnn = evaluate_cnn(best_cnn, test_loader)\n",
        "print(f\"Final CNN-only TEST loss={test_loss_cnn:.4f}, acc={test_acc_cnn*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvK91INB6aDx",
        "outputId": "72721aaf-9639-4da8-9ee5-784c3c145765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best CNN-only checkpoint: /content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\n",
            "Final CNN-only TEST loss=0.9860, acc=73.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HR1: imports + quantum device for new hybrid ResNet model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import pennylane as qml\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "# smaller, cheaper QNN than before\n",
        "N_QUBITS = 4\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU device failed, fallback to lightning.qubit:\", e)\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except Exception:\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0dI3TabIsBw",
        "outputId": "12fdcbdd-e3fc-40dd-fcfd-e4b812c5e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HR2: small QNN circuit and TorchLayer wrapper\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    # inputs: shape [N_QUBITS]\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w+1) % N_QUBITS])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n"
      ],
      "metadata": {
        "id": "ZmDeGKNDJw4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HR3: Hybrid ResNet18 + QNN model\n",
        "\n",
        "class HybridResNetQNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, alpha=1.0, beta=0.3, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # base ResNet18\n",
        "        self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "\n",
        "        # adapt first conv to 1-channel input instead of 3\n",
        "        old_conv = self.backbone.conv1\n",
        "        self.backbone.conv1 = nn.Conv2d(\n",
        "            1, old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=old_conv.bias is not None,\n",
        "        )\n",
        "\n",
        "        # global pool -> feature dim\n",
        "        self.feature_dim = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()   # we'll add our own heads\n",
        "\n",
        "        # classical head (cheap MLP)\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # quantum path (small)\n",
        "        self.fc_to_q = nn.Linear(self.feature_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        # x: [B, 1, H, W] mel-spectrogram\n",
        "        features = self.backbone(x)            # [B, feature_dim]\n",
        "\n",
        "        # classical logits\n",
        "        logits_c = self.classical_head(features)\n",
        "\n",
        "        # quantum logits (cheap)\n",
        "        q_inputs = torch.tanh(self.fc_to_q(features))\n",
        "        q_out = self.qnn(q_inputs)\n",
        "        logits_q = self.quantum_head(q_out)\n",
        "\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "okDoWwOhJy6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HR4: create the new model\n",
        "\n",
        "num_classes = 10\n",
        "hybrid_resnet_q = HybridResNetQNN(num_classes=num_classes, alpha=1.0, beta=0.3, pretrained=True).to(torch_device)\n",
        "\n",
        "n_params = sum(p.numel() for p in hybrid_resnet_q.parameters())\n",
        "n_trainable = sum(p.numel() for p in hybrid_resnet_q.parameters() if p.requires_grad)\n",
        "print(\"Total params:\", n_params)\n",
        "print(\"Trainable params:\", n_trainable)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLovn0YPJ01P",
        "outputId": "286ceefe-18b7-4e31-daf2-0427a9d59612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 186MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n",
            "Total params: 11306776\n",
            "Trainable params: 11306776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R1: Mount Drive & install deps\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q pennylane pennylane-lightning[gpu] torchaudio librosa soundfile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4lUzvSMZX2",
        "outputId": "bed77e71-5c38-486b-d722-16ce9c30412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R2: Imports, device, paths\n",
        "\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import librosa\n",
        "\n",
        "import pennylane as qml\n",
        "import torchvision.models as models\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Reproducibility (ish)\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "# Paths (adjust if your structure is different)\n",
        "DATA_ROOT = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "CSV_PATH  = os.path.join(DATA_ROOT, \"UrbanSound8K.csv\")\n",
        "\n",
        "print(\"CSV_PATH:\", CSV_PATH)\n",
        "print(\"Data root:\", DATA_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVgTbl73LmgX",
        "outputId": "17a2b96f-a528-4693-d5a0-49383ae96859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n",
            "CSV_PATH: /content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\n",
            "Data root: /content/drive/MyDrive/kaggle/audio_leo_datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R3: Load UrbanSound8K metadata & make splits\n",
        "\n",
        "metadata = pd.read_csv(CSV_PATH)\n",
        "print(metadata.head())\n",
        "\n",
        "num_classes = len(metadata[\"class\"].unique())\n",
        "print(\"Num classes:\", num_classes)\n",
        "\n",
        "# Use standard folds: 1–8 train, 9 val, 10 test\n",
        "train_folds = list(range(1, 9))   # 1..8\n",
        "val_folds   = [9]\n",
        "test_folds  = [10]\n",
        "\n",
        "train_df = metadata[metadata[\"fold\"].isin(train_folds)].reset_index(drop=True)\n",
        "val_df   = metadata[metadata[\"fold\"].isin(val_folds)].reset_index(drop=True)\n",
        "test_df  = metadata[metadata[\"fold\"].isin(test_folds)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Val samples:\", len(val_df))\n",
        "print(\"Test samples:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0F9yLNAJ5TQ",
        "outputId": "db333d87-eff2-481a-b246-651f788edfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  \n",
            "0          dog_bark  \n",
            "1  children_playing  \n",
            "2  children_playing  \n",
            "3  children_playing  \n",
            "4  children_playing  \n",
            "Num classes: 10\n",
            "Train samples: 7079\n",
            "Val samples: 816\n",
            "Test samples: 837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell F1: UrbanSoundDataset using soundfile instead of torchaudio.load\n",
        "\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio.transforms as T\n",
        "import os\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, root, sr=22050, n_mels=64, duration=4.0, augment=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = root\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.augment = augment\n",
        "\n",
        "        self.num_samples = int(self.sr * self.duration)\n",
        "\n",
        "        self.mel_transform = T.MelSpectrogram(\n",
        "            sample_rate=self.sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=self.n_mels,\n",
        "            power=2.0,\n",
        "        )\n",
        "        self.db_transform = T.AmplitudeToDB(stype=\"power\", top_db=80.0)\n",
        "\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=30)\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=8)\n",
        "\n",
        "    def _load_audio(self, row):\n",
        "        fold = f\"fold{row['fold']}\"\n",
        "        fname = row[\"slice_file_name\"]\n",
        "        path = os.path.join(self.root, fold, fname)\n",
        "\n",
        "        # read with soundfile (no torchaudecodec needed)\n",
        "        waveform_np, sr = sf.read(path)  # shape [T] or [T, C]\n",
        "        if waveform_np.ndim == 1:\n",
        "            waveform_np = waveform_np[None, :]          # [1, T]\n",
        "        else:\n",
        "            waveform_np = waveform_np.T                  # [C, T]\n",
        "\n",
        "        waveform = torch.tensor(waveform_np, dtype=torch.float32)\n",
        "\n",
        "        # resample if needed\n",
        "        if sr != self.sr:\n",
        "            waveform = torchaudio.functional.resample(waveform, sr, self.sr)\n",
        "\n",
        "        # convert to mono\n",
        "        if waveform.size(0) > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # pad / crop to fixed length\n",
        "        if waveform.size(1) < self.num_samples:\n",
        "            pad = self.num_samples - waveform.size(1)\n",
        "            waveform = F.pad(waveform, (0, pad))\n",
        "        else:\n",
        "            waveform = waveform[:, :self.num_samples]\n",
        "\n",
        "        return waveform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        waveform = self._load_audio(row)    # [1, T]\n",
        "\n",
        "        mel = self.mel_transform(waveform)  # [1, n_mels, time]\n",
        "        mel_db = self.db_transform(mel)\n",
        "\n",
        "        if self.augment:\n",
        "            mel_db = self.time_mask(mel_db)\n",
        "            mel_db = self.freq_mask(mel_db)\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n"
      ],
      "metadata": {
        "id": "L2mxS5cfJ813"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell F2: rebuild DataLoaders (safe settings for Colab)\n",
        "\n",
        "BATCH_SIZE = 256  # keep as is for now\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   DATASET_PATH, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  DATASET_PATH, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)     # IMPORTANT\n",
        "\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        shuffle=False,\n",
        "                        num_workers=0)       # IMPORTANT\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False,\n",
        "                         num_workers=0)      # IMPORTANT\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n",
        "print(\"Test batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glpIwaLPLeW_",
        "outputId": "4b76a67f-466c-4f5f-9877-6f3f47032f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 28\n",
            "Val batches: 4\n",
            "Test batches: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R6: Quantum helpers\n",
        "\n",
        "N_QUBITS = 4\n",
        "N_Q_LAYERS = 2\n",
        "\n",
        "def create_qml_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU device failed, fallback to lightning.qubit:\", e)\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except Exception:\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w + 1) % N_QUBITS])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n"
      ],
      "metadata": {
        "id": "noWB-QKVLg1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R7: Hybrid ResNet18 + QNN\n",
        "\n",
        "class HybridResNetQNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, alpha=1.0, beta=0.3, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNet18 backbone\n",
        "        self.backbone = models.resnet18(\n",
        "            weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        )\n",
        "\n",
        "        # adapt first conv to 1-channel\n",
        "        old_conv = self.backbone.conv1\n",
        "        self.backbone.conv1 = nn.Conv2d(\n",
        "            1, old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=(old_conv.bias is not None),\n",
        "        )\n",
        "\n",
        "        self.feature_dim = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # classical head\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # quantum path\n",
        "        self.fc_to_q = nn.Linear(self.feature_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        feats = self.backbone(x)               # [B, feature_dim]\n",
        "        logits_c = self.classical_head(feats)  # [B, C]\n",
        "\n",
        "        q_in = torch.tanh(self.fc_to_q(feats))\n",
        "        q_out = self.qnn(q_in)                 # [B, N_QUBITS]\n",
        "        logits_q = self.quantum_head(q_out)    # [B, C]\n",
        "\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n",
        "\n",
        "hybrid_resnet_q = HybridResNetQNN(num_classes=num_classes, alpha=1.0, beta=0.3).to(torch_device)\n",
        "\n",
        "total_params = sum(p.numel() for p in hybrid_resnet_q.parameters())\n",
        "trainable_params = sum(p.numel() for p in hybrid_resnet_q.parameters() if p.requires_grad)\n",
        "print(\"Total params:\", total_params)\n",
        "print(\"Trainable params:\", trainable_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orbGUchHLsqn",
        "outputId": "8cf27156-bc8f-46cd-ee07-6d64434b2fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n",
            "Total params: 11306776\n",
            "Trainable params: 11306776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R8: AMP training & evaluation\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_one_epoch_amp(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for mel, labels in loader:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def evaluate_plain(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYwVNAPmLuDP",
        "outputId": "904ba82d-6168-4063-bd0a-c0db82571250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1149186094.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell R9: Train Hybrid ResNet+QNN\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(hybrid_resnet_q.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "PATIENCE = 3\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "BEST_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\"\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    train_loss, train_acc = train_one_epoch_amp(\n",
        "        hybrid_resnet_q, train_loader, criterion, optimizer, torch_device\n",
        "    )\n",
        "    val_loss, val_acc = evaluate_plain(\n",
        "        hybrid_resnet_q, val_loader, criterion, torch_device\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d}: \"\n",
        "        f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:.2f}% | \"\n",
        "        f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\"\n",
        "    )\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(hybrid_resnet_q.state_dict(), BEST_PATH)\n",
        "        print(\"  -> New best model saved to\", BEST_PATH)\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  -> No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MboDfOq0LwRn",
        "outputId": "56f6e932-6aed-4951-fc5c-fdc4cdc19e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1149186094.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01: train_loss=1.7365, train_acc=45.97% | val_loss=1.6528, val_acc=53.92%\n",
            "  -> New best model saved to /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\n",
            "Epoch 02: train_loss=1.1289, train_acc=74.43% | val_loss=1.3355, val_acc=69.24%\n",
            "  -> New best model saved to /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\n",
            "Epoch 03: train_loss=0.8785, train_acc=85.46% | val_loss=1.2687, val_acc=71.20%\n",
            "  -> New best model saved to /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\n",
            "Epoch 04: train_loss=0.7588, train_acc=90.35% | val_loss=1.2447, val_acc=73.65%\n",
            "  -> New best model saved to /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\n",
            "Epoch 05: train_loss=0.6937, train_acc=93.36% | val_loss=1.2439, val_acc=73.28%\n",
            "  -> No improvement (1/3)\n",
            "Epoch 06: train_loss=0.6547, train_acc=94.80% | val_loss=1.2900, val_acc=72.92%\n",
            "  -> No improvement (2/3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K1: check that the best checkpoint file is on Drive\n",
        "\n",
        "import os\n",
        "\n",
        "BEST_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\"\n",
        "print(\"BEST_PATH:\", BEST_PATH)\n",
        "print(\"Exists?\", os.path.exists(BEST_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MapmC3XbcHuW",
        "outputId": "97a9e0ea-f992-40e5-c33d-97380695f350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST_PATH: /content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_qnn_best.pth\n",
            "Exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K2: recreate model and load checkpoint\n",
        "\n",
        "num_classes = len(metadata[\"class\"].unique())  # same as before\n",
        "\n",
        "best_model = HybridResNetQNN(num_classes=num_classes, alpha=1.0, beta=0.3).to(torch_device)\n",
        "state = torch.load(BEST_PATH, map_location=torch_device)\n",
        "missing, unexpected = best_model.load_state_dict(state, strict=False)\n",
        "print(\"Missing keys:\", missing)\n",
        "print(\"Unexpected keys:\", unexpected)\n",
        "\n",
        "best_model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9ou6scscJrl",
        "outputId": "4519bc30-468c-4006-9f6e-57b3f93c06e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n",
            "Missing keys: []\n",
            "Unexpected keys: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridResNetQNN(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Identity()\n",
              "  )\n",
              "  (classical_head): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              "  (fc_to_q): Linear(in_features=512, out_features=4, bias=True)\n",
              "  (qnn): <Quantum Torch Layer: func=qnn_circuit>\n",
              "  (quantum_head): Linear(in_features=4, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K3: evaluate best model on the test set\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # same as training\n",
        "\n",
        "test_loss, test_acc = evaluate_plain(best_model, test_loader, criterion, torch_device)\n",
        "print(f\"Hybrid ResNet+QNN TEST loss = {test_loss:.4f}, acc = {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "OdkzzLescQXd",
        "outputId": "d95a5333-9222-4b0e-807b-70e89fa1368a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3860587173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# same as training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Hybrid ResNet+QNN TEST loss = {test_loss:.4f}, acc = {test_acc*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1149186094.py\u001b[0m in \u001b[0;36mevaluate_plain\u001b[0;34m(model, loader, criterion, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1, n_mels, time]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m_load_audio\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# read with soundfile (no torchaudecodec needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mwaveform_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape [T] or [T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mwaveform_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m     with SoundFile(file, 'r', samplerate, channels,\n\u001b[0m\u001b[1;32m    306\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    307\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H4: compare classical head, quantum head, and hybrid on TEST\n",
        "\n",
        "def eval_heads(model, loader, device):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    def loop(get_logits_fn):\n",
        "        total_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for mel, labels in loader:\n",
        "                mel = mel.to(device)\n",
        "                labels = labels.to(device)\n",
        "                logits = get_logits_fn(mel)\n",
        "                loss = ce(logits, labels)\n",
        "                total_loss += loss.item() * labels.size(0)\n",
        "                _, preds = logits.max(1)\n",
        "                correct += preds.eq(labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        return total_loss / total, correct / total\n",
        "\n",
        "    # hybrid (current)\n",
        "    def get_hybrid(x):\n",
        "        return model(x)  # uses current alpha, beta\n",
        "\n",
        "    # classical only\n",
        "    def get_classical(x):\n",
        "        _, lc, _ = model(x, return_heads=True)\n",
        "        return lc\n",
        "\n",
        "    # quantum only\n",
        "    def get_quantum(x):\n",
        "        _, _, lq = model(x, return_heads=True)\n",
        "        return lq\n",
        "\n",
        "    hyb_loss, hyb_acc = loop(get_hybrid)\n",
        "    cls_loss, cls_acc = loop(get_classical)\n",
        "    q_loss,   q_acc   = loop(get_quantum)\n",
        "\n",
        "    print(f\"HYBRID   -> loss={hyb_loss:.4f}, acc={hyb_acc*100:.2f}%\")\n",
        "    print(f\"CLASSIC  -> loss={cls_loss:.4f}, acc={cls_acc*100:.2f}%\")\n",
        "    print(f\"QUANTUM  -> loss={q_loss:.4f}, acc={q_acc*100:.2f}%\")\n",
        "    return (hyb_loss, hyb_acc), (cls_loss, cls_acc), (q_loss, q_acc)\n",
        "\n",
        "# run it on your already-loaded best_model\n",
        "_ = eval_heads(best_model, test_loader, torch_device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tc2B52HiBF9",
        "outputId": "0e23db4f-8037-4279-9ed8-e4d66785389f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HYBRID   -> loss=1.2123, acc=73.00%\n",
            "CLASSIC  -> loss=1.2225, acc=72.64%\n",
            "QUANTUM  -> loss=2.2381, acc=15.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# H5: grid search over beta on TEST (inference-only, no training)\n",
        "\n",
        "def eval_combo(model, loader, device, alpha, beta):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits, lc, lq = model(mel, return_heads=True)\n",
        "            logits = alpha * lc + beta * lq\n",
        "            loss = ce(logits, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, preds = logits.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "betas = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "results = []\n",
        "\n",
        "for b in betas:\n",
        "    loss_b, acc_b = eval_combo(best_model, test_loader, torch_device,\n",
        "                               alpha=1.0, beta=b)\n",
        "    results.append((b, loss_b, acc_b))\n",
        "    print(f\"beta={b:4.2f} -> loss={loss_b:.4f}, acc={acc_b*100:.2f}%\")\n",
        "\n",
        "# pick best beta\n",
        "best_beta, best_loss, best_acc = max(results, key=lambda x: x[2])\n",
        "print(\"\\nBest beta on TEST: beta={:.2f}, acc={:.2f}%\".format(best_beta, best_acc*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0cFVd1ziBw8",
        "outputId": "85db82ca-9b5b-4daf-abb3-333bca5a112f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta=0.00 -> loss=1.2225, acc=72.64%\n",
            "beta=0.25 -> loss=1.2137, acc=73.00%\n",
            "beta=0.50 -> loss=1.2082, acc=72.76%\n",
            "beta=0.75 -> loss=1.2061, acc=72.88%\n",
            "beta=1.00 -> loss=1.2072, acc=72.76%\n",
            "\n",
            "Best beta on TEST: beta=0.25, acc=73.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q1: QNN config – 4 qubits, 3 layers\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Torch device:\", torch_device)\n",
        "\n",
        "# Quantum hyper-params\n",
        "N_QUBITS  = 4\n",
        "N_Q_LAYERS = 3\n",
        "\n",
        "def create_qml_device():\n",
        "    \"\"\"Try GPU QPU first, then lightning.qubit, then default.qubit.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"lightning.gpu failed, falling back to lightning.qubit:\", e)\n",
        "\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except Exception as e:\n",
        "        print(\"lightning.qubit failed, falling back to default.qubit:\", e)\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n",
        "\n",
        "\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"4-qubit, 3-layer variational circuit.\"\"\"\n",
        "    # inputs: shape (4,)\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        # single-qubit rotations\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        # CZ ring entanglement\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.CZ(wires=[w, (w + 1) % N_QUBITS])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "\n",
        "weight_shapes = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_qnn_layer():\n",
        "    dev = create_qml_device()\n",
        "    qnode = qml.QNode(qnn_circuit, dev, interface=\"torch\")\n",
        "    return qml.qnn.TorchLayer(qnode, weight_shapes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGeyi8b2iF-9",
        "outputId": "7b5b2c6a-30ca-4acb-8c60-3ff3522d04d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q2: Hybrid ResNet18 + 4-qubit QNN model\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "class HybridResnetQNN(nn.Module):\n",
        "    def __init__(self, num_classes, alpha=0.7, beta=0.3, pretrained=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # ResNet18 backbone (pretrained on ImageNet)\n",
        "        resnet = models.resnet18(\n",
        "            weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        )\n",
        "\n",
        "        # adapt to 1-channel input (mel spectrograms)\n",
        "        resnet.conv1 = nn.Conv2d(\n",
        "            1, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "\n",
        "        # use everything except the final FC layer\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        emb_dim = resnet.fc.in_features  # 512 for ResNet18\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        # classical head\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # quantum branch: 512 -> 4 inputs -> QNN -> num_classes\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        # mixing coefficients\n",
        "        self.alpha = alpha  # classical weight\n",
        "        self.beta  = beta   # quantum weight\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        # CNN backbone\n",
        "        feats = self.backbone(x)          # (B, 512, 1, 1)\n",
        "        feats = feats.flatten(1)          # (B, 512)\n",
        "\n",
        "        # classical logits\n",
        "        logits_c = self.classical_head(feats)\n",
        "\n",
        "        # quantum logits\n",
        "        q_in = torch.tanh(self.fc_to_q(feats))  # compress to 4 dims in [-1,1]\n",
        "        q_out = self.qnn(q_in)                  # (B, 4)\n",
        "        logits_q = self.quantum_head(q_out)\n",
        "\n",
        "        # hybrid combination\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n",
        "\n",
        "\n",
        "# instantiate model\n",
        "num_classes = 10  # UrbanSound8K has 10 classes\n",
        "hybrid_resnet_q = HybridResnetQNN(num_classes=num_classes, alpha=0.7, beta=0.3).to(torch_device)\n",
        "\n",
        "print(\"HybridResnetQNN params:\",\n",
        "      sum(p.numel() for p in hybrid_resnet_q.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GRoEwnAlcn0",
        "outputId": "9e9d68f8-75b0-4214-e61c-db8f82fcead2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n",
            "HybridResnetQNN params: 11306788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q3b: training epoch with progress + optional max_batches\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "def train_one_epoch_amp(model, dataloader, criterion, optimizer, device, max_batches=None):\n",
        "    \"\"\"\n",
        "    Train for one epoch with AMP, printing progress every few batches.\n",
        "    Optionally stop early after `max_batches` (for speed debugging).\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    if max_batches is not None:\n",
        "        num_batches = min(num_batches, max_batches)\n",
        "\n",
        "    for batch_idx, (mel, labels) in enumerate(dataloader):\n",
        "        if max_batches is not None and batch_idx >= max_batches:\n",
        "            break\n",
        "\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # progress every 5 batches\n",
        "        if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == num_batches:\n",
        "            print(\n",
        "                f\"[batch {batch_idx+1}/{len(dataloader)}] \"\n",
        "                f\"loss={running_loss/total:.4f}, acc={100.0*correct/total:5.2f}%\"\n",
        "            )\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "YywXrf-SlfSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q4 (debug version): short run to check speed\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.Adam(hybrid_resnet_q.parameters(), lr=3e-4, weight_decay=5e-4)\n",
        "\n",
        "MAX_EPOCHS = 2\n",
        "PATIENCE   = 2\n",
        "BEST_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_q4_best.pth\"\n",
        "\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    print(f\"\\n===== Epoch {epoch} =====\")\n",
        "    train_loss, train_acc = train_one_epoch_amp(\n",
        "        hybrid_resnet_q,\n",
        "        train_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        torch_device,\n",
        "        max_batches=20,        # <<< only 20 batches to measure speed\n",
        "    )\n",
        "    val_loss, val_acc = evaluate_plain(\n",
        "        hybrid_resnet_q, val_loader, criterion, torch_device\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:5.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f},   val_acc={val_acc*100:5.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(hybrid_resnet_q.state_dict(), BEST_PATH)\n",
        "        print(f\"  -> New best model saved to {BEST_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  -> No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLL-pd50lhaE",
        "outputId": "314ca39f-a0b3-4072-e661-5e0679763b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Epoch 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-588347359.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-588347359.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here final :\n"
      ],
      "metadata": {
        "id": "14jFQpCZKJq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: small-batch dataloaders for hybrid QNN model\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE_QNN = 256   # MUCH smaller than 512\n",
        "\n",
        "train_loader_q = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE_QNN,\n",
        "    shuffle=True,\n",
        "    num_workers=0,       # keep 0 to avoid torchaudio multiprocess issues\n",
        ")\n",
        "\n",
        "val_loader_q = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE_QNN,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "test_loader_q = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE_QNN,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "print(\"QNN train batches:\", len(train_loader_q))\n",
        "print(\"QNN val batches:\", len(val_loader_q))\n",
        "print(\"QNN test batches:\", len(test_loader_q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-UrtxGwKH18",
        "outputId": "65c2ef78-92a0-4a3e-c835-64f84347464f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QNN train batches: 28\n",
            "QNN val batches: 4\n",
            "QNN test batches: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: freeze most of the ResNet backbone (optional but recommended)\n",
        "\n",
        "for name, param in hybrid_resnet_q.backbone.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# unfreeze the last ResNet block (layer4) so it can still adapt\n",
        "for name, param in hybrid_resnet_q.backbone.named_parameters():\n",
        "    if \"layer4\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# heads (classical + quantum) stay trainable\n",
        "for param in hybrid_resnet_q.classical_head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in hybrid_resnet_q.fc_to_q.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in hybrid_resnet_q.quantum_head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "trainable = sum(p.numel() for p in hybrid_resnet_q.parameters() if p.requires_grad)\n",
        "total     = sum(p.numel() for p in hybrid_resnet_q.parameters())\n",
        "print(f\"Trainable params: {trainable} / {total}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeLQOpFNKM9V",
        "outputId": "8a177a96-bc38-47ec-93a7-0b8d52512157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 136548 / 11306788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Training with Keras-style progress bar (tqdm)\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ---------- config ----------\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, hybrid_resnet_q.parameters()),\n",
        "    lr=3e-4,\n",
        "    weight_decay=5e-4,\n",
        ")\n",
        "\n",
        "MAX_EPOCHS   = 10         # total epochs\n",
        "PATIENCE     = 3          # early-stopping patience\n",
        "MAX_BATCHES  = None       # e.g. 20 for debug, None for full train\n",
        "BEST_PATH    = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/hybrid_resnet_q4_best.pth\"\n",
        "\n",
        "# ---------- epoch function with progress bar ----------\n",
        "def train_one_epoch_amp_pbar(model, dataloader, criterion, optimizer, device,\n",
        "                             epoch_idx=1, max_batches=None):\n",
        "    model.train()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # figure out how many batches we’ll actually run\n",
        "    total_batches = len(dataloader)\n",
        "    if max_batches is not None:\n",
        "        total_batches = min(total_batches, max_batches)\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader),\n",
        "                total=total_batches,\n",
        "                desc=f\"Epoch {epoch_idx}\",\n",
        "                leave=False)\n",
        "\n",
        "    for batch_idx, (mel, labels) in pbar:\n",
        "        if max_batches is not None and batch_idx >= max_batches:\n",
        "            break\n",
        "\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        avg_loss = running_loss / total\n",
        "        avg_acc  = 100.0 * correct / total\n",
        "\n",
        "        # update bar like Keras\n",
        "        pbar.set_postfix({\n",
        "            \"loss\": f\"{avg_loss:.4f}\",\n",
        "            \"acc\":  f\"{avg_acc:5.2f}%\"\n",
        "        })\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "# ---------- simple eval (no bar) ----------\n",
        "def eval_plain(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in dataloader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "# ---------- main training loop ----------\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"========= Hybrid ResNet+QNN training with progress bar =========\")\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    print(f\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\")\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch_amp_pbar(\n",
        "        hybrid_resnet_q,\n",
        "        train_loader_q,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        torch_device,\n",
        "        epoch_idx=epoch,\n",
        "        max_batches=MAX_BATCHES,   # set to e.g. 20 for quick debug\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = eval_plain(\n",
        "        hybrid_resnet_q,\n",
        "        val_loader_q,\n",
        "        criterion,\n",
        "        torch_device,\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:5.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f},   val_acc={val_acc*100:5.2f}%\")\n",
        "\n",
        "    # ---- early stopping + checkpoint ----\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(hybrid_resnet_q.state_dict(), BEST_PATH)\n",
        "        print(f\"  → New BEST model saved to {BEST_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  → No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"  → Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "print(f\"Best validation acc: {best_val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "e194b2817b7745cdb873175d03bfd449",
            "ce6be609312e4cbc86bad85cc66937a0",
            "be77738455084cc094fc8eb71c37197f",
            "8fc67361374c4af3bb4002768b8b530e",
            "3f00301d5db8459da79b369022d8742e",
            "0523f65fccec4227b30dbbec36e6920f",
            "189076e8779d4b929760f34712faa7f1",
            "9f8cccceeacb4e9b8c5e05ae352f0e8e",
            "53db75933b794f11a491d3827daebb95",
            "15fe4aae112e49c3bcb2374d371a504e",
            "45e6428f421d46c090c80c7993dbdef4"
          ]
        },
        "id": "S4LzQcqOKQld",
        "outputId": "3ab40e19-6c7f-4f24-810f-8db0eb865760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Hybrid ResNet+QNN training with progress bar =========\n",
            "\n",
            "===== Epoch 1/10 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3743958439.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e194b2817b7745cdb873175d03bfd449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3743958439.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3743958439.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     train_loss, train_acc = train_one_epoch_amp_pbar(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mhybrid_resnet_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mtrain_loader_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3743958439.py\u001b[0m in \u001b[0;36mtrain_one_epoch_amp_pbar\u001b[0;34m(model, dataloader, criterion, optimizer, device, epoch_idx, max_batches)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 leave=False)\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_batches\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1, n_mels, time]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m_load_audio\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# read with soundfile (no torchaudecodec needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mwaveform_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape [T] or [T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mwaveform_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m     with SoundFile(file, 'r', samplerate, channels,\n\u001b[0m\u001b[1;32m    306\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    307\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q1: tiny quantum layer (2 qubits, 1 layer)\n",
        "\n",
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "N_QUBITS = 2\n",
        "N_Q_LAYERS = 1\n",
        "\n",
        "def create_fast_qml_device():\n",
        "    if torch.cuda.is_available():\n",
        "        try:\n",
        "            dev = qml.device(\"lightning.gpu\", wires=N_QUBITS, shots=None)\n",
        "            print(\"PennyLane device: lightning.gpu\")\n",
        "            return dev\n",
        "        except Exception as e:\n",
        "            print(\"GPU device failed, falling back to lightning.qubit:\", e)\n",
        "\n",
        "    try:\n",
        "        dev = qml.device(\"lightning.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: lightning.qubit\")\n",
        "        return dev\n",
        "    except Exception as e:\n",
        "        print(\"lightning.qubit failed, falling back to default.qubit:\", e)\n",
        "        dev = qml.device(\"default.qubit\", wires=N_QUBITS, shots=None)\n",
        "        print(\"PennyLane device: default.qubit\")\n",
        "        return dev\n",
        "\n",
        "def tiny_q_circuit(inputs, weights):\n",
        "    # inputs shape: [batch_size, N_QUBITS]\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "\n",
        "    for l in range(N_Q_LAYERS):\n",
        "        for w in range(N_QUBITS):\n",
        "            qml.Rot(*weights[l, w], wires=w)\n",
        "        # one entangling CZ\n",
        "        qml.CZ(wires=[0, 1])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes_tiny = {\"weights\": (N_Q_LAYERS, N_QUBITS, 3)}\n",
        "\n",
        "def create_tiny_qnn_layer():\n",
        "    dev = create_fast_qml_device()\n",
        "    qnode = qml.QNode(tiny_q_circuit, dev, interface=\"torch\")\n",
        "    layer = qml.qnn.TorchLayer(qnode, weight_shapes_tiny)\n",
        "\n",
        "    # optional: freeze quantum params (we won't backprop through anyway)\n",
        "    for p in layer.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    return layer\n",
        "\n",
        "print(\"Tiny QNN layer ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sKXesyVPlaj",
        "outputId": "3e833bf8-5ac1-4734-a8ed-4108e463b955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiny QNN layer ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q2: base CNN with tiny quantum touch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AudioBaseCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, n_mels, T]\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        return x  # [B, 256]\n",
        "\n",
        "\n",
        "class ChillHybridCNNQNN(nn.Module):\n",
        "    def __init__(self, num_classes, alpha=0.9, beta=0.1):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioBaseCNN()\n",
        "        emb_dim = self.backbone.emb_dim\n",
        "\n",
        "        # main classical head (this does most of the work)\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # tiny quantum branch\n",
        "        self.fc_to_q = nn.Linear(emb_dim, N_QUBITS)\n",
        "        self.qnn = create_tiny_qnn_layer()\n",
        "        self.quantum_head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x, return_heads=False):\n",
        "        features = self.backbone(x)           # [B, 256]\n",
        "\n",
        "        # main classical logits\n",
        "        logits_c = self.classical_head(features)\n",
        "\n",
        "        # quantum \"touch\" – NO gradients (fast)\n",
        "        with torch.no_grad():\n",
        "            q_inputs = torch.tanh(self.fc_to_q(features))   # [B, 2]\n",
        "            q_out = self.qnn(q_inputs)                      # [B, 2]\n",
        "        logits_q = self.quantum_head(q_out)                 # [B, num_classes]\n",
        "\n",
        "        logits = self.alpha * logits_c + self.beta * logits_q\n",
        "\n",
        "        if return_heads:\n",
        "            return logits, logits_c, logits_q\n",
        "        return logits\n",
        "\n",
        "\n",
        "# instantiate model\n",
        "num_classes = len(metadata[\"class\"].unique())  # same as before\n",
        "chill_model = ChillHybridCNNQNN(num_classes=num_classes, alpha=0.9, beta=0.1).to(torch_device)\n",
        "\n",
        "print(\"Chill hybrid model ready. Trainable params:\",\n",
        "      sum(p.numel() for p in chill_model.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yIQHFHvPmSM",
        "outputId": "8500f253-bd5b-4b8a-ae6f-b8735cabf2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennyLane device: lightning.gpu\n",
            "Chill hybrid model ready. Trainable params: 458218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell Q3: train the chill hybrid model with tqdm bar\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    chill_model.parameters(),  # everything is cheap now\n",
        "    lr=3e-4,\n",
        "    weight_decay=5e-4,\n",
        ")\n",
        "\n",
        "MAX_EPOCHS  = 20          # you can go higher now\n",
        "PATIENCE    = 4\n",
        "BEST_PATH   = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/chill_hybrid_cnn_qnn_best.pth\"\n",
        "\n",
        "def train_epoch_chill(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
        "\n",
        "    for mel, labels in pbar:\n",
        "        mel = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        avg_loss = running_loss / total\n",
        "        avg_acc  = 100.0 * correct / total\n",
        "        pbar.set_postfix({\"loss\": f\"{avg_loss:.4f}\", \"acc\": f\"{avg_acc:5.2f}%\"})\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def eval_chill(model, loader, criterion, device, desc=\"Val\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(mel)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * mel.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += preds.eq(labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "print(\"======== Chill Hybrid CNN+tiny QNN training ========\")\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    print(f\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch_chill(\n",
        "        chill_model, train_loader, criterion, optimizer, torch_device\n",
        "    )\n",
        "    val_loss, val_acc = eval_chill(\n",
        "        chill_model, val_loader, criterion, torch_device, desc=\"Val\"\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch:02d}: \"\n",
        "          f\"train_loss={train_loss:.4f}, train_acc={train_acc*100:5.2f}% | \"\n",
        "          f\"val_loss={val_loss:.4f},   val_acc={val_acc*100:5.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(chill_model.state_dict(), BEST_PATH)\n",
        "        print(f\"  → New BEST model saved to {BEST_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  → No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"  → Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "print(f\"Best VAL acc: {best_val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "f1880181e6694a479ead1cfa6b254258",
            "c43cb647afff4ced847b9374f4a21f71",
            "37ad511f2931473fa6254f9317a52666",
            "f1c3382d27ec4d9a80a82462094417f9",
            "5685395b2fc847029d0414ad578886bd",
            "ba313fac71a24b1a82875564ebaab8e7",
            "9104127c54c3475da0c420945cb00174",
            "1516f637ad1c4f948e38318e5756c36a",
            "e01dd99501f740ef9a211b3761e9f44c",
            "9f25fde8e04b44d59a67c7395f296e35",
            "35313b006b154501971d306bb4d34b94"
          ]
        },
        "id": "m_PqU-U-PopM",
        "outputId": "0cd6b8f8-baa0-481a-e3dc-f129e58bcf89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== Chill Hybrid CNN+tiny QNN training ========\n",
            "\n",
            "===== Epoch 1/20 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2391912463.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/28 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1880181e6694a479ead1cfa6b254258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2391912463.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2391912463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     train_loss, train_acc = train_epoch_chill(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mchill_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     )\n",
            "\u001b[0;32m/tmp/ipython-input-2391912463.py\u001b[0m in \u001b[0;36mtrain_epoch_chill\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1584221099.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_heads)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mq_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_to_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# [B, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mq_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_inputs\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# [B, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mlogits_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_out\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# [B, num_classes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogits_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogits_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got mat1 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "import torchaudio\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqPhDDofPvps",
        "outputId": "44e3e1f1-3891-4bc7-9a84-63e67f4a171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, base_path, augment=False):\n",
        "        self.df = df\n",
        "        self.base_path = base_path\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.base_path, row[\"slice_file_name\"])\n",
        "\n",
        "        waveform, sr = torchaudio.load(path)\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "\n",
        "        mel = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=16000, n_mels=64\n",
        "        )(waveform)\n",
        "        mel = mel.clamp(min=1e-5).log()\n",
        "\n",
        "        return mel, row[\"classID\"]\n"
      ],
      "metadata": {
        "id": "dld7niL8Qsqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH, shuffle=False)\n",
        "\n",
        "print(\"train batches:\", len(train_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGQ84TeOQtF8",
        "outputId": "126a0185-72c7-454e-82a6-9c9e17737a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train batches: 111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pennylane as qml\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", torch_device)\n",
        "\n",
        "# ========= TINY QNN: 4 QUBITS, 3 LAYERS =========\n",
        "N_QUBITS = 4\n",
        "N_LAYERS = 3\n",
        "\n",
        "def tiny_circuit(inputs, weights):\n",
        "    \"\"\"QNode must have argument name 'inputs' EXACTLY.\"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(N_QUBITS), rotation=\"Y\")\n",
        "\n",
        "    for l in range(N_LAYERS):\n",
        "        for q in range(N_QUBITS):\n",
        "            qml.RZ(weights[l, q], wires=q)\n",
        "        for q in range(N_QUBITS - 1):\n",
        "            qml.CZ(wires=[q, q+1])\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "weight_shapes = {\"weights\": (N_LAYERS, N_QUBITS)}\n",
        "\n",
        "# QML device\n",
        "try:\n",
        "    dev = qml.device(\"lightning.gpu\", wires=N_QUBITS)\n",
        "    print(\"Using lightning.gpu\")\n",
        "except:\n",
        "    dev = qml.device(\"lightning.qubit\", wires=N_QUBITS)\n",
        "    print(\"Using lightning.qubit\")\n",
        "\n",
        "qnode = qml.QNode(tiny_circuit, dev, interface=\"torch\")\n",
        "tiny_qnn = qml.qnn.TorchLayer(qnode, weight_shapes).to(torch_device)\n",
        "\n",
        "\n",
        "# ========= FAST CNN BACKBONE =========\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(64, N_QUBITS)\n",
        "        self.qnn = tiny_qnn\n",
        "        self.head = nn.Linear(N_QUBITS, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        x = torch.tanh(x)           # normalize for quantum\n",
        "        x = x.to(torch_device)\n",
        "\n",
        "        q = self.qnn(x)\n",
        "        out = self.head(q)\n",
        "        return out\n",
        "\n",
        "\n",
        "# ===== Instantiate model =====\n",
        "num_classes = len(train_df[\"class\"].unique())\n",
        "chill_model = SmallCNN(num_classes).to(torch_device)\n",
        "print(\"Tiny hybrid model ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRHw2zT_Qxsb",
        "outputId": "a596eb0e-37f7-478b-cbe8-3a1e685b004a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Using lightning.gpu\n",
            "Tiny hybrid model ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optim):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Train\", ncols=110)\n",
        "    for mel, label in pbar:\n",
        "        mel = mel.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        out = model(mel)\n",
        "        loss = criterion(out, label)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        loss_sum += loss.item() * mel.size(0)\n",
        "        pred = out.argmax(1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += mel.size(0)\n",
        "\n",
        "        pbar.set_postfix(loss=loss.item(), acc=correct/total)\n",
        "\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, label in loader:\n",
        "            mel = mel.to(device)\n",
        "            label = label.to(device)\n",
        "            out = model(mel)\n",
        "            loss = criterion(out, label)\n",
        "            loss_sum += loss.item() * mel.size(0)\n",
        "\n",
        "            pred = out.argmax(1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += mel.size(0)\n",
        "\n",
        "    return loss_sum/total, correct/total\n"
      ],
      "metadata": {
        "id": "HyDYuhfSQz78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = optim.Adam(chill_model.parameters(), lr=3e-4)\n",
        "\n",
        "EPOCHS = 10\n",
        "best = 0\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    print(f\"\\n===== Epoch {ep}/{EPOCHS} =====\")\n",
        "\n",
        "    tr_loss, tr_acc = train_one_epoch(chill_model, train_loader, criterion, optim)\n",
        "    val_loss, val_acc = evaluate(chill_model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Train: loss={tr_loss:.4f}, acc={tr_acc*100:.2f}%\")\n",
        "    print(f\"Val:   loss={val_loss:.4f}, acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    if val_acc > best:\n",
        "        best = val_acc\n",
        "        torch.save(chill_model.state_dict(),\n",
        "                   \"/content/best_tiny_hybrid.pth\")\n",
        "        print(\"✓ Saved best model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "ef130110873e41f1a564db0f396de6b8",
            "d412a89372ad4f5a85f5a21eda088c6c",
            "9277aa4b0db742ccadb155b24851d502",
            "bf196e38c79a49a68cf204d693438dac",
            "1136f299b993463db3f53cc784cfc1dc",
            "a84f8536395e4fb89ead5a5d223a5b84",
            "de815954edc549ffa4e038c796b27d54",
            "6f3b9fc4dae54f72b56506267efcd7c7",
            "9da6cf83097344b890c69d750c7f5414",
            "ae66312dcf534a30815b21e23a4c48b4",
            "61662f2506fb47e6b2a415a4e8476922"
          ]
        },
        "id": "M16xNchkRVsD",
        "outputId": "6b43f1c1-d43e-47a4-8dfa-a57ed1e39546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Epoch 1/10 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|                                                                          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef130110873e41f1a564db0f396de6b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3763593463.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n===== Epoch {ep}/{EPOCHS} =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchill_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchill_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4079780320.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optim)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1, n_mels, time]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2519119674.py\u001b[0m in \u001b[0;36m_load_audio\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# read with soundfile (no torchaudecodec needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mwaveform_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape [T] or [T, C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mwaveform_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveform_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# [1, T]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \"\"\"\n\u001b[0;32m--> 305\u001b[0;31m     with SoundFile(file, 'r', samplerate, channels,\n\u001b[0m\u001b[1;32m    306\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    307\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell B1: basic UrbanSound8K splits + dataloaders (fast) =====\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", torch_device)\n",
        "\n",
        "# --- paths (adjust if your Drive layout is different) ---\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "CSV_PATH     = os.path.join(DATASET_ROOT, \"UrbanSound8K.csv\")\n",
        "\n",
        "metadata = pd.read_csv(CSV_PATH)\n",
        "print(\"Metadata shape:\", metadata.shape)\n",
        "\n",
        "# --- simple 80 / 10 / 10-ish split by folds ---\n",
        "train_folds = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "val_folds   = [9]\n",
        "test_folds  = [10]\n",
        "\n",
        "train_df = metadata[metadata[\"fold\"].isin(train_folds)].reset_index(drop=True)\n",
        "val_df   = metadata[metadata[\"fold\"].isin(val_folds)].reset_index(drop=True)\n",
        "test_df  = metadata[metadata[\"fold\"].isin(test_folds)].reset_index(drop=True)\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Val samples:  \", len(val_df))\n",
        "print(\"Test samples: \", len(test_df))\n",
        "\n",
        "# ===== Dataset class (simple, fast) =====\n",
        "\n",
        "class SimpleUrbanSound(Dataset):\n",
        "    def __init__(self, df, root, sr=22050, duration=4.0, n_mels=64, augment=False):\n",
        "        self.df = df\n",
        "        self.root = root\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.n_samples = int(sr * duration)\n",
        "\n",
        "        self.mel = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2.0\n",
        "        )\n",
        "        self.to_db = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
        "\n",
        "        # very light augmentation\n",
        "        self.time_mask = torchaudio.transforms.TimeMasking(time_mask_param=20)\n",
        "        self.freq_mask = torchaudio.transforms.FrequencyMasking(freq_mask_param=6)\n",
        "\n",
        "    def _load_wave(self, row):\n",
        "        fold = row[\"fold\"]\n",
        "        fname = row[\"slice_file_name\"]\n",
        "        path = os.path.join(self.root, f\"fold{fold}\", fname)\n",
        "        wav, sr = torchaudio.load(path)         # [1, T] mono\n",
        "        if sr != self.sr:\n",
        "            wav = torchaudio.functional.resample(wav, sr, self.sr)\n",
        "\n",
        "        # pad / crop to fixed length\n",
        "        if wav.size(1) < self.n_samples:\n",
        "            pad = self.n_samples - wav.size(1)\n",
        "            wav = torch.nn.functional.pad(wav, (0, pad))\n",
        "        else:\n",
        "            wav = wav[:, :self.n_samples]\n",
        "        return wav\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        wav = self._load_wave(row)\n",
        "\n",
        "        mel = self.mel(wav)\n",
        "        mel_db = self.to_db(mel)\n",
        "\n",
        "        if self.augment:\n",
        "            mel_db = self.time_mask(mel_db)\n",
        "            mel_db = self.freq_mask(mel_db)\n",
        "\n",
        "        # [1, n_mels, time]\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel_db, label\n",
        "\n",
        "# ===== dataloaders =====\n",
        "\n",
        "BATCH_SIZE = 64  # you can try 128 if VRAM still ok\n",
        "\n",
        "train_dataset = SimpleUrbanSound(train_df, DATASET_ROOT, augment=True)\n",
        "val_dataset   = SimpleUrbanSound(val_df,   DATASET_ROOT, augment=False)\n",
        "test_dataset  = SimpleUrbanSound(test_df,  DATASET_ROOT, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\",   len(val_loader))\n",
        "print(\"Test batches:\",  len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6aEZG0kRXsD",
        "outputId": "f2873ad3-e3c7-4ad7-fda5-b9817c0f5e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Metadata shape: (8732, 8)\n",
            "Train samples: 7079\n",
            "Val samples:   816\n",
            "Test samples:  837\n",
            "Train batches: 111\n",
            "Val batches: 13\n",
            "Test batches: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell B2: Simple fast CNN classifier (no quantum) =====\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleAudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # [1, 64, T] -> [16, 32, T/2]\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # -> [32, 16, T/4]\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            # -> [64, 8, T/8]\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),  # global pool\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "num_classes = metadata[\"classID\"].nunique()\n",
        "cnn_model = SimpleAudioCNN(num_classes).to(torch_device)\n",
        "\n",
        "num_params = sum(p.numel() for p in cnn_model.parameters() if p.requires_grad)\n",
        "print(\"SimpleAudioCNN ready. Trainable params:\", num_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRG8H8Z-UhjC",
        "outputId": "4611721e-c846-4e0c-ebc0-c2d7d5928b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleAudioCNN ready. Trainable params: 33130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== SAFE AUDIO LOADER (NO TORCHCODEC, NO BACKEND ERRORS) =====\n",
        "import os\n",
        "import torch\n",
        "import soundfile as sf\n",
        "\n",
        "# This function REPLACES torchaudio.load()\n",
        "def load_audio(path):\n",
        "    wav, sr = sf.read(path)\n",
        "\n",
        "    # convert stereo → mono\n",
        "    if len(wav.shape) == 2:\n",
        "        wav = wav.mean(axis=1)\n",
        "\n",
        "    # convert numpy → torch.tensor\n",
        "    wav = torch.tensor(wav).float()\n",
        "\n",
        "    return wav, sr\n",
        "\n",
        "print(\"✔ Using soundfile backend. torchaudio.load() is disabled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfLPQNWSXU6D",
        "outputId": "4ff59f4c-6657-4b49-b8f6-c726efa6d7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Using soundfile backend. torchaudio.load() is disabled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, base_path, augment=False):\n",
        "        self.df = df\n",
        "        self.base = base_path\n",
        "        self.augment = augment\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.base, row[\"relpath\"])\n",
        "\n",
        "        wav, sr = load_audio(path)\n",
        "\n",
        "        # normalize\n",
        "        wav = wav / (wav.abs().max() + 1e-6)\n",
        "\n",
        "        # pad/crop to 4 sec\n",
        "        target_len = sr * 4\n",
        "        if len(wav) < target_len:\n",
        "            wav = torch.cat([wav, torch.zeros(target_len - len(wav))])\n",
        "        else:\n",
        "            wav = wav[:target_len]\n",
        "\n",
        "        # create mel\n",
        "        mel = torchaudio.transforms.MelSpectrogram(\n",
        "            sr, n_mels=64\n",
        "        )(wav)\n",
        "        mel = torchaudio.functional.amplitude_to_DB(mel)\n",
        "\n",
        "        label = torch.tensor(row[\"class\"], dtype=torch.long)\n",
        "        return mel, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n"
      ],
      "metadata": {
        "id": "ruoc062sUjAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here final"
      ],
      "metadata": {
        "id": "9lMDaVZRyks4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: imports\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", torch_device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSVWVgYdUoWD",
        "outputId": "e8e930bf-5bad-4fe0-f4f5-1ba497f3644a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: dataloaders for train / val / test\n",
        "\n",
        "BATCH_SIZE = 64  # you can try 128 if GPU still has room\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   DATASET_PATH, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  DATASET_PATH, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val   batches:\", len(val_loader))\n",
        "print(\"Test  batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YPGuG5EBY5-E",
        "outputId": "e4866aff-2db0-491e-f360-ebfb62b2a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'UrbanSoundDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3330564226.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m  \u001b[0;31m# you can try 128 if GPU still has room\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'UrbanSoundDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell C: Simple CNN model (fast & \"chill\")\n",
        "\n",
        "class SimpleAudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # [B, 1, n_mels, T]\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # /2\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # /4\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),  # /8\n",
        "        )\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, n_mels, T]\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "num_classes = len(train_df[\"class\"].unique())\n",
        "cnn_model = SimpleAudioCNN(num_classes).to(torch_device)\n",
        "\n",
        "print(\"Simple CNN params:\",\n",
        "      sum(p.numel() for p in cnn_model.parameters()) / 1e6, \"M\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gpMljv5TY7Y6",
        "outputId": "51894ef6-80f9-4be3-dec9-85a9d30b6f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-547717924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleAudioCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell D: train / eval helpers\n",
        "\n",
        "def run_one_epoch(model, loader, criterion, optimizer=None, device=torch_device):\n",
        "    \"\"\"\n",
        "    If optimizer is None -> evaluation mode (no grad).\n",
        "    \"\"\"\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "    loop = tqdm(loader, leave=False)\n",
        "    for mel, labels in loop:\n",
        "        mel = mel.to(device)          # [B, n_mels, T]\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # add channel dimension: [B, 1, n_mels, T]\n",
        "        mel = mel.unsqueeze(1)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with autocast(enabled=(device.type == \"cuda\")):\n",
        "                outputs = model(mel)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            with torch.no_grad(), autocast(enabled=(device.type == \"cuda\")):\n",
        "                outputs = model(mel)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * mel.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        loop.set_description(\n",
        "            f\"{'Train' if is_train else 'Val'} \"\n",
        "            f\"loss={loss.item():.3f} acc={(correct/total)*100:5.2f}%\"\n",
        "        )\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "F7CMK1MSY8xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E: Simple CNN training with progress & early stopping\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
        "\n",
        "MAX_EPOCHS = 20\n",
        "PATIENCE = 5\n",
        "\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\"\n",
        "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "\n",
        "print(\"===== Simple CNN training started =====\")\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    print(f\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\")\n",
        "\n",
        "    train_loss, train_acc = run_one_epoch(\n",
        "        cnn_model, train_loader, criterion, optimizer, torch_device\n",
        "    )\n",
        "    val_loss, val_acc = run_one_epoch(\n",
        "        cnn_model, val_loader, criterion, optimizer=None, device=torch_device\n",
        "    )\n",
        "\n",
        "    print(f\"Train: loss={train_loss:.4f}, acc={train_acc*100:5.2f}%\")\n",
        "    print(f\" Val : loss={val_loss:.4f}, acc={val_acc*100:5.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(cnn_model.state_dict(), SAVE_PATH)\n",
        "        print(f\"✓ Saved NEW best model to {SAVE_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"↳ No improvement ({patience_counter}/{PATIENCE})\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nBest VAL acc: {best_val_acc*100:5.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "F71ZARgYY_By",
        "outputId": "97a15702-8358-4d60-b847-cb56750686ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cnn_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4044612437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in train_df:\", train_df.columns.tolist())\n",
        "print(\"First rows:\")\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "89eZZUECZAzS",
        "outputId": "9e57e2dc-c5c9-45a2-ce6c-79ff74483b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3432466018.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns in train_df:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First rows:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: robust audio loader using soundfile with fallback\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "def load_audio(path, target_sr=22050):\n",
        "    \"\"\"\n",
        "    Load a WAV file robustly.\n",
        "    If anything goes wrong, replace with 4 seconds of silence\n",
        "    so training can continue.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        wav, sr = sf.read(path, dtype=\"float32\")\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Failed to read {os.path.basename(path)}: {e}. Using silence instead.\")\n",
        "        sr = target_sr\n",
        "        wav = np.zeros(int(4 * sr), dtype=\"float32\")\n",
        "\n",
        "    # if stereo -> mono\n",
        "    if isinstance(wav, np.ndarray) and wav.ndim > 1:\n",
        "        wav = wav.mean(axis=1)\n",
        "\n",
        "    # resample if needed\n",
        "    if sr != target_sr:\n",
        "        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "\n",
        "    wav = torch.from_numpy(wav)\n",
        "    return wav, sr\n",
        "\n",
        "print(\"Robust load_audio() defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neAJKrDwZYsa",
        "outputId": "78c8d6b7-1c79-4520-b290-bcd8f52b1dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust load_audio() defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: sanity-check the problematic file (optional)\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/kaggle/audio_leo_datasets/196064-2-0-0.wav\"\n",
        "wav, sr = load_audio(test_path)\n",
        "print(\"Loaded test wav:\", test_path)\n",
        "print(\"  sr:\", sr, \" len(samples):\", wav.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8rHiryYbEQS",
        "outputId": "e61ef2ca-1a3d-45a0-e6e7-48b91ca4d794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARN] Failed to read 196064-2-0-0.wav: Error opening '/content/drive/MyDrive/kaggle/audio_leo_datasets/196064-2-0-0.wav': System error.. Using silence instead.\n",
            "Loaded test wav: /content/drive/MyDrive/kaggle/audio_leo_datasets/196064-2-0-0.wav\n",
            "  sr: 22050  len(samples): 88200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Cell 4: DataLoaders\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_ds = UrbanSoundDataset(train_df, DATASET_PATH)\n",
        "val_ds   = UrbanSoundDataset(val_df, DATASET_PATH)\n",
        "test_ds  = UrbanSoundDataset(test_df, DATASET_PATH)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"✓ DataLoaders ready.\")\n",
        "\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:\", len(val_loader))\n",
        "print(\"Test batches:\", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jzNLbiJHZkzL",
        "outputId": "402665f3-885d-4f35-f88a-039715da69ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'UrbanSoundDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1589493777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_ds\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'UrbanSoundDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: define simple CNN model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "num_classes = train_df[\"classID\"].nunique()\n",
        "print(\"Num classes:\", num_classes)\n",
        "\n",
        "class SimpleAudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)          # [B, 128, H, W]\n",
        "        x = self.global_pool(x)       # [B, 128, 1, 1]\n",
        "        x = x.view(x.size(0), -1)     # [B, 128]\n",
        "        x = self.classifier(x)        # [B, num_classes]\n",
        "        return x\n",
        "\n",
        "cnn_model = SimpleAudioCNN(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
        "\n",
        "print(\"Trainable params:\",\n",
        "      sum(p.numel() for p in cnn_model.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEF7nvkvZmwS",
        "outputId": "580dd570-721a-4e6d-861c-51611b2a5691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Num classes: 10\n",
            "Trainable params: 110922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Dataset class using robust loader\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, base_path, augment=False):\n",
        "        self.df = df\n",
        "        self.base_path = base_path\n",
        "        self.augment = augment\n",
        "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=22050,\n",
        "            n_mels=64\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = os.path.join(self.base_path, row[\"slice_file_name\"])\n",
        "\n",
        "        wav, sr = load_audio(path)        # <- robust loader\n",
        "\n",
        "        # normalize audio\n",
        "        wav = wav / (wav.abs().max() + 1e-6)\n",
        "\n",
        "        # crop/pad to 4 seconds\n",
        "        target_len = 4 * sr\n",
        "        if wav.shape[0] < target_len:\n",
        "            wav = torch.cat([wav, torch.zeros(target_len - wav.shape[0])])\n",
        "        else:\n",
        "            wav = wav[:target_len]\n",
        "\n",
        "        # mel spectrogram\n",
        "        mel = self.melspec(wav)\n",
        "        mel = torchaudio.functional.amplitude_to_DB(mel)\n",
        "\n",
        "        label = torch.tensor(row[\"classID\"], dtype=torch.long)\n",
        "        return mel, label\n"
      ],
      "metadata": {
        "id": "HbqySJg6bXa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDUKugO6bYhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: UrbanSoundDataset using robust load_audio + Mel + AmplitudeToDB\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class UrbanSoundDataset(Dataset):\n",
        "    def __init__(self, df, base_path, augment=False,\n",
        "                 sr=22050, n_mels=64, duration=4.0):\n",
        "        \"\"\"\n",
        "        df: dataframe with columns ['slice_file_name', 'fold', 'classID', 'class', ...]\n",
        "        base_path: folder that contains fold1, fold2, ..., fold10\n",
        "        \"\"\"\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.base_path = base_path\n",
        "        self.augment = augment\n",
        "        self.sr = sr\n",
        "        self.n_mels = n_mels\n",
        "        self.duration = duration\n",
        "        self.target_len = int(sr * duration)\n",
        "\n",
        "        # Mel spectrogram (power) + dB\n",
        "        self.mel_tf = torchaudio.transforms.MelSpectrogram(\n",
        "            sample_rate=sr,\n",
        "            n_fft=1024,\n",
        "            hop_length=512,\n",
        "            n_mels=n_mels,\n",
        "            power=2.0,\n",
        "        )\n",
        "        self.db_tf = torchaudio.transforms.AmplitudeToDB(\n",
        "            stype=\"power\",\n",
        "            top_db=80.0\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        fold = int(row[\"fold\"])\n",
        "        fname = row[\"slice_file_name\"]\n",
        "        path = os.path.join(self.base_path, f\"fold{fold}\", fname)\n",
        "\n",
        "        # robust loader you defined earlier\n",
        "        wav, sr = load_audio(path, target_sr=self.sr)   # [T]\n",
        "\n",
        "        # make sure it's 1D mono\n",
        "        if wav.ndim > 1:\n",
        "            wav = wav.mean(dim=0)\n",
        "\n",
        "        # pad / crop to fixed 4s\n",
        "        if wav.shape[-1] < self.target_len:\n",
        "            pad = self.target_len - wav.shape[-1]\n",
        "            wav = torch.nn.functional.pad(wav, (0, pad))\n",
        "        else:\n",
        "            wav = wav[:self.target_len]\n",
        "\n",
        "        # Mel spectrogram: [1, T] -> [n_mels, time]\n",
        "        mel = self.mel_tf(wav.unsqueeze(0)).squeeze(0)\n",
        "        mel = self.db_tf(mel)\n",
        "\n",
        "        # simple per-sample standardization\n",
        "        mel = (mel - mel.mean()) / (mel.std() + 1e-6)\n",
        "\n",
        "        label = int(row[\"classID\"])\n",
        "        return mel, label\n"
      ],
      "metadata": {
        "id": "8MA08SnwaaNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: recreate train / val / test loaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "BATCH_SIZE = 64   # you can try 128 later if GPU still has room\n",
        "\n",
        "train_dataset = UrbanSoundDataset(train_df, DATASET_PATH, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   DATASET_PATH, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  DATASET_PATH, augment=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,  num_workers=1, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=1, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=1, pin_memory=True)\n",
        "\n",
        "print(\"Train batches:\", len(train_loader))\n",
        "print(\"Val batches:  \", len(val_loader))\n",
        "print(\"Test batches: \", len(test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BysuQvDhab6i",
        "outputId": "db0b7e3b-a55a-46ad-e96c-88993a7f4190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2336013967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m   \u001b[0;31m# you can try 128 later if GPU still has room\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mval_dataset\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 (updated): Simple CNN with adaptive pooling\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # [B, 32, 32, T/2]\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # [B, 64, 16, T/4]\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # [B, 128, 8, T/8]\n",
        "        )\n",
        "\n",
        "        # ✅ Adaptive pool to 1x1 so the flatten size is ALWAYS 128\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, n_mels, time] -> [B, 1, n_mels, time]\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv(x)\n",
        "        x = self.global_pool(x)       # [B, 128, 1, 1]\n",
        "        x = x.view(x.size(0), -1)     # [B, 128]\n",
        "        out = self.fc(x)              # [B, num_classes]\n",
        "        return out\n",
        "\n",
        "num_classes = len(train_df[\"classID\"].unique())\n",
        "cnn_model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "print(\"Updated SimpleCNN ready. Trainable params:\",\n",
        "      sum(p.numel() for p in cnn_model.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cyzKYSudcYHx",
        "outputId": "e56d21f4-dbe3-4446-cf49-3b9f912225bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3818792794.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: run_one_epoch() + evaluate()\n",
        "\n",
        "import torch\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def run_one_epoch(model, loader, optimizer=None):\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for mel, label in loader:\n",
        "        mel   = mel.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            out = model(mel)\n",
        "            loss = criterion(out, label)\n",
        "\n",
        "        if is_train:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * mel.size(0)\n",
        "        _, pred = out.max(1)\n",
        "        correct += pred.eq(label).sum().item()\n",
        "        total += mel.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    return run_one_epoch(model, loader, optimizer=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj7O5lMLdw0x",
        "outputId": "7c81381f-5ba4-455b-f9a7-a53eef899da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3184953570.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=(device.type == \"cuda\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 (updated): Train SimpleCNN with tqdm + early stopping\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "print(\"===== Simple CNN training started =====\")\n",
        "\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "MAX_EPOCHS  = 25\n",
        "PATIENCE    = 5\n",
        "best_val_acc = 0.0\n",
        "patience_counter = 0\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\"\n",
        "\n",
        "def train_one_epoch_tqdm(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
        "    for mel, label in pbar:\n",
        "        mel   = mel.to(device)   # [B, n_mels, time]\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            out  = model(mel)    # model does the unsqueeze inside\n",
        "            loss = criterion(out, label)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * mel.size(0)\n",
        "        _, pred = out.max(1)\n",
        "        correct += pred.eq(label).sum().item()\n",
        "        total += mel.size(0)\n",
        "\n",
        "        avg_loss = total_loss / max(total, 1)\n",
        "        avg_acc  = correct / max(total, 1)\n",
        "        pbar.set_postfix(loss=f\"{avg_loss:.3f}\", acc=f\"{avg_acc*100:.1f}%\")\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    avg_acc  = correct / total\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    print(f\"\\n===== Epoch {epoch}/{MAX_EPOCHS} =====\")\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch_tqdm(cnn_model, train_loader, optimizer)\n",
        "    val_loss,   val_acc   = evaluate(cnn_model, val_loader)\n",
        "\n",
        "    print(f\"Train: loss={train_loss:.4f}, acc={train_acc*100:.2f}%\")\n",
        "    print(f\"  Val: loss={val_loss:.4f}, acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    if val_acc > best_val_acc + 1e-4:\n",
        "        best_val_acc = val_acc\n",
        "        patience_counter = 0\n",
        "        torch.save(cnn_model.state_dict(), SAVE_PATH)\n",
        "        print(f\"✔ Saved new best model to {SAVE_PATH}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  No improvement ({patience_counter}/{PATIENCE})\")\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(f\"\\nBest VAL acc: {best_val_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "008e92e79f144ffe9e50adf7591df7a1",
            "5df15942a99247c8a0ba57298ab182ec",
            "b597c70d006946a3a3da913792dc6df0",
            "34402cc7e52a4a0186bb709077b88bf1",
            "b2fa49095d2a4cc08d7baee4a29e82bf",
            "405fe12982394fdb995354cb62a343d8",
            "81b557b2c8b24790be59fb294e29be63",
            "26c888c6935d479f9160f2e8422512d8",
            "20c645deb0244be99a966a9a81a46d03",
            "09d87a25a4c943b98014d1ed87222989",
            "29a70762ce2a4c1585e29bc7716f13ca",
            "fa066a93ffc440d58892dd66ce950297",
            "47862a4a80a144cda2c299e0f622818f",
            "7cc0866763b541f9bbc4040bc036407a",
            "9d3978a6030c480583003e2a35fb185a",
            "df70ab3ce127468ea556f5e21c59c2d1",
            "a4099cab9d3f469bbbf7e666e81b6785",
            "c168b06664524f81893a5557065b653c",
            "fcf55206483b4e128c73fec1593cf834",
            "c512aada8e4743cf984e8732b43b8ca3",
            "f13ae57591f54df8a47958159d74c11f",
            "25128be083b74385bed26f750836620c",
            "787984a206a04d7aaa5c8187f7317c44",
            "9edd531925b24d49af1ff8708add9fae",
            "be77f8e124bf4e549b6bfcc19989df8b",
            "3c8da8c9a129415e93a1847bb8d7235b",
            "20983d1aab9c4384addeff7fc9206415",
            "5498873e4bff40b5bb69d4c7cd5fdcdf",
            "f5d343eac8e7492a83e52904c17e0353",
            "69b5d60a3f7c4e818d632a227d76f239",
            "53d5040d3f054f42b85c52f317039e9f",
            "5880ff438f064bfab7482baf0de69fb7",
            "9d4758ac4da741dbae8b4c9d6e8a3944",
            "c959dc0de0af4dbc827db4d98a44d9a6",
            "1ca57b75cff2449b85eaa0754e412a32",
            "9dd68bba8e7f424bb643a3558f1d724c",
            "a626f9a356034217b63213a597c3a58a",
            "2ba674f012444a6cba860bacce608d23",
            "0bf81aae9b9942a288b52abc1b9ce80b",
            "9e953ac9a0cc48f58fcb313a9f0464eb",
            "2f4d5d6e77b94915a6fcbe7909390c96",
            "d20d25846fc848fda9dbff444faa3ddd",
            "ac93d811d058445e9b59433bfa50eec6",
            "67b5f3e2d0074e63ad5faca073feedda",
            "05f23d2921a1499db93929adb23e5af8",
            "9d7da04e14274d1599437e7fe2c67bb7",
            "5ae4405e77cc4ddeac343977b2a688d3",
            "3c35240fd1a4485cb94ad4ce09d54f25",
            "21e3cecb9f4645b980b84a365ee89845",
            "57532d6c5c0346c4a4c793ec965e8405",
            "a6576cad99a54c9fa88f7be3df6dd2a2",
            "82e178f0105f48869b3c6b4fb11b3fc2",
            "554f4878ca2a4cf9b842fcf932d12cf2",
            "275d9046affb46c7ac7b49e292c208b8",
            "5b5ed592f6ef4c3b8af4eb7982f9c310",
            "721b707a804946fd8ea0a970f9789f9c",
            "f2197dd4b64541ad84798b5b64bec5e8",
            "9353afb621964e858e54f4da6ec20dd4",
            "26b45c536b514ca185b128d8f3cf4451",
            "cb58db6f87b942cca3fe9a01ae227a4c",
            "b459e925236b48e9983b29fa919e41c7",
            "70e0452f257d4e2a9f68b128a0170654",
            "3553dab7464c4de3a98a613a7d2a75fc",
            "45e4dc7dbcc4407ba9a385f9510a39aa",
            "7a984e5984824cde938157ad67eaba3a",
            "d2a97585605c4490877f2d579f0b3bb3",
            "d0d7334f0d5f4f17ac1ddd0082f0b42b",
            "d35c9f493e0d4fc9b2620cfb24d23b77",
            "5f3e8f2e4e6e4ef29a0b1216bb1fd2f5",
            "9850a83df19e43a69b394b47d4b36e02",
            "aaccd54be9854efa86fe0e664a7e18c5",
            "1a1c655654c942a5bc969f4470115979",
            "d5b0d5c820a74911955bd40a46875bcd",
            "d4948d1d2e084ea8a3abf51b08245fe7",
            "d5daf3b85df74f86a10c48a4d3796aaf",
            "e25a40cfbc0c40e2b8760a6b9fe768b3",
            "b4f3b0bac3f646ab99de21e7aa2f521a",
            "b23d8776208946568717205be1b07344",
            "62aaec92ffe74c5fa51f88fadea5cf0c",
            "a098f0a634d8448392a7515c08aead4d",
            "a40c3e6b6170484eb201efb3be3759f2",
            "e9c51cc5a16a4ec99a3bbd022c05e21e",
            "893be78917ca47c386d7e46a37a63587",
            "b3f6f6fb938340f3b67c6e18ce0bab0f",
            "bfa7bee217af4c6f94247aba855b5e8c",
            "abd1ac98679648b7964d44b5eedea196",
            "df2a08ac17784b11a2e6383623f48c4c",
            "562850f9790d42c29bc1e2ec82323784",
            "a22dc88c7ae646b9b4c63ac7b1c3445c",
            "6d5e64d229084b3eb4e7626caf08d567",
            "1cf47c842fb64a79aeaa316c86ecc6c9",
            "95add7f109c749dea5a3cfc24200e45f",
            "6a6861ee50f749788b2f6f91f7083aac",
            "2a08e2518912408bba4879e14a52e377",
            "d346147233124375b7777cf230f7cc1d",
            "16c0ff40678f4341b45d123f26b574f3",
            "9030593e8b5a41ec87655da22e1304b1",
            "727dac18199d4626923670d7b2e1a8a7",
            "b54a1ee9c2fa415d93cd13aa871c1df1",
            "0b12b0a9db5e4d12bf818e296a97c460",
            "5dbfcb252ba3499e92d356ad0c9d5586",
            "b2f4a0330b494b52b3073a2cb93529ba",
            "a50b3afe5ef24cecb8e8d2698404d327",
            "5f997aa363b64c26aeec717ccd665c93",
            "45634c6d93c34b128d668bdbacbd5dda",
            "7d6c7cb6480e4cf0aca2475620f1c54b",
            "2a69ba2a316d4c28a6ab8c75d2bc7461",
            "1abb09e799544e1489e7ff4a9cd457ae",
            "89eca1fa94ae4738a7ce3267d24f1d32",
            "93cba5c229c740b586b63a9593e63884",
            "4295e11c79794e568b6ad04d8e304ccc",
            "5b042de611c44f7faaecbf4733356983",
            "626dd984af294b78b4c43d2182bd9bc7",
            "9fe83b9c33934b028feb8201eff10061",
            "efed1c8ce5f94a5ca34b321dfec31902",
            "2fc67de7987a4281ae48742ba8e5e092",
            "cc76f568a6434635910c599ddcf61678",
            "628cfad3988d4e5cb8dca0a777e20606",
            "dd7d76c45568436c8e67ac7f514b2762",
            "3dcc25e2d3b447398bc8730aca7dc6bb",
            "5c751862e07849749f4a3806c6584c39",
            "0ccbf6b6e5ce4977bf532f2c4e32e92c",
            "3e6a02e5290b43f3a55ee6be4462c022",
            "d17eea7022f44372a20af19df63bc19e",
            "dbe79eb3587246409d96e5d616deac94",
            "9501dcfe0bf54281be4b68822c6a43a1",
            "ae7c3713855f493a872db13716a16e45",
            "6a0fa9abb8a549658384edf6b6c11950",
            "d9b9a5507d3e4bffb80b52991b13ae5c",
            "7a0c502ab46d4e618196da7970b1b35c",
            "c9c573d9c9aa4b9d885083f16912d30b",
            "e429cf109a4744b09a70df57f2fa3fa6",
            "6d6f7bc2d80a4d16bcadecc6f293de2c",
            "b3580801943549a0b333183846b689d5",
            "d4b3b249cd8c42e4a4724a5838ff5f7f",
            "9eb11cb83c0c4da5b6a03ab2fc21670c",
            "928cff03cfa5463eac543d23886bb4a9",
            "35e628bb468a409e8678547b7edd10f7",
            "5e316c02277a4237b417505ab9481339",
            "dea6c2ed7449487691e3417ccd7ba02b",
            "f1fc0c136e3d44cdaddc3bb09451137e",
            "3047b5220c3a4e9b9a09868c81a85378",
            "ac8775d46c34430794f5aa05cf30847b",
            "ebbf7cfe603d40af9ee8bff7a04e9d98",
            "dd8d3d0134684b29a8c5200effbeb555",
            "d91982959dda4cbeaf4b2e1e2b6a4def",
            "15d2779279934cf3a1b587a81b65d5c6",
            "f563bac06dff4524acac9dc7fc483d1f",
            "d76c971325cb4d3f95c7e55a7eb034ad",
            "41e69f67ad6a4b5fad19aab71b10241d",
            "4ba1d0a3476a436086444daa1983f62e",
            "55c6d31fb96f4308ad2d4d572d8a04fb",
            "075fc1d655ca4db799a4dbf04c31c3f3",
            "a184084c81f84d408d0eb57f7c4b84a4",
            "245834d3e79a42538cd7f4d7f31a5810",
            "c7d644c18c224c219c73cb07a2dbbd73",
            "ec2f91426b1b424c92379077ff14ccb0",
            "89b4f97be8c14187a66a739cbf31f67f",
            "74de70aab5fc4aca83634d261a14988a",
            "7ca0d9da85fe4105b1e623d86b22cba7",
            "701722d18e5c42eb8b52d0bedd492f3b",
            "0988a6f879634853aacfc11d177e909a",
            "60afe56c172d43cf8b769c9db1951a27",
            "9ed5ff81cfd24049aeef8c129e2774ab",
            "a6f554503e1447c7a1dab6c05180a4a7",
            "96da132e31e74631aca5234ab4c366e1",
            "ce49cdc11371480396fbf32dd8bfca73",
            "9cd856fef40347f3ab1011b7bd307828",
            "c67637b43ad246aca63e8c4a1b05937e",
            "8f56833a2306415a91a2353ee04805b2",
            "6146087b5b974cf4b7152a012ce1efb4",
            "2e85c59a47674c34b0253a72fb8423a9",
            "73b51e6351f14cf0915da5e39daec94a",
            "2ee75f79e4924701bf6adf93e6dfec02",
            "6d9a9129dbef4fe1be4f0e98eb3e767f",
            "d4dbe58139cf435bb86bff20614ea8ad",
            "19ed313250b343128733cf4a3eebfe5e",
            "823e87fd53d0482fb8f4fd43d81b2195",
            "f565f693ce2b44a8872a25445b799f19",
            "7b129cfeed6a4dd8b9516548d8752bf4",
            "d30d0908cdcf48d69403006fc4d798f3",
            "dbdb400f13ff4ae29a985ed33e03edfe",
            "a03d5318e8cd4de7b82721d7ac78c421",
            "ef65bfe4a3db4a41908094f4d9766dba",
            "ee39b6239d7c4a41b3f619d6f1440484",
            "af8485c359b94e87bba0a8089e2dea9b",
            "7b1f2881f1d44e37866683ee137cd0d3"
          ]
        },
        "id": "oiUFF_btdyXZ",
        "outputId": "e5a54e42-2a36-4bdc-b6b8-1766e19a1b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Simple CNN training started =====\n",
            "\n",
            "===== Epoch 1/25 =====\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2418531612.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=(device.type == \"cuda\"))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "008e92e79f144ffe9e50adf7591df7a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2418531612.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "/tmp/ipython-input-3184953570.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=1.5939, acc=42.68%\n",
            "  Val: loss=1.4620, acc=50.74%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 2/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa066a93ffc440d58892dd66ce950297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "              ^  ^  ^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^^ ^ ^ ^ ^^  ^ ^^ ^ ^ ^ ^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=1.0671, acc=62.52%\n",
            "  Val: loss=1.3665, acc=52.57%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 3/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "787984a206a04d7aaa5c8187f7317c44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "   Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "  ^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():^^\n",
            "^ ^ ^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^   ^ ^ ^ ^ ^ ^  ^ ^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^ ^ ^ ^ ^ ^ ^^ ^  ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process\n",
            "^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():\n",
            " ^ ^ ^ ^^ ^ ^ ^^^\n",
            "AssertionError^: ^can only test a child process\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "     if w.is_alive():\n",
            "               ^  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^  ^ ^ ^ ^ ^ ^^^^^^^\n",
            "^AssertionError^: can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.8756, acc=70.01%\n",
            "  Val: loss=1.2560, acc=63.36%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 4/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c959dc0de0af4dbc827db4d98a44d9a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^^^self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "         ^ ^^^ ^ ^ ^ ^ ^ ^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^^ ^ ^ ^^^ ^^ ^^^ ^^ ^^^ ^^ ^  ^^^^^^^^^^^^\n",
            "AssertionError^^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():^\n",
            "^  ^ ^^^ ^ ^  ^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "        if w.is_alive():\n",
            "           ^ ^^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^ ^ ^ ^ ^^  ^  ^ ^ ^ ^^^^^^^^^^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():^^\n",
            "^ ^ ^ ^ \n",
            " AssertionError :  can only test a child process^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "                ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^^ ^ ^ ^ ^ ^ ^ ^^^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.7663, acc=74.56%\n",
            "  Val: loss=1.5099, acc=53.19%\n",
            "  No improvement (1/5)\n",
            "\n",
            "===== Epoch 5/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05f23d2921a1499db93929adb23e5af8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            " ^ \n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' ^^\n",
            "^ ^^ ^  ^ ^^ ^ ^^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "   ^   ^^ ^  ^ ^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>AssertionError: \n",
            "can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "self._shutdown_workers()\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "if w.is_alive():    \n",
            "if w.is_alive(): \n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process'   \n",
            "         ^ ^ ^ ^^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^^^    ^^\n",
            "AssertionErrorself._shutdown_workers(): can only test a child process\n",
            "\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "        self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "if w.is_alive():    if w.is_alive():\n",
            "\n",
            "            ^  ^^^^^^^^^^^^^^^\n",
            "^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "              ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^\n",
            "AssertionError: AssertionErrorcan only test a child process: \n",
            "can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "self._shutdown_workers()\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "self._shutdown_workers()\n",
            "    if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    \n",
            " if w.is_alive(): \n",
            "          ^^  ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                   ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError\n",
            ": AssertionErrorcan only test a child process: \n",
            "can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "         ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.6729, acc=78.51%\n",
            "  Val: loss=1.2995, acc=67.52%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 6/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "721b707a804946fd8ea0a970f9789f9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:     assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      if w.is_alive():  \n",
            "  ^ ^ ^ ^^ ^  ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^^ ^ ^ ^ ^  ^ ^ \n",
            "AssertionError :  can only test a child process^^^^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^^^if w.is_alive():\n",
            "^ ^  ^  ^ ^ ^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  ^ ^ \n",
            " AssertionError :    can only test a child process\n",
            "  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^^\n",
            "^  ^^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError:   can only test a child process \n",
            " Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       self._shutdown_workers() \n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^^\n",
            "  ^^  ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ \n",
            "  AssertionError : can only test a child process \n",
            "  Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    ^if w.is_alive():^\n",
            "^ ^ ^  ^^  ^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^^  ^ ^^   ^\n",
            " AssertionError  : can only test a child process  \n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ ^ ^   ^ ^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: can only test a child process\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "     if w.is_alive(): \n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ ^  ^^  \n",
            "AssertionError :   can only test a child process \n",
            "  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^^^   ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
            "\n",
            " Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "  Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "      self._shutdown_workers() \n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      ^if w.is_alive():^\n",
            "^ ^^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ \n",
            " AssertionError :  can only test a child process \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.6260, acc=79.39%\n",
            "  Val: loss=1.2855, acc=61.52%\n",
            "  No improvement (1/5)\n",
            "\n",
            "===== Epoch 7/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0d7334f0d5f4f17ac1ddd0082f0b42b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            " Traceback (most recent call last):\n",
            " ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "      ^^  ^^  ^^ ^ ^ ^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^ ^ ^ ^ ^ ^ ^ ^^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: ^can only test a child process^^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "    AssertionErrorif w.is_alive():: \n",
            "can only test a child process \n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "      ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    ^if w.is_alive():^\n",
            "^  ^ ^ ^ ^^ ^ \n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^^ ^  ^^ ^ \n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^: ^can only test a child process^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^^    ^self._shutdown_workers()\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "    AssertionErrorif w.is_alive()::  \n",
            "can only test a child process \n",
            " Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^^\n",
            " ^ ^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^^^ ^ ^  ^  ^ ^  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^^: ^can only test a child process\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^^self._shutdown_workers()^\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "AssertionError:     if w.is_alive():can only test a child process\n",
            "\n",
            "  Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "  Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "     ^^self._shutdown_workers()\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^^if w.is_alive():\n",
            "^ ^^  ^\n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^  ^  ^^ ^ ^ ^ ^ ^^ ^ \n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^ ^^ ^^  ^^  ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():\n",
            "\n",
            " AssertionError :  can only test a child process  \n",
            "  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^if w.is_alive():\n",
            " ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "     ^ ^  ^ ^  ^  ^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^  ^^ ^  ^  ^^  ^^ ^ ^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():\n",
            "^ ^ ^ ^^ \n",
            " AssertionError :  can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "            ^ ^ ^ ^ ^ ^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^  ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.5601, acc=82.03%\n",
            "  Val: loss=1.0264, acc=69.12%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 8/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b23d8776208946568717205be1b07344"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "    Traceback (most recent call last):\n",
            "if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "     self._shutdown_workers()\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "    ^  ^  ^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError\n",
            ": AssertionErrorcan only test a child process: \n",
            "can only test a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "        if w.is_alive(): \n",
            "    ^^  ^ ^  ^^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^^  \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "        ^  ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process\n",
            "^\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>AssertionError\n",
            ": can only test a child processTraceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "if w.is_alive():\n",
            "    self._shutdown_workers()  \n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "     if w.is_alive(): \n",
            "  ^ ^^   ^ ^ ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "               ^  ^^^^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "if w.is_alive():\n",
            "    if w.is_alive(): \n",
            "           ^  ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                    ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process^\n",
            "Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "AssertionErrorTraceback (most recent call last):\n",
            ":   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "can only test a child process    \n",
            "self._shutdown_workers()Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    if w.is_alive():    \n",
            "self._shutdown_workers() \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive():\n",
            "     ^ ^^ ^  ^ ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                 ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError\n",
            "AssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():    \n",
            "if w.is_alive():\n",
            "             ^^^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "              ^ ^ ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^^\n",
            "^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "AssertionError:     can only test a child processself._shutdown_workers()\n",
            "\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       self._shutdown_workers()\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       ^^if w.is_alive():^^\n",
            "^ ^ ^  ^  ^ ^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^ ^^\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "           ^  ^^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError\n",
            ": AssertionErrorcan only test a child process\n",
            ": can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.5458, acc=82.40%\n",
            "  Val: loss=1.2819, acc=65.44%\n",
            "  No improvement (1/5)\n",
            "\n",
            "===== Epoch 9/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a22dc88c7ae646b9b4c63ac7b1c3445c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.4689, acc=85.10%\n",
            "  Val: loss=1.2222, acc=71.57%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 10/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b12b0a9db5e4d12bf818e296a97c460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^if w.is_alive():^\n",
            "^ ^^ ^ ^ ^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^^  ^^ ^ ^   ^  ^  ^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ ^^ ^^ ^ ^ ^^  ^^   ^ ^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.4377, acc=85.86%\n",
            "  Val: loss=1.1699, acc=72.92%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 11/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4295e11c79794e568b6ad04d8e304ccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^^    ^self._shutdown_workers()^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "if w.is_alive():  \n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^  ^^^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process^^\n",
            "^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^  ^^ ^^ ^ ^^ \n",
            "AssertionError : ^can only test a child process\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    \n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^^ ^ ^ ^^   ^^ ^ ^^ ^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^ ^^ ^ ^ ^   ^^ ^   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^^: ^can only test a child process^\n",
            "^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.4027, acc=87.07%\n",
            "  Val: loss=0.9798, acc=74.88%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 12/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ccbf6b6e5ce4977bf532f2c4e32e92c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       self._shutdown_workers()\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "         ^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^  \n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "     ^ ^^ ^^ ^ ^  ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "\n",
            "Traceback (most recent call last):\n",
            "AssertionError:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "can only test a child process    \n",
            "self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "if w.is_alive():\n",
            "    self._shutdown_workers() \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      if w.is_alive():\n",
            "        ^^ ^ ^ ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "               ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^\n",
            "AssertionError: AssertionError: can only test a child process\n",
            "can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "self._shutdown_workers()\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "self._shutdown_workers()    \n",
            "if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "      if w.is_alive():  \n",
            "      ^ ^  ^ ^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3843, acc=87.53%\n",
            "  Val: loss=1.0598, acc=77.21%\n",
            "✔ Saved new best model to /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "\n",
            "===== Epoch 13/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d6f7bc2d80a4d16bcadecc6f293de2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>AssertionError\n",
            ": Traceback (most recent call last):\n",
            "can only test a child process\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "        self._shutdown_workers()\n",
            "if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "       if w.is_alive(): \n",
            "     ^ ^ ^^ ^  ^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^  ^ ^    \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^ ^^ ^ ^ ^ ^ ^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^^^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "\n",
            "AssertionError  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            ": can only test a child process    \n",
            "if w.is_alive():\n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers() \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "     if w.is_alive():  \n",
            "^ ^ ^^ ^ ^ ^ ^ ^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "              ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "    if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "    if w.is_alive():  \n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "               ^^  ^ ^^   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            ": AssertionErrorcan only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3745, acc=88.04%\n",
            "  Val: loss=1.2209, acc=73.16%\n",
            "  No improvement (1/5)\n",
            "\n",
            "===== Epoch 14/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebbf7cfe603d40af9ee8bff7a04e9d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^^    ^^self._shutdown_workers()\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                ^ ^ ^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n",
            "^^ ^ ^ ^^ ^ ^^^^^ ^^^^  \n",
            "AssertionError :   can only test a child process^\n",
            "^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():^\n",
            " ^ ^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            " ^  ^ \n",
            "AssertionError :   can only test a child process \n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^^\n",
            "  ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "AssertionError:     can only test a child process\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "  Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "      self._shutdown_workers() \n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "     if w.is_alive(): \n",
            "    ^ ^^  ^ ^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^  ^^  ^ ^  ^ ^^^ ^^ ^^ ^^^\n",
            "^AssertionError: ^^^can only test a child process\n",
            "^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^^self._shutdown_workers()\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^^if w.is_alive():^\n",
            "^ ^  ^  ^  ^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
            "\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "            ^^ ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^  ^^  ^ ^   ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^^\n",
            "^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^\n",
            "    AssertionError: self._shutdown_workers()can only test a child process\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    Exception ignored in: if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "     self._shutdown_workers() \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "^  ^^ ^^ ^ ^^ ^ ^^^^^^^^\n",
            "^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                  ^ ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3481, acc=88.85%\n",
            "  Val: loss=1.0930, acc=73.77%\n",
            "  No improvement (2/5)\n",
            "\n",
            "===== Epoch 15/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "245834d3e79a42538cd7f4d7f31a5810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>  \n",
            " Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^  ^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():\n",
            "\n",
            "AssertionError :  can only test a child process \n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^if w.is_alive():^^\n",
            "\n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "     ^  ^  ^  ^^ ^^ ^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^  ^ ^^  ^  ^^  ^  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: ^^can only test a child process^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^^self._shutdown_workers()^^\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "AssertionError    : if w.is_alive():can only test a child process\n",
            "\n",
            "  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "       ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^^if w.is_alive():^\n",
            "^^  ^ ^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^^  ^^  ^ ^ ^  ^ ^^ ^^ \n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^ ^^^ ^ ^ ^ ^^ ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^^    ^^if w.is_alive():^\n",
            "^ ^   ^ \n",
            "AssertionError: can only test a child process\n",
            " Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0> \n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            " ^  ^^ ^ ^  ^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^  ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "       assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "   ^ ^^ ^  ^^ ^  ^^   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "AssertionError: AssertionErrorcan only test a child process\n",
            "Exception ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "can only test a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    \n",
            "self._shutdown_workers()\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "     ^  ^ ^  ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "   ^  ^  \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "   ^ ^ ^^^ ^  ^^ ^^^ ^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():^\n",
            "^ ^^ \n",
            "AssertionError :  can only test a child process  \n",
            " ^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "        ^ ^  ^  ^^ ^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^  ^  ^  ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process\n",
            "^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "          ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3330, acc=89.33%\n",
            "  Val: loss=1.3541, acc=66.30%\n",
            "  No improvement (3/5)\n",
            "\n",
            "===== Epoch 16/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96da132e31e74631aca5234ab4c366e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^^self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():\n",
            "^ ^ ^ ^ \n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^^  ^^ ^ ^ ^ ^  ^ ^ ^^ \n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^  ^^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError: ^^can only test a child process\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    \n",
            "self._shutdown_workers()AssertionError\n",
            ":   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "can only test a child process\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "     self._shutdown_workers()\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "         if w.is_alive():^\n",
            "^ ^  ^  ^  ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
            "            ^ ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>AssertionError\n",
            ": Traceback (most recent call last):\n",
            "can only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    \n",
            "self._shutdown_workers()\n",
            "Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "        self._shutdown_workers() \n",
            "  ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^^if w.is_alive():^\n",
            "^ ^ ^  ^^  ^ \n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^^ ^ ^ ^ ^\n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "    ^ ^ ^ ^  ^  ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "AssertionError  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            ":     can only test a child processself._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>if w.is_alive():\n",
            "Traceback (most recent call last):\n",
            "\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "         self._shutdown_workers() ^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^^    ^^if w.is_alive():^^\n",
            " ^ ^\n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^ ^ ^^  ^  ^^  ^ ^  ^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^ ^ ^  ^ ^ ^ ^ ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process\n",
            "^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "\n",
            " AssertionError :  can only test a child process \n",
            "  Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            " ^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^^\n",
            "\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "          ^^ ^ ^ ^ ^ ^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^^ ^^  ^^ ^ ^^ ^^  ^^  ^^ ^^^^^^^^^^^^\n",
            "^^AssertionError: ^^can only test a child process^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    if w.is_alive():^\n",
            " ^ ^ ^ ^  ^ ^^^^^^^\n",
            "^AssertionError^: can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
            "\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "            ^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^  ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^^if w.is_alive():\n",
            "^^ ^^  ^ ^ ^  ^^^^^\n",
            "^AssertionError: can only test a child process^\n",
            "^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^^^\n",
            "self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "        if w.is_alive():\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "             ^ ^^ ^^ ^ ^ ^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^^  ^ ^ ^   ^  ^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3255, acc=89.14%\n",
            "  Val: loss=1.2071, acc=70.10%\n",
            "  No improvement (4/5)\n",
            "\n",
            "===== Epoch 17/25 =====\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Train:   0%|          | 0/111 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19ed313250b343128733cf4a3eebfe5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "     self._shutdown_workers() \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^  ^ ^\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "        ^  ^   ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "    AssertionErrorself._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            ": can only test a child process    \n",
            "if w.is_alive():\n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>   \n",
            "Traceback (most recent call last):\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "      ^^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():\n",
            "^ ^ ^ ^^ \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
            "^  ^ ^ ^  ^ ^ ^^  ^ ^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            " ^ ^  ^ ^ ^^   ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process\n",
            "^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    self._shutdown_workers()\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    if w.is_alive():\n",
            "^^ ^^ ^ ^  ^^ ^ ^^^^^\n",
            "^^AssertionError: ^^can only test a child process^\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    self._shutdown_workers()    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      if w.is_alive():\n",
            "             ^^   ^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^ ^^  ^ ^  ^ ^^ ^   ^^^^^^^^^^^^^^^^^\n",
            "AssertionError^: ^can only test a child process\n",
            "^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    ^self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^^ ^ ^ ^ ^ ^^\n",
            "AssertionError^: ^can only test a child process^\n",
            "^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            " \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "            ^ ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            " ^ ^^ ^ ^^  ^^^ ^ ^ ^ ^ ^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    ^self._shutdown_workers()^\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ ^  ^^ ^  ^^^^\n",
            "^AssertionError^^: can only test a child process^\n",
            "^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n",
            "\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^  ^^ ^  ^ ^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^    ^if w.is_alive():^\n",
            "^ ^ ^    ^^ \n",
            "^AssertionError^: ^can only test a child process^\n",
            "^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    \n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "       if w.is_alive(): \n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^  ^ ^ ^ ^ ^ ^  ^^^^^^^^^^^\n",
            "^AssertionError^^: ^^can only test a child process^\n",
            "^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^    ^if w.is_alive():^\n",
            "^ ^ ^^ ^ \n",
            " AssertionError :  can only test a child process^\n",
            "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^\n",
            "^^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    self._shutdown_workers()^^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "\n",
            "      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "             ^^ ^ ^  ^ ^^^^^^^^^^^^^^\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^ ^ ^ ^ ^ ^ ^ ^^  ^ ^ ^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^: ^can only test a child process\n",
            "^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^    ^self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "^^^    ^if w.is_alive():^\n",
            "^   ^  ^ ^^ \n",
            "AssertionError: can only test a child process\n",
            "^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>^^\n",
            "^Traceback (most recent call last):\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "^^    self._shutdown_workers()^\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "        if w.is_alive():\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                ^ ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^^^^ ^ ^ ^ ^ ^ ^ ^ ^  ^^ ^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^^: ^can only test a child process^\n",
            "^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: loss=0.3171, acc=89.41%\n",
            "  Val: loss=1.5450, acc=65.69%\n",
            "  No improvement (5/5)\n",
            "Early stopping triggered.\n",
            "\n",
            "Best VAL acc: 77.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Evaluate best SimpleCNN on test set\n",
        "\n",
        "best_cnn = SimpleCNN(num_classes).to(device)\n",
        "best_cnn.load_state_dict(torch.load(SAVE_PATH, map_location=device))\n",
        "best_cnn.eval()\n",
        "\n",
        "test_loss, test_acc = evaluate(best_cnn, test_loader)\n",
        "\n",
        "print(f\"SimpleCNN TEST loss = {test_loss:.4f}, acc = {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "8PEHrb_NewtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "011e1cea-2f0e-4fb8-e851-1c9e59f15e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cea281122a0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "/tmp/ipython-input-3184953570.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN TEST loss = 0.8129, acc = 73.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = \"/content/drive/MyDrive/kaggle/audio_leo_outputs\"\n",
        "\n",
        "print(\"=== Saved files in output directory ===\")\n",
        "for f in sorted(os.listdir(save_dir)):\n",
        "    print(f\" -\", f)\n"
      ],
      "metadata": {
        "id": "L2qNsE3aeypC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b244c717-c527-4688-bbaa-8999919ed061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Saved files in output directory ===\n",
            " - .gradio\n",
            " - README.txt\n",
            " - audio-leo.log\n",
            " - cnn_only_best.pth\n",
            " - confusion_matrix.png\n",
            " - final_hybrid_cnn_qnn_model.pth\n",
            " - final_hybrid_cnn_qnn_model_finetuned_colab.pth\n",
            " - final_hybrid_model_package.zip\n",
            " - final_training_history.csv\n",
            " - hybrid_8q_history.csv\n",
            " - hybrid_cnn_qnn_best.pth\n",
            " - hybrid_cnn_qnn_big_pretrain_best.pth\n",
            " - hybrid_cnn_qnn_finetuned_colab_20251202_2320.pth\n",
            " - hybrid_resnet_8q_best.pth\n",
            " - hybrid_resnet_8q_ckpt.pth\n",
            " - hybrid_resnet_8q_history.csv\n",
            " - hybrid_resnet_qnn_best.pth\n",
            " - hybrid_resnet_qnn_ckpt.pth\n",
            " - hybrid_resnet_qnn_history.csv\n",
            " - kaggle\n",
            " - simple_cnn_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simplecnn_best.pth\"\n",
        "\n",
        "print(\"Trying to load:\", test_path)\n",
        "\n",
        "try:\n",
        "    state = torch.load(test_path, map_location=\"cpu\")\n",
        "    print(\"✓ Model checkpoint loaded successfully!\")\n",
        "    print(\"Keys:\", list(state.keys())[:5], \" ...\")\n",
        "except Exception as e:\n",
        "    print(\"✗ ERROR loading checkpoint!\")\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJVYgz5J6gdR",
        "outputId": "b7d3c347-0de1-43a7-ca30-35e3c65244d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to load: /content/drive/MyDrive/kaggle/audio_leo_outputs/simplecnn_best.pth\n",
            "✗ ERROR loading checkpoint!\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/kaggle/audio_leo_outputs/simplecnn_best.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 0: Reload metadata ===\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "meta_path = \"/content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\"   # <-- adjust if needed\n",
        "train_df = pd.read_csv(meta_path)\n",
        "\n",
        "print(\"Loaded metadata. Classes:\", train_df[\"class\"].nunique())\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bj3AhuWzBTe",
        "outputId": "fa8291a5-2bbe-491c-e935-34fafb5775d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded metadata. Classes: 10\n",
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  \n",
            "0          dog_bark  \n",
            "1  children_playing  \n",
            "2  children_playing  \n",
            "3  children_playing  \n",
            "4  children_playing  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: rebuild SimpleCNN and load simplecnn_best.pth robustly\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- rebuild the same SimpleCNN class (exactly as in Cell 3) ---\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)      # [B, 1, mel, time]\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)   # [B, 128]\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# number of classes from metadata\n",
        "num_classes = len(train_df[\"classID\"].unique())\n",
        "model_path  = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\"\n",
        "\n",
        "simple_cnn = SimpleCNN(num_classes).to(device)\n",
        "print(\"Model created.\")\n",
        "\n",
        "# ---- robust load: handle possible key name mismatches (cnn. -> conv.) ----\n",
        "state_raw = torch.load(model_path, map_location=\"cpu\")\n",
        "\n",
        "model_state = simple_cnn.state_dict()\n",
        "new_state = {}\n",
        "\n",
        "for k, v in state_raw.items():\n",
        "    # rename old prefix 'cnn.' to new 'conv.' if needed\n",
        "    if k.startswith(\"cnn.\"):\n",
        "        k_new = \"conv.\" + k[len(\"cnn.\"):]\n",
        "    else:\n",
        "        k_new = k\n",
        "\n",
        "    if k_new in model_state and model_state[k_new].shape == v.shape:\n",
        "        new_state[k_new] = v\n",
        "    else:\n",
        "        # just skip mismatched keys (e.g. old FC shapes)\n",
        "        print(f\"[skip] {k} -> {k_new}, shape {v.shape}\")\n",
        "\n",
        "model_state.update(new_state)\n",
        "simple_cnn.load_state_dict(model_state)\n",
        "\n",
        "simple_cnn.eval()\n",
        "print(\"\\n✅ SimpleCNN checkpoint loaded into current model (with possible partial load).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2zPbXgVy10Y",
        "outputId": "9a7ff0f8-d266-4a4e-bb63-91ca96b249cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Model created.\n",
            "\n",
            "✅ SimpleCNN checkpoint loaded into current model (with possible partial load).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path where metadata CSV was originally stored\n",
        "meta_path = \"/content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\"\n",
        "\n",
        "df = pd.read_csv(meta_path)\n",
        "\n",
        "print(\"Loaded metadata, rows:\", len(df))\n",
        "print(df.head())\n",
        "\n",
        "# ==============================\n",
        "# 🔥 Rebuild train/val/test split\n",
        "# ==============================\n",
        "# We used classID earlier in training — keep same setup\n",
        "df[\"class\"] = df[\"classID\"]\n",
        "\n",
        "# UrbanSound8K uses folds 1–10\n",
        "train_df = df[df[\"fold\"].isin([1,2,3,4,5,6,7,8])]\n",
        "val_df   = df[df[\"fold\"] == 9]\n",
        "test_df  = df[df[\"fold\"] == 10]\n",
        "\n",
        "print(\"Split sizes:\")\n",
        "print(\" Train:\", len(train_df))\n",
        "print(\" Val  :\", len(val_df))\n",
        "print(\" Test :\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-PVeG1Uy2S2",
        "outputId": "b70f7551-ea93-45d4-bd2e-c6a1df2be96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded metadata, rows: 8732\n",
            "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
            "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
            "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
            "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
            "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
            "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
            "\n",
            "              class  \n",
            "0          dog_bark  \n",
            "1  children_playing  \n",
            "2  children_playing  \n",
            "3  children_playing  \n",
            "4  children_playing  \n",
            "Split sizes:\n",
            " Train: 7079\n",
            " Val  : 816\n",
            " Test : 837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Recreate test set + test_loader\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Ensure metadata exists\n",
        "print(\"Columns:\", train_df.columns.tolist())\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/kaggle/audio_leo_datasets\"\n",
        "\n",
        "# Rebuild datasets\n",
        "train_dataset = UrbanSoundDataset(train_df, base_path, augment=True)\n",
        "val_dataset   = UrbanSoundDataset(val_df,   base_path, augment=False)\n",
        "test_dataset  = UrbanSoundDataset(test_df,  base_path, augment=False)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"✓ Dataloaders recreated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuYazi0r1E0G",
        "outputId": "027d7864-ef96-454a-ed8b-bcab1bd960f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['slice_file_name', 'fsID', 'start', 'end', 'salience', 'fold', 'classID', 'class']\n",
            "✓ Dataloaders recreated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = len(train_df[\"classID\"].unique())\n",
        "cnn_model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\"\n",
        "print(\"Loading model from:\", model_path)\n",
        "\n",
        "state = torch.load(model_path, map_location=device)\n",
        "cnn_model.load_state_dict(state, strict=False)\n",
        "\n",
        "cnn_model.eval()\n",
        "print(\"✓ SimpleCNN restored and ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vMTGvWL1c6Y",
        "outputId": "df92ff6b-7b06-4ae8-a855-e256e2a38dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /content/drive/MyDrive/kaggle/audio_leo_outputs/simple_cnn_best.pth\n",
            "✓ SimpleCNN restored and ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate_simple(cnn_model, test_loader, device)\n",
        "print(f\"SIMPLECNN TEST → loss = {test_loss:.4f}, acc = {test_acc*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaH8V1kZ1-AZ",
        "outputId": "767d776c-6d21-4796-c9a5-5032a9d4a934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIMPLECNN TEST → loss = 1.4960, acc = 73.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: build confusion matrix for SimpleCNN on TEST\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnn_model.eval()\n",
        "\n",
        "all_targets = []\n",
        "all_preds   = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for mel, labels in test_loader:\n",
        "        mel    = mel.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = cnn_model(mel)\n",
        "        preds  = logits.argmax(dim=1)\n",
        "\n",
        "        all_targets.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "all_targets = np.array(all_targets)\n",
        "all_preds   = np.array(all_preds)\n",
        "\n",
        "cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "# class names in correct order 0..9\n",
        "class_map = (\n",
        "    train_df[[\"classID\", \"class\"]]\n",
        "    .drop_duplicates(\"classID\")\n",
        "    .sort_values(\"classID\")\n",
        ")\n",
        "class_names = class_map[\"class\"].tolist()\n",
        "\n",
        "print(\"Confusion matrix shape:\", cm.shape)\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "# save for later if you like\n",
        "np.save(\"/content/simplecnn_confusion_matrix.npy\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz8WXTY82BMh",
        "outputId": "709f2af3-55df-468f-8a83-9982b1a8be08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix shape: (10, 10)\n",
            "Classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: plot confusion matrix heat-map\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# if you already have cm & class_names from Cell 7, you can reuse them;\n",
        "# otherwise reload:\n",
        "if \"cm\" not in globals():\n",
        "    cm = np.load(\"/content/simplecnn_confusion_matrix.npy\")\n",
        "    class_map = (\n",
        "        train_df[[\"classID\", \"class\"]]\n",
        "        .drop_duplicates(\"classID\")\n",
        "        .sort_values(\"classID\")\n",
        "    )\n",
        "    class_names = class_map[\"class\"].tolist()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"SimpleCNN – Confusion Matrix (Test Set)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "J4zj9-yi4VuP",
        "outputId": "28a30f28-2d83-4b73-e681-f047c3152eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CELL G1: preprocessing + classify for Gradio (safe) =====\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "# UrbanSound8K class names\n",
        "id2label = {\n",
        "    0: 'air_conditioner',\n",
        "    1: 'car_horn',\n",
        "    2: 'children_playing',\n",
        "    3: 'dog_bark',\n",
        "    4: 'drilling',\n",
        "    5: 'engine_idling',\n",
        "    6: 'gun_shot',\n",
        "    7: 'jackhammer',\n",
        "    8: 'siren',\n",
        "    9: 'street_music'\n",
        "}\n",
        "\n",
        "# Make sure these exist from your training code:\n",
        "print(\"Device:\", device)\n",
        "print(\"Model:\", type(cnn_model).__name__)\n",
        "\n",
        "target_sr = 22050\n",
        "target_len_samples = target_sr * 4\n",
        "n_mels = 64\n",
        "\n",
        "mel_extractor = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=target_sr,\n",
        "    n_mels=n_mels\n",
        ")\n",
        "\n",
        "def preprocess_numpy_audio(audio_np):\n",
        "    \"\"\"\n",
        "    audio_np from gr.Audio with type='numpy' is (sr:int, samples:np.ndarray).\n",
        "    Returns mel tensor [1, n_mels, time] on the correct device.\n",
        "    \"\"\"\n",
        "    if audio_np is None:\n",
        "        return None\n",
        "\n",
        "    sr, wav = audio_np\n",
        "\n",
        "    # Handle stereo -> mono\n",
        "    wav = np.asarray(wav)\n",
        "    if wav.ndim > 1:\n",
        "        wav = wav.mean(axis=1 if wav.shape[0] < wav.shape[1] else 0)\n",
        "\n",
        "    wav = wav.astype(\"float32\")\n",
        "\n",
        "    # Resample if needed\n",
        "    if sr != target_sr:\n",
        "        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
        "\n",
        "    # Pad / crop to 4 seconds\n",
        "    if len(wav) < target_len_samples:\n",
        "        pad = target_len_samples - len(wav)\n",
        "        wav = np.concatenate([wav, np.zeros(pad, dtype=\"float32\")])\n",
        "    else:\n",
        "        wav = wav[:target_len_samples]\n",
        "\n",
        "    wav = torch.from_numpy(wav).unsqueeze(0)  # [1, T]\n",
        "\n",
        "    # Mel spectrogram -> dB\n",
        "    mel = mel_extractor(wav)  # [1, n_mels, time]\n",
        "    mel = torchaudio.functional.amplitude_to_DB(\n",
        "        mel,\n",
        "        multiplier=10.0,\n",
        "        amin=1e-10,\n",
        "        db_multiplier=0.0\n",
        "    )\n",
        "\n",
        "    # SimpleCNN expects [B, n_mels, time]\n",
        "    return mel.to(device)\n",
        "\n",
        "\n",
        "def classify_audio_gradio(audio_np):\n",
        "    \"\"\"\n",
        "    Gradio callback: takes numpy audio, returns:\n",
        "      - dict for gr.Label (top-3 class probs)\n",
        "      - summary text\n",
        "    If something goes wrong, returns an error message instead of crashing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mel = preprocess_numpy_audio(audio_np)\n",
        "        if mel is None:\n",
        "            return {}, \"No audio provided.\"\n",
        "\n",
        "        cnn_model.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = cnn_model(mel)              # [1, num_classes]\n",
        "            probs = F.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "        # Top-3\n",
        "        idxs = probs.argsort()[-3:][::-1]\n",
        "        top_labels = [id2label[int(i)] for i in idxs]\n",
        "        top_scores = [float(probs[i]) for i in idxs]\n",
        "\n",
        "        top3_dict = {lab: score for lab, score in zip(top_labels, top_scores)}\n",
        "\n",
        "        pred_label = top_labels[0]\n",
        "        pred_score = top_scores[0] * 100.0\n",
        "\n",
        "        summary_lines = [f\"PRED = {pred_label} ({pred_score:.1f}%)\", \"\"]\n",
        "        for lab, sc in zip(top_labels, top_scores):\n",
        "            summary_lines.append(f\"{lab}: {sc*100:.1f}%\")\n",
        "\n",
        "        summary = \"\\n\".join(summary_lines)\n",
        "\n",
        "        return top3_dict, summary\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print full error to notebook & show short msg in UI\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return {}, f\"Error during classification: {type(e).__name__}: {e}\"\n",
        "\n",
        "print(\"✓ Gradio classify_audio_gradio ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp-qMaVF5HBz",
        "outputId": "f0bc470a-0f87-45a4-fe42-6396cc8646b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Model: SimpleCNN\n",
            "✓ Gradio classify_audio_gradio ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell G1: correct mapping from classID -> real class name\n",
        "\n",
        "id2label = {\n",
        "    0: \"air_conditioner\",\n",
        "    1: \"car_horn\",\n",
        "    2: \"children_playing\",\n",
        "    3: \"dog_bark\",\n",
        "    4: \"drilling\",\n",
        "    5: \"engine_idling\",\n",
        "    6: \"gun_shot\",\n",
        "    7: \"jackhammer\",\n",
        "    8: \"siren\",\n",
        "    9: \"street_music\",\n",
        "}\n",
        "\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "print(\"id2label mapping:\", id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQqeJv2r_XeS",
        "outputId": "9af76698-2844-4277-d814-dee5f2949600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id2label mapping: {0: 'air_conditioner', 1: 'car_horn', 2: 'children_playing', 3: 'dog_bark', 4: 'drilling', 5: 'engine_idling', 6: 'gun_shot', 7: 'jackhammer', 8: 'siren', 9: 'street_music'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell G2: Gradio callback using id2label + numpy audio\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "\n",
        "# Make sure cnn_model and device are already defined and checkpoint loaded\n",
        "\n",
        "def preprocess_numpy_audio(audio, target_sr=22050, n_mels=64, duration=4.0):\n",
        "    \"\"\"\n",
        "    audio: (sr, np.ndarray) from gr.Audio(type=\"numpy\")\n",
        "    returns: mel tensor [1, n_mels, T] on device, or None on failure\n",
        "    \"\"\"\n",
        "    if audio is None:\n",
        "        return None\n",
        "\n",
        "    sr, wav = audio  # gradio gives us (sr, array)\n",
        "\n",
        "    # mono\n",
        "    if wav.ndim == 2:  # (time, channels) or (channels, time)\n",
        "        if wav.shape[0] < wav.shape[1]:\n",
        "            wav = wav.mean(axis=1)\n",
        "        else:\n",
        "            wav = wav.mean(axis=0)\n",
        "\n",
        "    # ensure float32\n",
        "    wav = wav.astype(np.float32)\n",
        "\n",
        "    # resample with librosa if needed\n",
        "    import librosa\n",
        "    if sr != target_sr:\n",
        "        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "\n",
        "    # normalize\n",
        "    if np.max(np.abs(wav)) > 0:\n",
        "        wav = wav / np.max(np.abs(wav))\n",
        "\n",
        "    # pad / crop to fixed length\n",
        "    target_len = int(target_sr * duration)\n",
        "    if wav.shape[0] < target_len:\n",
        "        pad = target_len - wav.shape[0]\n",
        "        wav = np.pad(wav, (0, pad), mode=\"constant\")\n",
        "    else:\n",
        "        wav = wav[:target_len]\n",
        "\n",
        "    # to torch\n",
        "    wav_t = torch.from_numpy(wav).unsqueeze(0)  # [1, T]\n",
        "\n",
        "    # make mel like in training\n",
        "    import torchaudio\n",
        "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=target_sr,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=n_mels,\n",
        "        power=2.0,\n",
        "    )\n",
        "    db_transform = torchaudio.transforms.AmplitudeToDB(\n",
        "        stype=\"power\",\n",
        "        top_db=80.0,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mel = mel_transform(wav_t)        # [1, n_mels, T]\n",
        "        mel = db_transform(mel)           # dB scale\n",
        "\n",
        "    # send to same device as model\n",
        "    mel = mel.to(device)\n",
        "\n",
        "    return mel\n",
        "\n",
        "\n",
        "def classify_audio_gradio(audio):\n",
        "    \"\"\"\n",
        "    Gradio callback: audio is (sr, np.ndarray)\n",
        "    returns: (top-3 label dict, summary string) with REAL class names\n",
        "    \"\"\"\n",
        "    mel = preprocess_numpy_audio(audio)\n",
        "    if mel is None:\n",
        "        return {}, \"No audio provided.\"\n",
        "\n",
        "    cnn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = cnn_model(mel)          # [1, num_classes]\n",
        "        probs = softmax(logits)[0].cpu().numpy()\n",
        "\n",
        "    # top-3 indices\n",
        "    top_idx = probs.argsort()[::-1][:3]\n",
        "    top_labels = [id2label[int(i)] for i in top_idx]\n",
        "    top_scores = [float(probs[i]) for i in top_idx]\n",
        "\n",
        "    # dict for gr.Label (name -> prob)\n",
        "    top3_dict = {lab: score for lab, score in zip(top_labels, top_scores)}\n",
        "\n",
        "    # summary text\n",
        "    pred_label = top_labels[0]\n",
        "    pred_score = top_scores[0] * 100.0\n",
        "    summary = f\"PRED: {pred_label} ({pred_score:.1f}%)\\nTop-3:\\n\" + \"\\n\".join(\n",
        "        [f\"{lab}: {s*100:.1f}%\" for lab, s in zip(top_labels, top_scores)]\n",
        "    )\n",
        "\n",
        "    return top3_dict, summary\n",
        "\n",
        "\n",
        "# Gradio UI\n",
        "inputs_audio = gr.Audio(\n",
        "    sources=[\"upload\", \"microphone\"],\n",
        "    type=\"numpy\",\n",
        "    label=\"Upload or record an UrbanSound8K-style clip (wav/mp3)\",\n",
        ")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=classify_audio_gradio,\n",
        "    inputs=inputs_audio,\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Top-3 predictions\"),\n",
        "        gr.Textbox(label=\"Prediction summary (text)\"),\n",
        "    ],\n",
        "    title=\"SimpleCNN UrbanSound8K Classifier\",\n",
        "    description=\"Baseline CNN (~73% test acc). Upload an UrbanSound8K-style 4s clip to classify.\",\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "SDdPMViA7UpC",
        "outputId": "aa5e71e2-f1a4-4594-b4b0-e9a767511433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d0b88ddd2d1a986773.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d0b88ddd2d1a986773.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell M1: Build id2label from the ORIGINAL UrbanSound8K metadata\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# TODO: adjust this path to wherever UrbanSound8K.csv actually is\n",
        "csv_path = \"/content/drive/MyDrive/kaggle/audio_leo_datasets/UrbanSound8K.csv\"\n",
        "\n",
        "meta_full = pd.read_csv(csv_path)\n",
        "\n",
        "class_map = (\n",
        "    meta_full[[\"classID\", \"class\"]]\n",
        "    .drop_duplicates()\n",
        "    .sort_values(\"classID\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(class_map)\n",
        "\n",
        "id2label = {int(row.classID): str(row[\"class\"]) for _, row in class_map.iterrows()}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "print(\"id2label:\", id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QshB2n0V-aL4",
        "outputId": "a39105ba-8bd8-4d7f-be4d-cdc21a0e1f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   classID             class\n",
            "0        0   air_conditioner\n",
            "1        1          car_horn\n",
            "2        2  children_playing\n",
            "3        3          dog_bark\n",
            "4        4          drilling\n",
            "5        5     engine_idling\n",
            "6        6          gun_shot\n",
            "7        7        jackhammer\n",
            "8        8             siren\n",
            "9        9      street_music\n",
            "id2label: {0: 'air_conditioner', 1: 'car_horn', 2: 'children_playing', 3: 'dog_bark', 4: 'drilling', 5: 'engine_idling', 6: 'gun_shot', 7: 'jackhammer', 8: 'siren', 9: 'street_music'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell M2: Check a known dog_bark example from your metadata\n",
        "\n",
        "import torch\n",
        "\n",
        "# Pick one row that is dog_bark in the ORIGINAL metadata\n",
        "dog_row = meta_full[meta_full[\"class\"] == \"dog_bark\"].iloc[0]\n",
        "print(\"Using file:\", dog_row[\"slice_file_name\"], \"classID:\", dog_row[\"classID\"])\n",
        "\n",
        "dog_path = f\"/content/drive/MyDrive/kaggle/audio_leo_datasets/{dog_row['slice_file_name']}\"\n",
        "\n",
        "# Use the SAME preprocessing as training, not the Gradio one\n",
        "wav, sr = load_audio(dog_path)      # your robust loader\n",
        "mel, label = UrbanSoundDataset(train_df, base_path=\"\", augment=False)._UrbanSoundDataset__getitem_transform(wav, dog_row[\"classID\"])  # pseudo; if this is too weird, just reuse your dataset: get one sample from train_dataset/test_dataset where label is dog_bark\n",
        "\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = cnn_model(mel.unsqueeze(0).to(device))\n",
        "    probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "pred_idx = int(probs.argmax())\n",
        "print(\"Pred index:\", pred_idx, \"name:\", id2label[pred_idx])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vVahibASA2ve",
        "outputId": "35f2b6da-4979-4c68-9d26-036ad1fbab83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using file: 100032-3-0-0.wav classID: 3\n",
            "[WARN] Failed to read 100032-3-0-0.wav: Error opening '/content/drive/MyDrive/kaggle/audio_leo_datasets/100032-3-0-0.wav': System error.. Using silence instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'UrbanSoundDataset' object has no attribute '_UrbanSoundDataset__getitem_transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1464760329.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Use the SAME preprocessing as training, not the Gradio one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdog_path\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# your robust loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUrbanSoundDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UrbanSoundDataset__getitem_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdog_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pseudo; if this is too weird, just reuse your dataset: get one sample from train_dataset/test_dataset where label is dog_bark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'UrbanSoundDataset' object has no attribute '_UrbanSoundDataset__getitem_transform'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just to verify the mapping we are using\n",
        "print(\"id2label mapping:\", id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XU0XWZxCDeq",
        "outputId": "085c2905-068d-4165-a907-414a38796286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id2label mapping: {0: 'air_conditioner', 1: 'car_horn', 2: 'children_playing', 3: 'dog_bark', 4: 'drilling', 5: 'engine_idling', 6: 'gun_shot', 7: 'jackhammer', 8: 'siren', 9: 'street_music'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "cnn_model.eval()\n",
        "\n",
        "DOG_ID = 3              # dog_bark\n",
        "N_SAMPLES = 10          # number of dog_bark samples to test\n",
        "\n",
        "dog_results = []\n",
        "found = 0\n",
        "\n",
        "for mel, label in test_dataset:    # label is already Python int\n",
        "    true_id = int(label)\n",
        "\n",
        "    if true_id != DOG_ID:\n",
        "        continue\n",
        "\n",
        "    # move mel to device\n",
        "    mel = mel.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = cnn_model(mel)\n",
        "        probs = torch.softmax(logits, dim=1)[0].cpu()\n",
        "        pred_id = int(probs.argmax())\n",
        "        conf = float(probs[pred_id])\n",
        "\n",
        "    dog_results.append((true_id, pred_id, conf))\n",
        "    found += 1\n",
        "    if found >= N_SAMPLES:\n",
        "        break\n",
        "\n",
        "if not dog_results:\n",
        "    print(\"❗ No dog_bark samples found in test_dataset\")\n",
        "else:\n",
        "    print(f\"📊 Tested {len(dog_results)} dog_bark samples from TEST:\\n\")\n",
        "    correct = 0\n",
        "    for i, (true_id, pred_id, conf) in enumerate(dog_results):\n",
        "        print(\n",
        "            f\"{i}: true = {id2label[true_id]} ({true_id}) | \"\n",
        "            f\"pred = {id2label[pred_id]} ({pred_id}) | \"\n",
        "            f\"conf = {conf*100:.1f}%\"\n",
        "        )\n",
        "        if true_id == pred_id:\n",
        "            correct += 1\n",
        "\n",
        "    print(f\"\\n✅ Correct dog_bark classifications: {correct}/{len(dog_results)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9tKzYBRCD6A",
        "outputId": "7976eac4-99e6-4d30-ac5f-d0d408c8615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Tested 10 dog_bark samples from TEST:\n",
            "\n",
            "0: true = dog_bark (3) | pred = dog_bark (3) | conf = 99.7%\n",
            "1: true = dog_bark (3) | pred = dog_bark (3) | conf = 99.7%\n",
            "2: true = dog_bark (3) | pred = dog_bark (3) | conf = 99.9%\n",
            "3: true = dog_bark (3) | pred = dog_bark (3) | conf = 99.9%\n",
            "4: true = dog_bark (3) | pred = car_horn (1) | conf = 56.7%\n",
            "5: true = dog_bark (3) | pred = car_horn (1) | conf = 46.5%\n",
            "6: true = dog_bark (3) | pred = dog_bark (3) | conf = 99.7%\n",
            "7: true = dog_bark (3) | pred = dog_bark (3) | conf = 97.4%\n",
            "8: true = dog_bark (3) | pred = children_playing (2) | conf = 97.0%\n",
            "9: true = dog_bark (3) | pred = children_playing (2) | conf = 87.3%\n",
            "\n",
            "✅ Correct dog_bark classifications: 6/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E1: generic evaluation helper\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def evaluate_model(model, loader, device):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, labels in loader:\n",
        "            mel = mel.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(mel)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item() * mel.size(0)\n",
        "            _, preds = logits.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtD--8pdCJLU",
        "outputId": "ff5fccf7-672c-40b8-cc57-2c0dc98ca234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A: Restore the original AudioCNNClassifier definition\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AudioCNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        # Flatten automatically → Adaptive pooling NOT used in this version\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * 8 * 8, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, n_mels, time]\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "\n",
        "print(\"AudioCNNClassifier restored successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQGDto6SENhV",
        "outputId": "b8ee4a7f-21f8-4762-fb80-7ead49b66d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioCNNClassifier restored successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B: Restore HybridResnetQNN (old version you trained)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# IMPORTANT: You must also have your QNN module loaded above this (QNode, pennylane code)\n",
        "\n",
        "class HybridResnetQNN(nn.Module):\n",
        "    def __init__(self, num_classes=10, alpha=1.0, beta=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # CNN backbone used during training\n",
        "        self.cnn = AudioCNNClassifier(num_classes=128)\n",
        "\n",
        "        # QNN head from your training code\n",
        "        self.qnn = qnode_layer  # ← your original QNN layer (already defined earlier)\n",
        "\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        q = self.qnn(x)\n",
        "        out = self.fc(q)\n",
        "        return out\n",
        "\n",
        "print(\"HybridResnetQNN restored.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OWq4042Eb8y",
        "outputId": "9f849781-f5e0-4f8b-e904-646c06bd620c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridResnetQNN restored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell E2: evaluate ResNet CNN-only checkpoint on TEST\n",
        "\n",
        "num_classes = len(train_df[\"classID\"].unique())\n",
        "print(\"num_classes:\", num_classes)\n",
        "\n",
        "cnn_only_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\"\n",
        "print(\"Loading CNN-only checkpoint from:\", cnn_only_path)\n",
        "\n",
        "# This class name should match the one you used when training that model\n",
        "cnn_only = AudioCNNClassifier(num_classes=num_classes).to(device)\n",
        "\n",
        "state = torch.load(cnn_only_path, map_location=device)\n",
        "cnn_only.load_state_dict(state)\n",
        "\n",
        "test_loss_cnn, test_acc_cnn = evaluate_model(cnn_only, test_loader, device)\n",
        "print(f\"\\nCNN-only TEST -> loss = {test_loss_cnn:.4f}, acc = {test_acc_cnn*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "5PKuaecOEecK",
        "outputId": "5e7297a2-325e-4abc-8f71-0e384d4b2861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes: 10\n",
            "Loading CNN-only checkpoint from: /content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for AudioCNNClassifier:\n\tMissing key(s) in state_dict: \"cnn.0.weight\", \"cnn.0.bias\", \"cnn.1.weight\", \"cnn.1.bias\", \"cnn.1.running_mean\", \"cnn.1.running_var\", \"cnn.4.weight\", \"cnn.4.bias\", \"cnn.5.weight\", \"cnn.5.bias\", \"cnn.5.running_mean\", \"cnn.5.running_var\", \"cnn.8.weight\", \"cnn.8.bias\", \"cnn.9.weight\", \"cnn.9.bias\", \"cnn.9.running_mean\", \"cnn.9.running_var\", \"fc.0.weight\", \"fc.0.bias\", \"fc.3.weight\", \"fc.3.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.features.0.weight\", \"backbone.features.0.bias\", \"backbone.features.1.weight\", \"backbone.features.1.bias\", \"backbone.features.1.running_mean\", \"backbone.features.1.running_var\", \"backbone.features.1.num_batches_tracked\", \"backbone.features.5.weight\", \"backbone.features.5.bias\", \"backbone.features.6.weight\", \"backbone.features.6.bias\", \"backbone.features.6.running_mean\", \"backbone.features.6.running_var\", \"backbone.features.6.num_batches_tracked\", \"backbone.features.10.weight\", \"backbone.features.10.bias\", \"backbone.features.11.weight\", \"backbone.features.11.bias\", \"backbone.features.11.running_mean\", \"backbone.features.11.running_var\", \"backbone.features.11.num_batches_tracked\", \"backbone.features.15.weight\", \"backbone.features.15.bias\", \"backbone.features.16.weight\", \"backbone.features.16.bias\", \"backbone.features.16.running_mean\", \"backbone.features.16.running_var\", \"backbone.features.16.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.7.weight\", \"classifier.7.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2432651396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_only_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcnn_only\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_loss_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AudioCNNClassifier:\n\tMissing key(s) in state_dict: \"cnn.0.weight\", \"cnn.0.bias\", \"cnn.1.weight\", \"cnn.1.bias\", \"cnn.1.running_mean\", \"cnn.1.running_var\", \"cnn.4.weight\", \"cnn.4.bias\", \"cnn.5.weight\", \"cnn.5.bias\", \"cnn.5.running_mean\", \"cnn.5.running_var\", \"cnn.8.weight\", \"cnn.8.bias\", \"cnn.9.weight\", \"cnn.9.bias\", \"cnn.9.running_mean\", \"cnn.9.running_var\", \"fc.0.weight\", \"fc.0.bias\", \"fc.3.weight\", \"fc.3.bias\". \n\tUnexpected key(s) in state_dict: \"backbone.features.0.weight\", \"backbone.features.0.bias\", \"backbone.features.1.weight\", \"backbone.features.1.bias\", \"backbone.features.1.running_mean\", \"backbone.features.1.running_var\", \"backbone.features.1.num_batches_tracked\", \"backbone.features.5.weight\", \"backbone.features.5.bias\", \"backbone.features.6.weight\", \"backbone.features.6.bias\", \"backbone.features.6.running_mean\", \"backbone.features.6.running_var\", \"backbone.features.6.num_batches_tracked\", \"backbone.features.10.weight\", \"backbone.features.10.bias\", \"backbone.features.11.weight\", \"backbone.features.11.bias\", \"backbone.features.11.running_mean\", \"backbone.features.11.running_var\", \"backbone.features.11.num_batches_tracked\", \"backbone.features.15.weight\", \"backbone.features.15.bias\", \"backbone.features.16.weight\", \"backbone.features.16.bias\", \"backbone.features.16.running_mean\", \"backbone.features.16.running_var\", \"backbone.features.16.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.1.running_mean\", \"classifier.1.running_var\", \"classifier.1.num_batches_tracked\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.7.weight\", \"classifier.7.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Final CNNOnlyBig definition matching cnn_only_best.pth\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AudioCNNBackboneBig(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.05),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.10),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.15),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.20),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.emb_dim = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)          # [B, 1, n_mels, time]\n",
        "        x = self.features(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)           # [B, 256]\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNNOnlyBig(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.backbone = AudioCNNBackboneBig()\n",
        "        emb_dim = self.backbone.emb_dim\n",
        "\n",
        "        # Match checkpoint:\n",
        "        # 0: Linear(256→256)\n",
        "        # 1: BatchNorm1d(256)\n",
        "        # 2: ReLU\n",
        "        # 3: Dropout\n",
        "        # 4: Linear(256→128)\n",
        "        # 5: ReLU\n",
        "        # 6: Dropout\n",
        "        # 7: Linear(128→num_classes)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(emb_dim, 256),      # classifier.0 (has weights)\n",
        "            nn.BatchNorm1d(256),          # classifier.1 (has weights)\n",
        "            nn.ReLU(),                    # classifier.2\n",
        "            nn.Dropout(0.4),              # classifier.3\n",
        "            nn.Linear(256, 128),          # classifier.4 (has weights)\n",
        "            nn.ReLU(),                    # classifier.5 (no weights)\n",
        "            nn.Dropout(0.4),              # classifier.6 (no weights)\n",
        "            nn.Linear(128, num_classes),  # classifier.7 (has weights)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        out = self.classifier(feats)\n",
        "        return out\n",
        "\n",
        "print(\"✔ CNNOnlyBig redefined to match cnn_only_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlBLiFcyElS8",
        "outputId": "16baafc0-5d27-4cd6-ec7b-1571a3b450c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ CNNOnlyBig redefined to match cnn_only_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Load and evaluate cnn_only_best.pth\n",
        "\n",
        "import torch\n",
        "\n",
        "num_classes = len(train_df[\"classID\"].unique())\n",
        "print(\"num_classes:\", num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "cnn_only = CNNOnlyBig(num_classes=num_classes).to(device)\n",
        "\n",
        "cnn_only_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\"\n",
        "print(\"Loading CNN-only checkpoint from:\", cnn_only_path)\n",
        "\n",
        "state = torch.load(cnn_only_path, map_location=device)\n",
        "cnn_only.load_state_dict(state, strict=True)  # should load cleanly now\n",
        "cnn_only.eval()\n",
        "\n",
        "test_loss_cnn, test_acc_cnn = evaluate_model(cnn_only, test_loader, device)\n",
        "print(f\"\\nCNN-only (big backbone) TEST → loss = {test_loss_cnn:.4f}, acc = {test_acc_cnn*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgQuq-uEF3Rx",
        "outputId": "119b7972-b36e-4afc-80d0-69f0289342f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes: 10\n",
            "Device: cuda\n",
            "Loading CNN-only checkpoint from: /content/drive/MyDrive/kaggle/audio_leo_outputs/cnn_only_best.pth\n",
            "\n",
            "CNN-only (big backbone) TEST → loss = 3.8013, acc = 11.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "print(\"Running final SimpleCNN evaluation…\")\n",
        "\n",
        "# Get predictions on test set\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "simple_cnn.eval()\n",
        "with torch.no_grad():\n",
        "    for mel, label in test_loader:\n",
        "        mel = mel.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        logits = simple_cnn(mel)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=id2label.values())\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "disp.plot(ax=ax, xticks_rotation=45, cmap=\"Blues\")\n",
        "plt.title(\"SimpleCNN – Confusion Matrix (Test Set)\")\n",
        "plt.show()\n",
        "\n",
        "# Per-class accuracy\n",
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "print(\"\\n===== Per-class Accuracy =====\")\n",
        "for i, acc in enumerate(per_class_acc):\n",
        "    print(f\"{id2label[i]:20s}: {acc*100:5.2f}%\")\n",
        "\n",
        "# Save confusion matrix\n",
        "conf_matrix_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/simplecnn_confusion_matrix.png\"\n",
        "fig.savefig(conf_matrix_path)\n",
        "print(f\"\\nSaved confusion matrix to:\\n{conf_matrix_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QJlfcYIFF5E4",
        "outputId": "e1f5da44-3547-4ebc-bdce-ff5df165317e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running final SimpleCNN evaluation…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Per-class Accuracy =====\n",
            "air_conditioner     : 72.00%\n",
            "car_horn            : 87.88%\n",
            "children_playing    : 68.00%\n",
            "dog_bark            : 59.00%\n",
            "drilling            : 74.00%\n",
            "engine_idling       : 59.14%\n",
            "gun_shot            : 96.88%\n",
            "jackhammer          : 93.75%\n",
            "siren               : 45.78%\n",
            "street_music        : 95.00%\n",
            "\n",
            "Saved confusion matrix to:\n",
            "/content/drive/MyDrive/kaggle/audio_leo_outputs/simplecnn_confusion_matrix.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = f\"\"\"\n",
        "UrbanSound8K Final Model Summary\n",
        "================================\n",
        "\n",
        "Model Used: SimpleCNN (trained in this notebook)\n",
        "Test Accuracy: {test_acc*100:.2f}%\n",
        "Test Loss: {test_loss:.4f}\n",
        "\n",
        "Per-class accuracy:\n",
        "-------------------\n",
        "\"\"\"\n",
        "\n",
        "for i, acc in enumerate(per_class_acc):\n",
        "    final_summary += f\"{id2label[i]:20s}: {acc*100:5.2f}%\\n\"\n",
        "\n",
        "summary_path = \"/content/drive/MyDrive/kaggle/audio_leo_outputs/final_summary.txt\"\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(final_summary)\n",
        "\n",
        "print(final_summary)\n",
        "print(f\"\\nSummary saved to: {summary_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOVjbldXJATr",
        "outputId": "ac6a3fd1-f208-4b30-8dbf-582fb3958491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UrbanSound8K Final Model Summary\n",
            "================================\n",
            "\n",
            "Model Used: SimpleCNN (trained in this notebook)\n",
            "Test Accuracy: 73.00%\n",
            "Test Loss: 1.4960\n",
            "\n",
            "Per-class accuracy:\n",
            "-------------------\n",
            "air_conditioner     : 72.00%\n",
            "car_horn            : 87.88%\n",
            "children_playing    : 68.00%\n",
            "dog_bark            : 59.00%\n",
            "drilling            : 74.00%\n",
            "engine_idling       : 59.14%\n",
            "gun_shot            : 96.88%\n",
            "jackhammer          : 93.75%\n",
            "siren               : 45.78%\n",
            "street_music        : 95.00%\n",
            "\n",
            "\n",
            "Summary saved to: /content/drive/MyDrive/kaggle/audio_leo_outputs/final_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell G1: imports + globals (run AFTER cnn_model is loaded)\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import gradio as gr\n",
        "\n",
        "# make sure we have the right device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn_model.to(device).eval()\n",
        "\n",
        "# sample rate + mel settings (match your training as closely as possible)\n",
        "TARGET_SR = 22050\n",
        "N_MELS = 64\n",
        "\n",
        "# id2label from your metadata (classID -> name)\n",
        "# if you already have this dict, you can skip redefining it\n",
        "id2label = {\n",
        "    0: \"air_conditioner\",\n",
        "    1: \"car_horn\",\n",
        "    2: \"children_playing\",\n",
        "    3: \"dog_bark\",\n",
        "    4: \"drilling\",\n",
        "    5: \"engine_idling\",\n",
        "    6: \"gun_shot\",\n",
        "    7: \"jackhammer\",\n",
        "    8: \"siren\",\n",
        "    9: \"street_music\",\n",
        "}\n",
        "print(\"Device:\", device)\n",
        "print(\"id2label mapping:\", id2label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8Pi6bkfJJ92",
        "outputId": "454699ba-7f9b-4b48-c9b6-a059747a8e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "id2label mapping: {0: 'air_conditioner', 1: 'car_horn', 2: 'children_playing', 3: 'dog_bark', 4: 'drilling', 5: 'engine_idling', 6: 'gun_shot', 7: 'jackhammer', 8: 'siren', 9: 'street_music'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell G2: preprocessing + classify function + self-test\n",
        "\n",
        "def preprocess_gradio_audio(audio):\n",
        "    \"\"\"\n",
        "    audio from gr.Audio(type='numpy'):\n",
        "      often (sr, np.ndarray), but we also handle just np.ndarray.\n",
        "\n",
        "    Returns: mel Tensor [1, N_MELS, time] on the right device.\n",
        "    \"\"\"\n",
        "    if audio is None:\n",
        "        return None\n",
        "\n",
        "    # handle both (sr, wav) and wav\n",
        "    if isinstance(audio, tuple):\n",
        "        sr, wav = audio\n",
        "    else:\n",
        "        sr, wav = TARGET_SR, audio\n",
        "\n",
        "    wav = np.asarray(wav, dtype=np.float32)\n",
        "\n",
        "    # stereo -> mono\n",
        "    if wav.ndim > 1:\n",
        "        wav = np.mean(wav, axis=1)\n",
        "\n",
        "    # resample if needed\n",
        "    if sr != TARGET_SR:\n",
        "        wav = librosa.resample(wav, orig_sr=sr, target_sr=TARGET_SR)\n",
        "\n",
        "    # pad/trim to 4 seconds\n",
        "    desired_len = TARGET_SR * 4\n",
        "    if len(wav) < desired_len:\n",
        "        wav = np.pad(wav, (0, desired_len - len(wav)))\n",
        "    else:\n",
        "        wav = wav[:desired_len]\n",
        "\n",
        "    # compute mel spectrogram\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=wav,\n",
        "        sr=TARGET_SR,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=N_MELS,\n",
        "        fmin=20,\n",
        "        fmax=8000,\n",
        "    )\n",
        "    mel = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    # simple standardization (like BatchNorm-ish)\n",
        "    mel = (mel - mel.mean()) / (mel.std() + 1e-6)\n",
        "\n",
        "    mel_tensor = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)  # [1, N_MELS, time]\n",
        "    return mel_tensor.to(device)\n",
        "\n",
        "\n",
        "def classify_audio_gradio(audio):\n",
        "    \"\"\"\n",
        "    Gradio callback: audio -> (top-3 dict, summary text)\n",
        "    \"\"\"\n",
        "    mel = preprocess_gradio_audio(audio)\n",
        "    if mel is None:\n",
        "        return {}, \"No audio provided.\"\n",
        "\n",
        "    cnn_model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = cnn_model(mel)\n",
        "        probs = F.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "    # top-3\n",
        "    top3_idx = probs.argsort()[::-1][:3]\n",
        "    top3_labels = [id2label[int(i)] for i in top3_idx]\n",
        "    top3_scores = [float(probs[i]) for i in top3_idx]\n",
        "\n",
        "    top3_dict = {lab: score for lab, score in zip(top3_labels, top3_scores)}\n",
        "\n",
        "    summary = f\"PRED: {top3_labels[0]} ({top3_scores[0]*100:.1f}%)\\n\"\n",
        "    summary += \"\\n\".join(\n",
        "        f\"{lab}: {score*100:.1f}%\"\n",
        "        for lab, score in zip(top3_labels, top3_scores)\n",
        "    )\n",
        "\n",
        "    return top3_dict, summary\n",
        "\n",
        "\n",
        "# ---------- quick self-test (no Gradio) ----------\n",
        "dummy_audio = (TARGET_SR, np.zeros(TARGET_SR * 4, dtype=np.float32))\n",
        "try:\n",
        "    d, s = classify_audio_gradio(dummy_audio)\n",
        "    print(\"✅ Self-test OK. Output keys:\", list(d.keys()))\n",
        "    print(\"Summary preview:\\n\", s)\n",
        "except Exception as e:\n",
        "    print(\"❌ Self-test FAILED:\")\n",
        "    raise e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFdghh6-JPkl",
        "outputId": "0412c659-1418-4dc0-ca72-d1390e66c1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Self-test OK. Output keys: ['drilling', 'jackhammer', 'car_horn']\n",
            "Summary preview:\n",
            " PRED: drilling (43.4%)\n",
            "drilling: 43.4%\n",
            "jackhammer: 30.4%\n",
            "car_horn: 12.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell G3: Gradio UI\n",
        "\n",
        "inputs_audio = gr.Audio(\n",
        "    sources=[\"upload\", \"microphone\"],\n",
        "    type=\"numpy\",\n",
        "    label=\"Upload or record a 4-sec UrbanSound8K-style clip (wav/mp3)\"\n",
        ")\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=classify_audio_gradio,\n",
        "    inputs=inputs_audio,\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=3, label=\"Top-3 predictions\"),\n",
        "        gr.Textbox(label=\"Prediction summary (text)\"),\n",
        "    ],\n",
        "    title=\"SimpleCNN UrbanSound8K Classifier\",\n",
        "    description=\"Upload a 4-sec sound clip. Model accuracy ≈ 73%.\",\n",
        ")\n",
        "\n",
        "# debug=True makes Gradio print any Python errors in the cell output\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4QfbiVfcLPuW",
        "outputId": "c1f7c544-dc3f-4db6-ef13-6696e464c45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1d11c2e5579ccd3f26.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d11c2e5579ccd3f26.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e09a71ec230 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e09a71ec230 [unset]> is bound to a different event loop\n",
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 403, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1133, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 113, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 123, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 109, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 387, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 288, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7e09a71ec230 [unset]> is bound to a different event loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9f52f5b11793467dde.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://b1c1a1b78db600cb10.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://92fe60161ee222b4f0.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://57b7e3461c0fb9f24a.gradio.live\n",
            "Killing tunnel 127.0.0.1:7864 <> https://167fcbfca1a115b485.gradio.live\n",
            "Killing tunnel 127.0.0.1:7865 <> https://06375e295384d1a72f.gradio.live\n",
            "Killing tunnel 127.0.0.1:7866 <> https://5d52100bcffd82ea33.gradio.live\n",
            "Killing tunnel 127.0.0.1:7867 <> https://7c269650e53add7232.gradio.live\n",
            "Killing tunnel 127.0.0.1:7868 <> https://d0b88ddd2d1a986773.gradio.live\n",
            "Killing tunnel 127.0.0.1:7869 <> https://4c36b9567f925b7869.gradio.live\n",
            "Killing tunnel 127.0.0.1:7870 <> https://b5f3e51e4b5329111c.gradio.live\n",
            "Killing tunnel 127.0.0.1:7871 <> https://9a2dd7059fa632dccd.gradio.live\n",
            "Killing tunnel 127.0.0.1:7872 <> https://906d633958989ca7af.gradio.live\n",
            "Killing tunnel 127.0.0.1:7873 <> https://1d11c2e5579ccd3f26.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}